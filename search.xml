<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kaggle Dog vs Cat]]></title>
    <url>%2F2020%2F03%2F13%2FKaggle-Dog-vs-Cat%2F</url>
    <content type="text"><![CDATA[这是我接触的第一个Kaggle上面的比赛使用深度学习框架去完成，毕竟是一个图片识别的问题 原题目在这里 The training archive contains 25,000 images of dogs and cats. Train your algorithm on these files and predict the labels for test1.zip (1 = dog, 0 = cat). 其实说白了，这道题也是比较简单的一道图片的二分类问题，最终的目的就是要输出这张图片究竟是狗狗还是猫猫 按照 步骤来做，以下的步骤基于深度学习框架 Pytorch 数据处理这里是直接去封装成一个dataset来读取操作图片 下面给出代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061from PIL import Imagefrom torch.utils.data import Datasetfrom torchvision import transforms as Timport osclass DogVsCat(Dataset): def __init__(self, root, transforms, train, test): self.test = test imgs = [os.path.join(root, img) for img in os.listdir(root)] if self.test: # ...../data/1001.jpg imgs = sorted(imgs, key=lambda x: int(x.split('.')[-2].split('/')[-1])) self.imgs = imgs else: # ...../data/dog.1001.jpg imgs = sorted(imgs, key=lambda x: int(x.split('.')[-2])) imgs_num = len(imgs) if self.test: pass elif train: self.imgs = imgs[:int(0.7 * imgs_num)] else : self.imgs = imgs[int(0.7 * imgs_num):] if transforms is None: normalize = T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]) if self.test or not train: self.transforms = T.Compose([ T.Resize(224), T.CenterCrop(224), T.ToTensor(), normalize ]) else : self.transforms = T.Compose([ T.Resize(256), T.RandomResizedCrop(224), T.RandomHorizontalFlip(), T.ToTensor(), normalize ]) def __getitem__(self, index): img_path = self.imgs[index] # return the label if you get img if self.test: # ...../data/1001.jpg label = int(img_path.split('.')[-2].split('/')[-1]) else : # ...../data/dog.1001.jpg # dog : 1 , cat : 0 label = 1 if 'dog' in img_path else 0 img = Image.open(img_path) img = self.transforms(img) return img, label def __len__(self): return len(self.imgs) 需要注意的三个地方 在getitem里面再去将图片保存在内存里，其他的时候保存图片的路径，并且进行排序 区分以下图片的测试集，与训练集，验证集，label返回的值，图片数量，以及图片优化都有所不同 最后一次写的时候竟然还是忘记在读取图片的过程中进行一个优化 当处理完数据，并且封装了一个相应的数据集合之后，接下来的任务就是 建立卷积网络模型，这里应用的是包的深度学习网络，并且采取的预训练参数 当然，如果自己去调试一个模型的话，可能要花上一个月左右的时间，所以这里直接借用其他人的模型，来帮助自己进行调试相关的模型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445import torch as tfrom torchvision.models import squeezenet1_1from torch.optim import Adamfrom torch import nnimport timeclass SqueezeNet(nn.Module): def __init__(self, num_classes=2): super(SqueezeNet, self).__init__() self.model_name = 'squeezenet' self.model = squeezenet1_1(pretrained=True) self.num_classes = num_classes self.classifier = nn.Sequential( nn.Dropout(p=0.5), # 相当于全链接层 nn.Conv2d(512, num_classes, 1), nn.ReLU(True), nn.AvgPool2d(13, stride=1) ) def forward(self, x): return self.model(x) def get_optim(self, lr, weight_decay): # 这里使用的是预训练模型，所以只有优化后面的参数即可 return Adam(self.model.classifier.parameters(),lr=lr, weight_decay=weight_decay) def load(self, path): self.load_state_dict(t.load(path)) def save(self, name=None): if (name is None): prefix = 'checkpoints/' + self.model_name + '_' name = time.strftime(prefix + '%m%d_%H:%M:%S.pth') t.save(self.state_dict(), name) def load(self, path): self.load_state_dict(t.load(path)) def save(self, name=None): if (name is None): prefix = 'checkpoints/' + self.model_name + '_' name = time.strftime(prefix + '%m%d_%H:%M:%S.pth') t.save(self.state_dict(), name) return name 同样要记住两点 记住在优化的过程中所有的 in_feature 与 out_feature 必须一一对应清楚 由于这里直接使用了预训练模型，所以就直接优化后面的模型就可以了 接下来就可以开始着手写 配置函数和主函数了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import torch as timport osimport ipdbimport tqdmimport fireimport warningsfrom torchnet import meterfrom torch.utils.data import DataLoaderfrom torch import nnimport csvfrom dataset import DogVsCatfrom model import SqueezeNetfrom utils import Visualizerclass Config(object): env = 'Dog or Cat' train_root = './data/train' test_root = './data/test1' load_model_path = None use_gpu = False lr = 0.001 lr_decay = 0.5 weight_decay = 0e-5 batch_size = 32 num_works = 4 max_epoch = 10 plot_every = 20 debug_path = 'tmp/debug' device = Noneopt = Config()def test(**kwargs): for k, v in kwargs.items(): if not hasattr(opt, k): warnings.warn("Warning: opt has not attribut %s" % k) setattr(opt, k, v) model = SqueezeNet() if opt.load_model_path: model.load(opt.load_model_path) device = t.device('cuda') if opt.use_gpu else t.device('cpu') model.to(opt.device) test_data = DogVsCat(opt.test_root,train=False,test=True) test_dataloader = DataLoader(test_data,batch_size=opt.batch_size,shuffle=False,num_workers=opt.num_works) results = [] for ii,(data, label) in tqdm.tqdm(enumerate(test_dataloader)): input = data.to(opt.device) score = model(input) probability = t.nn.functional.softmax(score,dim=1)[:,0].detach().tolist() if ii == 0 : print(score) res = [(path_.item(), probability_) for path_,probability_ in zip(label, probability)] results.append(res) with open('result.csv','w') as f: writer = csv.writer(f) writer.writerow(['id', 'label']) writer.writerows(results)def train(**kwargs): for k, v in kwargs.items(): setattr(opt, k, v) opt.device = t.device('cuda') if opt.use_gpu else t.device('cpu') vis = Visualizer(env=opt.env) train_dataset = DogVsCat(opt.train_root, train=True, test=False) train_dataloader = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_works) cv_dataset = DogVsCat(opt.train_root, train=False, test=False) cv_dataloader = DataLoader(cv_dataset, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_works) model = SqueezeNet() if opt.load_model_path: model.load(opt.load_model_path) model.to(opt.device) criterion = nn.CrossEntropyLoss() lr = opt.lr optim = model.get_optim(lr=lr, weight_decay=opt.weight_decay) loss_meter = meter.AverageValueMeter() confusion_matrix = meter.ConfusionMeter(2) # 二分类问题，所以就使用这样的写法 previous_loss = 1e10 # 训练集操作 for epoch in range(opt.max_epoch): loss_meter.reset() confusion_matrix.reset() for ii, (data, label) in tqdm.tqdm(enumerate(train_dataloader)): input = data.to(opt.device) target = label.to(opt.device) output = model(input) optim.zero_grad() loss = criterion(output, target) loss.backward() optim.step() loss_meter.add(loss.item()) confusion_matrix.add(output.detach(), target.detach()) if (ii + 1) % opt.plot_every == 0: vis.plot('loss', loss_meter.value()[0]) if os.path.exists(opt.debug_path): ipdb.set_trace() model.save() # 验证集开始验证 cv_val, cv_accuracy = val(model, cv_dataloader) vis.plot('val_accuracy', cv_accuracy) vis.log("epoch:&#123;epoch&#125;,lr:&#123;lr&#125;,loss:&#123;loss&#125;,train_cm:&#123;train_cm&#125;,val_cm:&#123;val_cm&#125;".format( epoch=epoch, loss=loss_meter.value()[0], val_cm=str(cv_val), train_cm=str(confusion_matrix.value()), lr=opt.lr)) if loss_meter.value()[0] &gt; previous_loss: lr = lr * opt.lr_decay for param_group in optim.param_groups: param_group['lr'] = lr previous_loss = loss_meter.value()[0]def val(model, cv_dataloader): model.eval() confusion_matrix = meter.ConfusionMeter(2) for ii, (data, label) in tqdm.tqdm(enumerate(cv_dataloader)): input = data.to(opt.device) target = label.to(opt.device) output = model(input) confusion_matrix.add(output.detach().squeeze(), target.type(t.LongTensor)) model.train() cv_val = confusion_matrix.value() cv_accuracy = 100 * (cv_val[0][0] + cv_val[1][1] / cv_val.sum()) return cv_val, cv_accuracyif __name__ == '__main__': fire.Fire() 总体来说代码还是比较简单的，由于对py的语法不是特别熟悉，所以需要注意五个地方 注意**kwargs 需要将其的item拿出来赋值，要不然就必须全部赋值 这里混淆矩阵有办法帮着看而分类问题 时时刻刻都要注意代码运行的地方到底实在cpu还是在gpu 记住对特征值的处理才能够得到答案 也是最重要的一点，上面模型生成结果之后，需要去应用softmax进行一个二分类问题]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Pytorch</tag>
        <tag>卷积网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clustering and Dimensionality Reduction]]></title>
    <url>%2F2020%2F03%2F13%2FClustering-and-Dimensionality-Reduction%2F</url>
    <content type="text"><![CDATA[Clustering终于步入到了，非监督学习，前面所涉及到的课程，全部都是监督学习。 所谓监督学习与非监督学习之间的区别，最简单的区别就是前者有标签值，后者没有标签值。 就像下面两副图片 二者的区别就一目了然 课上，就直接将这群没有标签值的数据 叫做 cluster。 意思是每一个数据都是没有差别，其举的例子，在应用上有 市场分管，社交网络，天文学，还有很多。 但是，每一个数据本身的特征会使有相近特征的人互相靠近，举个例子，社交网络上，你加的好友，大多数是你的亲人，你的现实生活中的朋友，这些都是你现实中的社交网络 那么，如何将给定的数据进行一个有效的分类呢？ 这个时候就引出了 K-means算法 通过给出的一大堆数据点，随机选取标签点，然后根据与标签的相对距离，来完成一个近似的分类过程 这里给出三张图片来完成这样一个过程： 在这个算法里，输入的是 K个族群分布标签，和训练集 下面就是这个算法的全过程了 翻译成中文的意思 随机选取K个标签数据 然后再去遍历每一个数据，计算与哪一个标签值是最近的，并且将其归类 归类结束之后，计算每一群的均值，并且试图将其最小化 一直重复2，3，一直到mean值最小为止 其的应用就主要体现在了 衣服的选择上 人类去选择衣服，根据身高体重划分衣服为 S，M，L码 K-mean的优化方式123456Randomly initialize K cluster centroids mu(1), mu(2), ..., mu(K)Repeat: for i = 1 to m: c(i):= index (from 1 to K) of cluster centroid closest to x(i) for k = 1 to K: mu(k):= average (mean) of points assigned to cluster k 算法分为两个步骤，第一个for循环是赋值步骤，即：对于每一个样例i，计算其应该属于的类。第二个for循环是聚类中心的移动，即：对于每一个类 K重新计算该类的质心。在K-means算法中的变量在上面已经被标明。 回顾刚才给出的，k-mean均值迭代算法，我们知道，第一个循环是用于减小 ${c}^{(i)}$ 引起的代价，而第二个循环则是用于减小 引起代价。迭代的过程一定会减小代价函数，要不然就是出现了错误。 随机初始化在运行K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做： 我们应该选择 K &lt; m，即聚类中心点的个数要小于所有训练集实例的数量 随机选择 K 个训练实例。 令 K 个聚类中心分别与这 K个训练实例相等 K-均值的一个问题在于它有可能会停留在一个局部最小值处，而这取决于初始化的情况。为了解决这个问题，我们通常需要多次运行K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行K-均值的结果，选择代价函数最小的结果。这种方法在K较小的时候（2—10）还是可行的，但是K如果较大，这么做也可能不会有明显地改善。 12345for i = 1 to 100: randomly initialize k-means run k-means to get 'c' and 'm' compute the cost function (distortion) J(c,m)pick the clustering that gave us the lowest cost 选择聚类数K的选择往往是任意的或者说是模糊不清的，通常是需要根据不同的问题人工进行选择的。选择的时候我们需要思考运用K-均值算法聚类的动机是什么，然后选择能最好服务于该目的标聚类数。 一般都是什么问题，就需要去怎么考虑的选择聚类数 当人们在讨论，选择聚类数目的方法时，有一个可能会谈及的方法叫作“肘部法则”。将代价J和聚类K画在图中。代价函数会随着K的增加而降低然后趋于平缓，我们要做的就是找到J开始趋于平缓时的K。然而很多时候，曲线经常是很平缓的，这时的肘部就很不明显。（note：J一般都是随着K的增加而降低，但如果K出现了错误的局部最优则会导致不一样的结果）。 这个地方需要去注意的是： 等到cost函数值稳定了之后再记入相关的函数中： Dimensionality Reduction使用降维的动机有几个不同的的原因使你可能想要做降维。一是数据压缩，如果我们有大量多余的数据时，我们可能想降低特征的维度，为此可以找到两个高度相关的特征，将其画出图像然后做一条直线来同时描述这两个特征。二是数据可视化，因为数据超过三维就很难可视化了，因此有时候需要将维度下降到3或者以下来达到可视化的目的。 主成分分析问题主成分分析(PCA)是最常见的降维算法。其定义是想把数据从n维降到k维（k小于n），就在这个空间里面找k个单位向量来表示数据，使得数据点投影到这个面上的误差最小。如下例子：2到1和3到2： 在二维变成一维的时候 虽然同是一条直线拟合，但PCA和线性回归是不同的： 计算loss的方式有所不同 PCA没有标签Y（非监督） PCA算法PCA 减少 n 维到 k 维： 均值归一化。我们需要计算出所有特征的均值，然后令x_j=x_j-μ_j。如果特征是在不同的数量级上，我们还需要将其除以标准差$σ^2$。 计算协方差矩阵（covariance matrix）$Σ ：\sum=\frac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$ 计算协方差矩阵Σ的特征向量（eigenvectors）在 Octave 里我们可以利用奇异值分解（singular value decomposition）来求解，[U, S, V]= svd(sigma)。$\Sigma=\frac {1}{m}\sum^{n}_{i=1}\left( x^{(i)}\right) \left( x^{(i)}\right) ^{T}$ 对于一个 n×n 维度的矩阵，上式中的 U 是一个具有与数据之间最小投射误差的方向向量构成的矩阵。如果我们希望将数据从 n 维降至 k 维，我们只需要从U中选取前k个向量，获得一个n×k维度的矩阵，我们$U_{reduce}$用表示，然后通过如下计算获得要求的新特征向量 $z^{(i)}=U^{T}_{reduce}*x^{(i)}$ 其中x是n×1维的，因此结果为 k×1 维度。我们不对方差特征进行处理。 选择主成分的数量在PCA算法中我们把n维特征变量降维到k维特征变量。这个数字k也被称作主成分的数量或者说是我们保留的主成分的数量。我们先来思考两个值： PCA所做的是尽量最小化平均平方映射误差(Average Squared Projection Error)。 我还要定义一下数据的总变差(Total Variation)。它的意思是 “平均来看我的训练样本距离零向量多远？ 我们把两个数的比值作为衡量PCA算法的有效性 定义一个阈值然后实验k，看看那个最小的k合适。计算步骤如 这里有个技巧：svd函数会返回一个对角矩阵S，他的元素可以很快的计算这个阈值。 主成分分析法的应用建议PCA算法主要有以下用途： 压缩： 减少内存和磁盘的占用 提升算法的速度 可视化： 降维到二维或者三维 有些人觉的PCA也可以用来防止过拟合，但是这是不对的。应该用正则化。正则化使用y标签最小化损失函数，使用了y标签信息。而PCA只单纯的看x的分部就删除了一些特征，损失率很多信息。另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分，这虽然很多时候有效果，最好还是从所有原始特征开始，只在有必要的时候（算法运行太慢或者占用太多内存）才考虑采用主要成分分析。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>非监督学习</tag>
        <tag>维度下降</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Support Vector Machines]]></title>
    <url>%2F2020%2F03%2F13%2FSupport-Vector-Machines%2F</url>
    <content type="text"><![CDATA[首先，支持向量机的由来（在吴恩达机器学习的课程中，是从逻辑回归课延伸过来的） 其实 支持向量机就是一个二分类模型，目的就是为了寻找一个超平面对样本进行一个线性分割，分割的员额是间隔最大化， 从简单到困难的模型包括： 当训练样本线性可分时，通过硬间隔最大化，学习一个线性可分支持向量机 当训练样本近似线性可分时，通过软间隔最大化，学习一个线性支持向量机 当训练样本线性不可分时，通过核技巧和软间隔最大化，学习一个非线性支持向量机 初识向量机 首先从这个函数y一点点的进行修改，取这里的z=1点，先画出将要用的代价函数，新的代价函数将会水平的从这里到右边，然后再画一条同逻辑回归非常相似的直线，但是在这里是一条直线，也就是 用紫红色画的曲线。那么到了这里已经非常接近逻辑回归中使用的代价函数了，只是这里是由两条线段组成 即位于右边的水平部分和位于左边的直线部分。先别过多的考虑左边直线部分的斜率，这并不是很重要，但是 这里我们将使用的新的代价函数是在y=1的前提下的。你也许能想到这应该能做同逻辑回归中类似的事情但事实上在之后的的优化问题中这会变得更坚定，并且为支持向量机带来计算上的优势。 通过对边界的划分，引出支持向量机 其实我刚刚开始的理解，对于支持向量机的理解也并不是特别到位。 只知道支持向量机 更改以往机器学习处理数据的方式，支持向量机不太在乎数据的维度、 所谓机器学习的本质就是将问题真实模型无限逼近，这个与问题真实解之间的误差，就叫做风险（更严格的说，误差的累积叫做风险）。我们选择了一个假设之后（更直观点说，我们得到了一个分类器以后），真实误差无从得知，但我们可以用某些可以掌握的量来逼近它。最直观的想法就是使用分类器在样本数据上的分类的结果与真实结果（因为样本是已经标注过的数据，是准确的数据）之间的差值来表示。这个差值叫做经验风险Remp(w)。以前的机器学习方法都把经验风险最小化作为努力的目标，但后来发现很多分类函数能够在样本集上轻易达到100%的正确率，在真实分类时却一塌糊涂（即所谓的推广能力差，或泛化能力差）。此时的情况便是选择了一个足够复杂的分类函数（它的VC维很高），能够精确的记住每一个样本，但对样本之外的数据一律分类错误。回头看看经验风险最小化原则我们就会发现，此原则适用的大前提是经验风险要确实能够逼近真实风险才行（行话叫一致），但实际上能逼近么？答案是不能，因为样本数相对于现实世界要分类的文本数来说简直九牛一毛，经验风险最小化原则只在这占很小比例的样本上做到没有误差，当然不能保证在更大比例的真实文本上也没有误差。 这里引入了一个概念： 统计学习因此而引入了泛化误差界的概念，就是指真实风险应该由两部分内容刻画，一是经验风险，代表了分类器在给定样本上的误差；二是置信风险，代表了我们在多大程度上可以信任分类器在未知文本上分类的结果。很显然，第二部分是没有办法精确计算的，因此只能给出一个估计的区间，也使得整个误差只能计算上界，而无法计算准确的值（所以叫做泛化误差界，而不叫泛化误差） 所谓VC维是对函数类的一种度量，可以简单的理解为问题的复杂程度，VC维越高，一个问题就越复杂。正是因为SVM关注的是VC维，后面我们可以看到，SVM解决问题的时候，和样本的维数是无关的（甚至样本是上万维的都可以，这使得SVM很适合用来解决文本分类的问题，当然，有这样的能力也因为引入了核函数）。 置信风险与两个量有关，一是样本数量，显然给定的样本数量越大，我们的学习结果越有可能正确，此时置信风险越小；二是分类函数的VC维，显然VC维越大，推广能力越差，置信风险会变大。 泛化误差界的公式为： SVM正是这样一种努力最小化结构风险的算法。 SVM其他的特点就比较容易理解了。 小样本，并不是说样本的绝对数量少（实际上，对任何算法来说，更多的样本几乎总是能带来更好的效果），而是说与问题的复杂度比起来，SVM算法要求的样本数是相对比较少的。 非线性，是指SVM擅长应付样本数据线性不可分的情况，主要通过松弛变量（也有人叫惩罚变量）和核函数技术来实现，这一部分是SVM的精髓，以后会详细讨论。多说一句，关于文本分类这个问题究竟是不是线性可分的，尚没有定论，因此不能简单的认为它是线性可分的而作简化处理，在水落石出之前，只好先当它是线性不可分的（反正线性可分也不过是线性不可分的一种特例而已，我们向来不怕方法过于通用）。 高维模式识别是指样本维数很高，例如文本的向量表示，如果没有经过另一系列文章（《文本分类入门》）中提到过的降维处理，出现几万维的情况很正常，其他算法基本就没有能力应付了，SVM却可以，主要是因为SVM 产生的分类器很简洁，用到的样本信息很少（仅仅用到那些称之为“支持向量”的样本，此为后话），使得即使样本维数很高，也不会给存储和计算带来大麻烦（相对照而言，kNN算法在分类时就要用到所有样本，样本数巨大，每个样本维数再一高，这日子就没法过了……）。 其实在文本数据的处理上，目前来最好的使用方法就是深度学习中的RNN和词向量的结合 直观上对大间隔的理解下图中的公式表示了支持向量机模型的代价函数，左边的图中，画出了z的代价函数，此函数适用于正样本，右边画的z的代价函数，适用于负样本。 上面介绍了间隔的概念。 具体的例子，可以直接看下面这样一个数据集： 其中有正样本也有负样本，可以看到这个数据是线性可分的，即存在一条直线把正负样本分开，且这里存在有多条不同的直线可以把正负样本分开。支持向量机会选择图中黑色的这条线来作为决策边界，相对于其他的线来看要更合理些。从数学上来讲，这条黑线和训练样本之间有着更大的最短距离，这个距离被称作支持向量机的间距，这是支持向量机具有鲁棒性的原因，因为它努力用一个最大间距来分离样本。因此SVM经常被称作是一种大间距分类器（Large Margin Intuition）。 在实际的使用中，我们可能会出现一些异常点数据，比如下图： 由于异常点的存在，决策边界可能就变成了图中倾斜的那条线，这显然是不明智的。因此，如果C设置的非常大，这也是支持向量机将会做的，它从图中较为竖直的线变为了倾斜的那条，但如果C的值设置的小一点，最终将会得到图中较为竖直的线。当然，如果数据不是线性可分的，支持向量机也可以将它们分开。因此大间距分类器仅仅是从直观上给出了正则化参数C非常大的情形。同时要提醒你C的作用类似于 1 / lambda, lambda 是我们之前使用过的正则化参数，这只是C非常大的情形或者等价 lambda 非常小的情形。实际上当C不是非常大时，支持向量机可以忽略掉一些异常点的影响，得到更好的决策边界，甚至当数据不是线性可分的时候也能给出很好的结果。 核函数假设有个数据集如下图所示，我们希望拟合一个非线性的决策边界来区分正负样本，一种方法是构造多项式特征变量如图中所示： 这就是一种新的函数了，直接嵌合在支持向量机内部函数里面。作为相应的分类依据，计算新的特征变量 当然，这个时候再次考虑到一个问题，有没有比这些高阶项更好的特征变量呢？ 就是相当于力了几根柱子，与后面的k-mean有点相像，并且类似。 通过上图可以看出，sigmoid越大收敛越慢，反之收敛越快。 那么现在有个问题，上述的标记点是随机取得，这很显然没那么简单，有一种较好的方法，是将训练集中的正样本作为标记点，对于每一个训练集中的数据，我们都有一个m+1维向量与之对应。 这里的fo默认为1。如下图所示： 下面是支持向量机的两个参数 C 和 sigmoid 的影响(C可以看做)：C较大时，相当于sigmoid较小，可能会导致过拟合，高方差；C较小时，相当于sigmoid较大，可能会导致低拟合，高偏差；sigmoid 较大时，可能会导致低方差，高偏差；sigmoid 较小时，可能会导致低偏差，高方差。 实践SVM在实际工作中，我们往往使用已有的工具包中所包含的SVM。在使用时，我们需要注意其中的参数选定和选择想要使用的核函数。其中一个选择是不需要使用任何内核参数，这也叫作线性核函数。因此如果有人说使用了线性核函数的SVM，这就意味着使用了不带有核函数的SVM。从逻辑回归模型，我们得到了支持向量机模型，在两者之间，我们应该如何选择呢？ 如果n很大，接近m，那么使用Logistic回归或者线性SVM； 如果n很小，m大小适中，使用高斯核函数； 如果n很小，m很大，则可以创建新的特征然后使用logistic回归或者线性SVM 神经网络在上面几种情况下都可能有较好的表现，但训练神经网络非常慢。 这一章 需要在今后有大量大块大块时间的时候去弄清楚 背后的数学逻辑 当然在sklearn这个包里面就已经内置好了相应的库了。 目前的要求，就是会去使用就行了。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>支持向量机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络]]></title>
    <url>%2F2020%2F03%2F12%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[首先声明 一下博客内容，全部来自于吴恩达 deep learning 中的内容，这是第四门课的，卷积神经网络的总结。 另外再次声明本篇所用到的所有图片是来自各大博客，由于latex公式还不是特别熟悉，所以遇到数学公式多的知识点，就直接截图别人的总结了。 前面目前遇到的所有机器学习问题，只是涉及到数据，数字上面的变化，但是真实世界中不仅有一维的数字，还有高维度图片，甚至是语音，以及视频。 这个就是后面所研究的最重要的地方了。 卷积神经网络的基础计算机视觉计算机视觉（Computer Vision）包含很多不同类别的问题，如图片分类、目标检测、图片风格迁移等等。 对于小尺寸的图片问题，也许我们用深度神经网络的结构可以较为简单的解决一定的问题。但是当应用在大尺寸的图片上，输入规模将变得十分庞大，使用神经网络将会有非常多的参数需要去学习，这个时候神经网络就不再适用。 卷积神经网络在计算机视觉问题上是一个非常好的网络结构。 边缘检测实例卷积运算是卷积神经网络的基本组成部分。下面以边缘检测的例子来介绍卷积运算。 所谓边缘检测，在下面的图中，分别通过垂直边缘检测和水平边缘检测得到不同的结果： 垂直边缘检测假设对于一个 6 6 大小的图片（以数字表示），以及一个3 3大小的 filter（卷积核） 进行卷积运算，以“*” 符号表示。图片和垂直边缘检测器分别如左和中矩阵所示： 下面就相当于一个最简单最基本的卷积网络的使用 filter 不断地和其大小相同的部分做对应元素的乘法运算并求和，最终得到的数字相当于新图片的一个像素值，如右矩阵所示，最终得到一个4*4大小的图片。 说实话就是将图片中的像素点，进行一系列的数学变换，从而保留出相应的图片像素点组合，当然，其中有很多权重需要去学习。 边缘检测原理以一个有一条垂直边缘线的简单图片来说明。通过垂直边缘 filter 我们得到的最终结果图片可以明显地将边缘和非边缘区分出来： 当然，有更多样式的卷积核，这种卷积核就是弄好的，在卷积神经网络中，需要自己去训练其中的参数 对于复杂的图片，我们可以直接将 filter 中的数字直接看作是需要学习的参数，其可以学习到对于图片检测相比上面filter更好的更复杂的 filter ，如相对于水平和垂直检测器，我们训练的 filter 参数也许可以知道不同角度的边缘。 通过卷积运算，在卷积神经网络中通过反向传播算法，可以学习到相应于目标结果的 filter，将其应用于整个图片，输出其提取到的所有有用的特征。 卷积和互相关在数学定义上，矩阵的卷积操作为首先将卷积核同时在水平核垂直方向上进行翻转，构成一个卷积核的镜像，然后使用该镜像在和前面的矩阵进行移动核相乘求和操作，如下面例子所示： 在深度学习中，我们称为的卷积运算实则没有卷积核变换为镜像的这一步操作，因为在权重学习的角度，变换是没有必要的。深度学习的卷积操作在数学上准确度来说称为互相关（cross-correlation）。 padding没有Padding的缺点： 每次卷积操作，图片就会缩小 角落和边缘位置的像素可能进行的卷积运算次数少，可能会丢失有用的信息。 如果加padding 为了解决上面的两个缺点，我们在进行卷积运算前为图片加padding，包围角落和边缘的像素，使得通过filter的卷积运算后，图片大小不变，也不会丢失角落和边沿的信息。 Valid/Same卷积 前者是没有padding操作，后者就是加入padding后，正好输出图片与输入图片相同。 在计算机视觉中，一般来说padding的值为奇数 卷积步长（stride）卷积的步长是构建卷积神经网络的一个基本的操作。 如前面的例子中，我们使用的 stride=1，每次的卷积运算以1个步长进行移动。下面是 stride=2 时对图片进行卷积的结果： 当然，这只是一维的情况，正常的彩色图片，应该是三个维度的 立体卷积和卷积网络卷积核的通道数，要对于之前的输入的通道数，而卷积核的个数，最后对应输出的通道数 这里需要注意的是 单卷积核与多卷积核的区别，不过多赘述了 其实主要就是记住公式，然后将卷积操作看清楚就行了，正常的深度学习框架都已经给你封装好了操作 下面直接借用一张简单的卷积图来完成对其总结 池化层池化层就分为最大池化层，和平均池化层 这里的公式与上面卷积层基本一样 不过与上面最大的不同就是 池化层里面没有需要学习的参数 下面直接展示两张图片，来介绍一下卷积神经网络，并且讲解一下，为什么会使用卷积神经网络 LeNet-5的参数如下： 使用卷积神经网络的优势 参数少，跟同期的全链接层相比，参数是大大的减少，意思就是可以大大的增加卷积神经网络 参数共享：一个特征检测器（filter）对图片的一部分有用的同时也有可能对图片的另外一部分有用。 连接的稀疏性：在每一层中，每个输出值只取决于少量的输入。 我们将训练集输入到卷积神经网络中，对网络进行训练。利用梯度下降（Adam、momentum等优化算法）最小化代价函数来寻找网络的最优参 深度卷积模型介绍经典的卷积网络下面介绍几种经典的卷积网络，分别是LeNet, AlexNet, VGGNet LeNet-5:针对灰度图片LeNet-5主要是针对灰度设计的，所以其输入较小，为32 32 1，其结构如下： 在LetNet中，存在的经典模式： 随着网络的深度增加，图像的大小在缩小，与此同时，通道的数量却在增加； 每个卷积层后面接一个池化层。 AlexNet 一般用于彩色大图片 与LeNet相似，但网络结构更大，参数更多，表现更加出色； 使用了Relu； 使用了多个GPUs； LRN（后来发现用处不大，丢弃了） AlexNet使得深度学习在计算机视觉方面受到极大的重视。 VGG-16VGG卷积层和池化层均具有相同的卷积核大小，都使用 3 3， stride=1 的卷积和 2 2，stride = 2的池化。其结构如下： ResNetResNet是由残差块组成的 残差块下面是一个普通的神经网络块的传输： 而ResNet块则将其传播过程增加了一个从 [公式] 直接到 [公式] 的连接，将其称之为“short cut”或者“skip connection”： 直接在中间添加了一条捷径，原因是为了解决 深层次的神经网络容易造成梯度消失，以至于后面梯度为0，就不好去更新参数 增加“short cut”后，成为残差块的网络结构： Residual Network： 多个残差块堆积起来构成ResNet的网络结构，其结构如下所示： 在没有残差的普通神经网络中，训练的误差实际上是随着网络层数的加深，先减小再增加； 在有残差的ResNet中，即使网络再深，训练误差都会随着网络层数的加深逐渐减小。 ResNet对于中间的激活函数来说，有助于能够达到更深的网络，解决梯度消失和梯度爆炸的问题。 ResNet表现好的原因下面就直接贴从网站上面找到的相关原因 将普通深度神经网络变为ResNet： 1 * 1 卷积在二维上的卷积相当于图片的每个元素和一个卷积核数字相乘。 但是在三维上，与 nc 卷积核进行卷积，相当于三维图像上的 1 1 nc 的切片，也就是 nc 个点乘以卷积数值权重，通过Relu函数后，输出对应的结果。而不同的卷积核则相当于不同的隐层神经元结点与切片上的点进行一一连接。 所以根本上 1 * 1 卷积核相当于对一个切片上的 nc 个单元都应用了一个全连接的神经网络。 1x1卷积应用： 维度压缩：使用目标维度的 1 1 的卷积核个数。增加非线性：保持与原维度相同的 1 1 的卷积核个数 Inception NetworkInception Network 的作用就是使我们无需去考虑在构建深度卷积神经网络时，使用多大的卷积核以及是否添加池化层等问题。 Inception主要结构： 计算成本的问题 对于上面的 5 * 5 大小卷积核的计算成本： 对于 1 * 1 大小卷积核用作过渡的计算成本，也将下面的中间的层叫做“bottleneck layer”： 所以 1 * 1 卷积核作为“bottleneck layer”的过渡层能够有效减小卷积神经网的计算成本。事实证明，只要合理地设置“bottleneck layer”，既可以显著减小上层的规模，同时又能降低计算成本，从而不会影响网络的性能。 Inception 模块： 将上面说介绍的两种主要思想和模式结合到一起构成 Inception 模块，如下： Inception Network： 多个Inception 模块的堆叠构成Inception Network，下面是GoogleNet的结构： 迁移学习小数据集： 如今在深度学习领域，许多研究者都会将他们的工作共享到网络上。在我们实施自己的工作的时候，比如说做某种物体的识别分类，但是只有少量的数据集，对于从头开始训练一个深度网络结构是远远不够的。 但是我们可以应用迁移学习，应用其他研究者建立的模型和参数，用少量的数据仅训练最后自定义的softmax网络。从而能够在小数据集上达到很好的效果。 其实就是pytorch上面 pretrain=True 如果是自己的数据，那么就建议用他人预训练好的模型，自己再训练自己的数据就会非常省事 大数据集： 如果我们在自己的问题上也拥有大量的数据集，我们可以多训练后面的几层。总之随着数据集的增加，我们需要“ freeze”的层数越来越少。最后如果我们有十分庞大的数据集，那么我们可以训练网络模型的所有参数，将其他研究者训练的模型参数作为参数的初始化来替代随机初始化，来加速我们模型的训练。 就像最后一次pytorch训练 识别图片上面在做的事情一样，将最后一层进行一个更改就可以了。 数据增强 以及数据扩充与其他机器学习问题相比，在计算机视觉领域当下最主要的问题是没有办法得到充足的数据。所以在我们训练计算机数据模型的时候，数据的扩充就是会非常有用。 数据扩充的方法： 镜像翻转（Mirroring） 随机剪裁（Random Cropping） 色彩转换（Color shifting） 为图片的RGB三个色彩通道进行增减值，如（R：+20，G：-20，B：+20）；PCA颜色增强：对图片的主色的变化较大，图片的次色变化较小，使总体的颜色保持一致。 为了节省时间，数据扩充的过程和训练过程可以多CPU多线程来并行的实现。 数据和手工工程： 在有大量数据的时候，我们更倾向于使用简单的算法和更少的手工工程。因为此时有大量的数据，我们不需要为这个问题来精心设计特征，我们使用一个大的网络结果或者更简单的模型就能够解决。 相反，在有少量数据的时候，我们从事更多的是手工工程。因为数据量太少，较大的网络结构或者模型很难从这些少量的数据中获取足够的特征，而手工工程实际上是获得良好表现的最佳方式。 对于机器学习应用： 标记数据，（x,y） 手工特征工程/网络结构/其他构建 在基准研究和比赛中，下面的tips可能会有较好的表现： Ensembling：独立地训练多个网络模型，输出平均结果或加权平均结果； 测试时的 Multi-crop：在测试图片的多种版本上运行分类器，输出平均结果。 目标检测目标定位和特征点检测图片检测问题： 分类问题：判断图中是否为汽车； 目标定位：判断是否为汽车，并确定具体位置； 目标检测：检测不同物体并定位。 目标分类和定位： 对于目标定位问题，我们卷积神经网络模型结构可能如下： 输出：包含图片中存在的对象及定位框 行人，0 or 1；汽车，0 or 1；摩托车，0 or 1；图片背景，0 or 1； 然后根据图片中的定位框： 其中bx，by表示汽车中点，bh，bw分别表示定位框的。以左上图为（0，0），以右下图为（1，1），这些数字均为位置或长度 特征点检测： 由前面的目标定位问题，我们可以知道，神经网络可以通过输出图片上特征点的坐标（x,y），来实现对目标特征的识别和定位标记。 如对于人脸表情识别的问题中，我们通过标定训练数据集中特征点的位置信息，来对人脸进行不同位置不同特征的定位和标记。AR的应用就是基于人脸表情识别来设计的，如脸部扭曲、增加头部配饰等。 在人体姿态检测中，同样可以通过对人体不同的特征位置关键点的标注，来记录人体的姿态。 目标检测目标检测采用的是基于滑动窗口的检测算法。 滑动窗口目标检测： 首先选定一个特定大小的窗口，将窗口内的图片输入到模型中进行预测 以固定步幅滑动该窗口，遍历图像的每个区域，对窗内的各个小图不断输入模型进行预测 继续选取一个更大的窗口，再次遍历图像的每个区域，对区域内是否有车进行预测 遍历整个图像，可以保证在每个位置都能检测到是否有车 缺点：计算成本巨大，每个窗口的小图都要进行卷积运算，（但在神经网络兴起之前，使用的是线性分类器，所以滑动窗口算法的计算成本较低）。 卷积层替代全连接层：对于卷积网络中全连接层，我们可以利用1 * 1大小卷积核的卷积层来替代。 就像下面一样: 滑动窗口卷积实现 在我们实现了以卷积层替代全部的全连接层以后，在该基础上进行滑动窗口在卷积层上的操作。下面以一个小的图片为例： 我们以上面训练好的模型，输入一个16 16 3大小的整幅图片，图中蓝色部分代表滑动窗口的大小。我们以2为大小的步幅滑动窗口，分别与卷积核进行卷积运算，最后得到4幅 10 10 16 大小的特征图，然而因为在滑动窗口的操作时，输入部分有大量的重叠，也就是有很多重复的运算，导致在下一层中的特征图值也存在大量的重叠，所以最后得到的第二层激活值（特征图）构成一副 12 12 16大小的特征图。对于后面的池化层和全连接层也是同样的过程。 那么由此可知，滑动窗口在整幅图片上进行滑动卷积的操作过程，就等同于在该图片上直接进行卷积运算的过程。所以卷积层实现滑动窗口的这个过程，我们不需要把输入图片分割成四个子集分别执行前向传播，而是把他们作为一张图片输入到卷积神经网络中进行计算，其中的重叠部分（公共区域）可以共享大量的计算。 汽车目标检测： 依据上面的方法，我们将整张图片输入到训练好的卷积神经网络中。无需再利用滑动窗口分割图片，只需一次前向传播，我们就可以同时得到所有图片子集的预测值 Bounding Box 预测前面一节的卷积方式实现的滑动窗口算法，使得在预测时计算的效率大大提高。但是其存在的问题是：不能输出最精准的边界框（Bounding Box）。 在滑动窗口算法中，我们取的一些离散的图片子集的位置，在这种情况下，有可能我们没有得到一个能够完美匹配汽车位置的窗口，也有可能真实汽车的边界框为一个长方形。所以我们需要寻找更加精确的边界框。 YOLO： YOLO算法可以使得滑动窗口算法寻找到更加精准的边界框。 YOLO notation： 将对象分配到一个格子的过程是：观察对象的中点，将该对象分配到其中点所在的格子中，（即使对象横跨多个格子，也只分配到中点所在的格子中，其他格子记为无该对象，即标记为“0”）； YOLO显式地输出边界框，使得其可以具有任意宽高比，并且能输出更精确的坐标，不受滑动窗口算法滑动步幅大小的限制； YOLO是一次卷积实现，并不是在 n * n网格上进行 n 的平方运算，而是单次卷积实现，算法实现效率高，运行速度快，可以实现实时识别。 bounding boxes 细节： 利用YOLO算法实现目标探测的时候，对于存在目标对象的网格中，定义训练标签Y的时候，边界框的指定参数的不同对其预测精度有很大的影响。这里给出一个较为合理的约定：（其他参数指定方式可阅读论文） 交并比（Intersection-over-Union）交并比函数用来评价目标检测算法是否运作良好。 对于理想的边界框和目标探测算法预测得到的边界框，交并比函数计算两个边界框交集和并集之比。 IoU = 交集面积 / 并集面积 一般在目标检测任务中，约定如果IoU &gt;= 0.5 ，那么就说明检测正确。当然标准越大，则对目标检测算法越严格。得到的IoU值越大越好。 非最大值抑制（non-max suppression，NMS）对于我们前面提到的目标检测算法，可能会对同一个对象做出多次的检测，非最大值抑制可以确保我们的算法对每个对象只检测一次。 多网格检测同一物体： 对于汽车目标检测的例子中，我们将图片分成很多精细的格子。最终预测输出的结果中，可能会有相邻的多个格子里均检测出都具有同一个对象。 Anchor box通过上面的各种方法，目前我们的目标检测算法在每个格子上只能检测出一个对象。使用Anchor box可以同时检测出多个对象。 Anchor box 的选择： 一般人工指定Anchor box 的形状，选择5~10个以覆盖到多种不同的形状，可以涵盖我们想要检测的对象的形状； 高级方法：K-means 算法：将不同对象形状进行聚类，用聚类后的结果来选择一组最具代表性的Anchor box，以此来代表我们想要检测对象的形状。 YOLO算法目标检测假设我们要在图片中检测三种目标：行人、汽车和摩托车，同时使用两种不同的Anchor box。 模型预测： 输入与训练集中相同大小的图片，同时得到每个格子中不同的输出结果：3 3 2 * 8 运行非最大值抑制（NMS）： 假设使用了2个Anchor box，那么对于每一个网格，我们都会得到预测输出的2个bounding boxes，其中一个 Pc 比较高 抛弃概率 Pc 值低的预测bounding boxes 对每个对象（如行人、汽车、摩托车）分别使用NMS算法得到最终的预测边界框 候选区域（region proposals）R-CNN： R-CNN（Regions with convolutional networks），会在我们的图片中选出一些目标的候选区域，从而避免了传统滑动窗口在大量无对象区域的无用运算。 所以在使用了R-CNN后，我们不会再针对每个滑动窗口运算检测算法，而是只选择一些候选区域的窗口，在少数的窗口上运行卷积网络。 具体实现：运用图像分割算法，将图片分割成许多不同颜色的色块，然后在这些色块上放置窗口，将窗口中的内容输入网络，从而减小需要处理的窗口数量。 更快的算法： R-CNN：给出候选区域，不使用滑动窗口，对每个候选区域进行分类识别，输出对象 标签 和 bounding box，从而在确实存在对象的区域得到更精确的边界框，但速度慢； Fast R-CNN：给出候选区域，使用滑动窗口的卷积实现去分类所有的候选区域，但得到候选区的聚类步骤仍然非常慢； Faster R-CNN：使用卷积网络给出候选区域。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>卷积网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kaggle Titanic 生存预测]]></title>
    <url>%2F2020%2F03%2F11%2FKaggle-Titanic-%E7%94%9F%E5%AD%98%E9%A2%84%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[这是一篇入门的kaggle的初级案例。 本来自己第一遍去做的时候，发现预测的正确率只能够达到77%，经过了无数次调参，最后也只能到达79%，于是自己决定花点时间按照流程写一遍，并且记录下来 题目比较具有趣味性。给你两个数据集合，其中一个有标签值，另外一个没有标签值，然后给出了姓名，性别，船费，年龄，以及船仓位相关的数据 然后预测这个人是否能够存活 按照相关的步骤来： 分析题目首先这道题就是一个让你预测test数据组里面的人能否存活，其实就是一个二分类问题，如果存活最后的结果输出1，如果没有存活，那么最后的结果输出0 确认这是一个二分类问题，接下来就可以去整理数据了 数据总览Titanic 生存模型预测，其中包含了两组数据：train.csv 和 test.csv，分别为训练集合和测试集合。 12345678import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns# 下面这函数就是在jupyter notbook里面，# 可以不必写show函数，可以直接显示出来%matplotlib inline 运用pandas里面的函数，去进行观测数据，并且开始着手数据的处理 12345train_data = pd.read_csv('data/train.csv')test_data = pd.read_csv('data/test.csv')sns.set_style('whitegrid')train_data.head() 123train_data.info()print("-" * 40)test_data.info() 12345678910111213141516171819202122232425262728293031323334&lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Name 891 non-null object Sex 891 non-null object Age 714 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Ticket 891 non-null object Fare 891 non-null float64 Cabin 204 non-null object Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.6+ KB ---------------------------------------- &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 418 entries, 0 to 417 Data columns (total 11 columns): PassengerId 418 non-null int64 Pclass 418 non-null int64 Name 418 non-null object Sex 418 non-null object Age 332 non-null float64 SibSp 418 non-null int64 Parch 418 non-null int64 Ticket 418 non-null object Fare 417 non-null float64 Cabin 91 non-null object Embarked 418 non-null object dtypes: float64(2), int64(4), object(5) memory usage: 36.0+ KB 从上面我们可以看出，Age、Cabin、Embarked、Fare几个特征存在缺失值。 绘制存活的比例： 下面先来一个可视化：1train_data['Survived'].value_counts().plot.pie(autopct = '%1.2f%%') 由上面这张图，我们可以得知 活下来的人与没有活下来的人总体比例，就开始对数据有一个整体的认知 数据处理接下来，我们就要开始准备数据的处理，一般数据存在的问题，要么就是离群点问题，要么就是缺失值问题，要么就是数据变换的问题。 数值变换变量转换的目的是将数据转换为适用于模型使用的数据，不同模型接受不同类型的数据，Scikit-learn要求数据都是数字型numeric，所以我们要将一些非数字型的原始数据转换为数字型numeric。 所有的数据可以分为两类： 定性(Quantitative)变量可以以某种方式排序，Age就是一个很好的列子。 定量(Qualitative)变量描述了物体的某一（不能被数学表示的）方面，Embarked就是一个例子。 针对上面不可以被数学数字表示的数据，下面采取： Dummy Variables就是类别变量或者二元变量，当qualitative variable是一些频繁出现的几个独立变量时，Dummy Variables比较适合使用。我们以Embarked为例，Embarked只包含三个值’S’,’C’,’Q’，我们可以使用下面的代码将其转换为dummies: 1234567embark_dummies = pd.get_dummies(train_data['Embarked'])train_data = train_data.join(embark_dummies)train_data.drop(['Embarked'], axis=1,inplace=True)embark_dummies = train_data[['S', 'C', 'Q']]embark_dummies.head() 其实上面的这种方法有点特别像RNN中词向量。给每一个词加上相应的特征，应用one-hot编码形式 Factorizingdummy不好处理Cabin（船舱号）这种标称属性，因为他出现的变量比较多。所以Pandas有一个方法叫做factorize()，它可以创建一些数字，来表示类别变量，对每一个类别映射一个ID，这种映射最后只生成一个特征，不像dummy那样生成多个特征。 12345678# Replace missing values with "U0"train_data['Cabin'][train_data.Cabin.isnull()] = 'U0'# create feature for the alphabetical part of the cabin numbertrain_data['CabinLetter'] = train_data['Cabin'].map( lambda x : re.compile("([a-zA-Z]+)").search(x).group())# convert the distinct cabin letters with incremental integer valuestrain_data['CabinLetter'] = pd.factorize(train_data['CabinLetter'])[0]train_data['CabinLetter'].head() 1234567891011121314151617181920 0 0 1 1 2 0 3 1 4 0 Name: CabinLetter, dtype: int64``` ##### ScalingScaling可以将一个很大范围的数值映射到一个很小的范围(通常是-1 - 1，或则是0 - 1)，很多情况下我们需要将数值做Scaling使其范围大小一样，否则大范围数值特征将会由更高的权重。比如：Age的范围可能只是0-100，而income的范围可能是0-10000000，在某些对数组大小敏感的模型中会影响其结果。下面对Age进行Scaling：```pythonfrom sklearn import preprocessingassert np.size(train_data['Age']) == 891# StandardScaler will subtract the mean from each value then scale to the unit variancescaler = preprocessing.StandardScaler()train_data['Age_scaled'] = scaler.fit_transform(train_data['Age'].values.reshape(-1, 1)) 1train_data['Age_scaled'].head() 1234560 -0.5584491 0.6067732 -0.2671443 0.3882934 0.388293Name: Age_scaled, dtype: float64 BinningBinning通过观察“邻居”(即周围的值)将连续数据离散化。存储的值被分布到一些“桶”或“箱“”中，就像直方图的bin将数据划分成几块一样。下面的代码对Fare进行Binning。 123# Divide all fares into quartilestrain_data['Fare_bin'] = pd.qcut(train_data['Fare'], 5)train_data['Fare_bin'].head() 12345670 (-0.001, 7.854]1 (39.688, 512.329]2 (7.854, 10.5]3 (39.688, 512.329]4 (7.854, 10.5]Name: Fare_bin, dtype: categoryCategories (5, interval[float64]): [(-0.001, 7.854] &lt; (7.854, 10.5] &lt; (10.5, 21.679] &lt; (21.679, 39.688] &lt; (39.688, 512.329]] 一般这里比较好的使用这个算法的位置是给范围值进行等级的划分，这样以来，然而就会有更好的结果 在将数据Bining化后，要么将数据factorize化，要么dummies化。 123456# factorizetrain_data['Fare_bin_id'] = pd.factorize(train_data['Fare_bin'])[0]# dummiesfare_bin_dummies_df = pd.get_dummies(train_data['Fare_bin']).rename(columns=lambda x: 'Fare_' + str(x))train_data = pd.concat([train_data, fare_bin_dummies_df], axis=1) 缺失值处理一些机器学习算法能够处理缺失值，比如神经网络，一些则不能。对于缺失值，一般有以下几种处理方法： 如果数据集很多，但有很少的缺失值，可以删掉带缺失值的行； 如果该属性相对学习来说不是很重要，可以对缺失值赋均值或者众数。比如在哪儿上船Embarked这一属性（共有三个上船地点），缺失俩值，可以用众数赋值 因为“Embarked”项的缺失值不多，所以这里我们以众数来填充： 1combined_train_test['Embarked'].fillna(combined_train_test['Embarked'].mode().iloc[0], inplace=True) 对于三种不同的港口，由上面介绍的数值转换，我们知道可以有两种特征处理方式：dummy和facrorizing。因为只有三个港口，所以我们可以直接用dummy来处理： 123456# 为了后面的特征分析，这里我们将 Embarked 特征进行facrorizingcombined_train_test['Embarked'] = pd.factorize(combined_train_test['Embarked'])[0]# 使用 pd.get_dummies 获取one-hot 编码emb_dummies_df = pd.get_dummies(combined_train_test['Embarked'], prefix=combined_train_test[['Embarked']].columns[0])combined_train_test = pd.concat([combined_train_test, emb_dummies_df], axis=1) 因为Age项的缺失值较多，所以不能直接填充age的众数或者平均数。 常见的有两种对年龄的填充方式：一种是根据Title中的称呼，如Mr，Master、Miss等称呼不同类别的人的平均年龄来填充；一种是综合几项如Sex、Title、Pclass等其他没有缺失值的项，使用机器学习算法来预测Age。 这里我们使用后者来处理。以Age为目标值，将Age完整的项作为训练集，将Age缺失的项作为测试集。 1234567missing_age_df = pd.DataFrame(combined_train_test[ ['Age', 'Embarked', 'Sex', 'Title', 'Name_length', 'Family_Size', 'Family_Size_Category','Fare', 'Fare_bin_id', 'Pclass']])missing_age_train = missing_age_df[missing_age_df['Age'].notnull()]missing_age_test = missing_age_df[missing_age_df['Age'].isnull()]missing_age_test.head() 建立Age的预测模型，我们可以多模型预测，然后再做模型的融合，提高预测的精度。 123456789101112131415161718192021222324252627282930313233343536373839404142from sklearn import ensemblefrom sklearn import model_selectionfrom sklearn.ensemble import GradientBoostingRegressorfrom sklearn.ensemble import RandomForestRegressordef fill_missing_age(missing_age_train, missing_age_test): missing_age_X_train = missing_age_train.drop(['Age'], axis=1) missing_age_Y_train = missing_age_train['Age'] missing_age_X_test = missing_age_test.drop(['Age'], axis=1) # model 1 gbm gbm_reg = GradientBoostingRegressor(random_state=42) gbm_reg_param_grid = &#123;'n_estimators': [2000], 'max_depth': [4], 'learning_rate': [0.01], 'max_features': [3]&#125; gbm_reg_grid = model_selection.GridSearchCV(gbm_reg, gbm_reg_param_grid, cv=10, n_jobs=25, verbose=1, scoring='neg_mean_squared_error') gbm_reg_grid.fit(missing_age_X_train, missing_age_Y_train) print('Age feature Best GB Params:' + str(gbm_reg_grid.best_params_)) print('Age feature Best GB Score:' + str(gbm_reg_grid.best_score_)) print('GB Train Error for "Age" Feature Regressor:' + str(gbm_reg_grid.score(missing_age_X_train, missing_age_Y_train))) missing_age_test.loc[:, 'Age_GB'] = gbm_reg_grid.predict(missing_age_X_test) print(missing_age_test['Age_GB'][:4]) # model 2 rf rf_reg = RandomForestRegressor() rf_reg_param_grid = &#123;'n_estimators': [200], 'max_depth': [5], 'random_state': [0]&#125; rf_reg_grid = model_selection.GridSearchCV(rf_reg, rf_reg_param_grid, cv=10, n_jobs=25, verbose=1, scoring='neg_mean_squared_error') rf_reg_grid.fit(missing_age_X_train, missing_age_Y_train) print('Age feature Best RF Params:' + str(rf_reg_grid.best_params_)) print('Age feature Best RF Score:' + str(rf_reg_grid.best_score_)) print('RF Train Error for "Age" Feature Regressor' + str(rf_reg_grid.score(missing_age_X_train, missing_age_Y_train))) missing_age_test.loc[:, 'Age_RF'] = rf_reg_grid.predict(missing_age_X_test) print(missing_age_test['Age_RF'][:4]) # two models merge print('shape1', missing_age_test['Age'].shape, missing_age_test[['Age_GB', 'Age_RF']].mode(axis=1).shape) # missing_age_test['Age'] = missing_age_test[['Age_GB', 'Age_LR']].mode(axis=1) missing_age_test.loc[:, 'Age'] = np.mean([missing_age_test['Age_GB'], missing_age_test['Age_RF']]) print(missing_age_test['Age'][:4]) missing_age_test.drop(['Age_GB', 'Age_RF'], axis=1, inplace=True) return missing_age_test 利用融合模型预测的结果填充Age的缺失值： 其实这个地方需要注意的，上面是将trainset与testset进行一个有效的拼接 1combined_train_test.loc[(combined_train_test.Age.isnull()), 'Age'] = fill_missing_age(missing_age_train, missing_age_test) 1234567891011121314151617181920212223242526272829303132Fitting 10 folds for each of 1 candidates, totalling 10 fits [Parallel(n_jobs=25)]: Done 5 out of 10 | elapsed: 3.9s remaining: 3.9s [Parallel(n_jobs=25)]: Done 10 out of 10 | elapsed: 6.9s finished Age feature Best GB Params:&#123;'n_estimators': 2000, 'learning_rate': 0.01, 'max_features': 3, 'max_depth': 4&#125; Age feature Best GB Score:-130.295677599 GB Train Error for "Age" Feature Regressor:-64.6566961723 5 35.773942 17 31.489153 19 34.113840 26 28.621281 Name: Age_GB, dtype: float64 Fitting 10 folds for each of 1 candidates, totalling 10 fits [Parallel(n_jobs=25)]: Done 5 out of 10 | elapsed: 6.2s remaining: 6.2s [Parallel(n_jobs=25)]: Done 10 out of 10 | elapsed: 10.7s finished Age feature Best RF Params:&#123;'n_estimators': 200, 'random_state': 0, 'max_depth': 5&#125; Age feature Best RF Score:-119.094956052 RF Train Error for "Age" Feature Regressor-96.0603148448 5 33.459421 17 33.076798 19 34.855942 26 28.146718 Name: Age_RF, dtype: float64 shape1 (263,) (263, 2) 5 30.000675 17 30.000675 19 30.000675 26 30.000675 Name: Age, dtype: float64 最后一项缺失值处理 因为Cabin项的缺失值确实太多了，我们很难对其进行分析，或者预测。所以这里我们可以直接将Cabin这一项特征去除。但通过上面的分析，可以知道，该特征信息的有无也与生存率有一定的关系，所以这里我们暂时保留该特征，并将其分为有和无两类。 12combined_train_test.loc[combined_train_test.Cabin.isnull(), 'Cabin'] = 'U0'combined_train_test['Cabin'] = combined_train_test['Cabin'].apply(lambda x: 0 if x == 'U0' else 1) 特征处理上面已经处理了一些数据，现在我需要增强一些特征，以便与后面特征的变化 Sex对Sex也进行one-hot编码，也就是dummy处理： 12345# 为了后面的特征分析，这里我们也将 Sex 特征进行facrorizingcombined_train_test['Sex'] = pd.factorize(combined_train_test['Sex'])[0]sex_dummies_df = pd.get_dummies(combined_train_test['Sex'], prefix=combined_train_test[['Sex']].columns[0])combined_train_test = pd.concat([combined_train_test, sex_dummies_df], axis=1) Name首先先从名字中提取各种称呼： 12# what is each person's title? combined_train_test['Title'] = combined_train_test['Name'].map(lambda x: re.compile(", (.*?)\.").findall(x)[0]) 将各式称呼进行统一化处理：123456789title_Dict = &#123;&#125;title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))title_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))combined_train_test['Title'] = combined_train_test['Title'].map(title_Dict) 使用dummy对不同的称呼进行分列： 12345# 为了后面的特征分析，这里我们也将 Title 特征进行facrorizingcombined_train_test['Title'] = pd.factorize(combined_train_test['Title'])[0]title_dummies_df = pd.get_dummies(combined_train_test['Title'], prefix=combined_train_test[['Title']].columns[0])combined_train_test = pd.concat([combined_train_test, title_dummies_df], axis=1) 下面开始就不准备贴代码了，可以去GitHub上面去看 Fare由前面分析可以知道，Fare项在测试数据中缺少一个值，所以需要对该值进行填充。 我们按照一二三等舱各自的均价来填充： 下面transform将函数np.mean应用到各个group中 通过对Ticket数据的分析，我们可以看到部分票号数据有重复，同时结合亲属人数及名字的数据，和票价船舱等级对比，我们可以知道购买的票中有家庭票和团体票，所以我们需要将团体票的票价分配到每个人的头上。 使用binning给票价分等级，对于5个等级的票价我们也可以继续使用dummy为票价等级分列。 Pclass这里是神来之笔，我看到别人在这个地方有出奇的特征增强方法： Pclass这一项，其实已经可以不用继续处理了，我们只需要将其转换为dummy形式即可。 但是为了更好的分析问题，我们这里假设对于不同等级的船舱，各船舱内部的票价也说明了各等级舱的位置，那么也就很有可能与逃生的顺序有关系。所以这里分出每等舱里的高价和低价位。 Parch and SibSp对于这两个参数，大佬们的处理就是 将这两个特征整合成一个特征，牛逼了大佬 特征间相关性分析我们挑选一些主要的特征，生成特征之间的关联图，查看特征与特征之间的相关性：将上述所有特征去看看相互之间的关系或者与结果之间的关系 123Correlation = pd.DataFrame(combined_train_test[ ['Embarked', 'Sex', 'Title', 'Name_length', 'Family_Size', 'Family_Size_Category','Fare', 'Fare_bin_id', 'Pclass', 'Pclass_Fare_Category', 'Age', 'Ticket_Letter', 'Cabin']]) 1234colormap = plt.cm.viridisplt.figure(figsize=(14,12))plt.title('Pearson Correlation of Features', y=1.05, size=15)sns.heatmap(Correlation.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True) 特征之间的数据分布图 123g = sns.pairplot(combined_train_test[[u'Survived', u'Pclass', u'Sex', u'Age', u'Fare', u'Embarked', u'Family_Size', u'Title', u'Ticket_Letter']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )g.set(xticklabels=[]) 输入模型前的一些处理这里我们将Age和fare进行正则化： 12scale_age_fare = preprocessing.StandardScaler().fit(combined_train_test[['Age','Fare', 'Name_length']])combined_train_test[['Age','Fare', 'Name_length']] = scale_age_fare.transform(combined_train_test[['Age','Fare', 'Name_length']]) 丢弃掉一些无用的特征 对于上面的特征工程中，我们从一些原始的特征中提取出了很多要融合到模型中的特征，但是我们需要剔除那些原本的我们用不到的或者非数值特征。 首先对我们的数据先进行一下备份，以便后期的再次分析： 123combined_data_backup = combined_train_testcombined_train_test.drop(['PassengerId', 'Embarked', 'Sex', 'Name', 'Title', 'Fare_bin_id', 'Pclass_Fare_Category', 'Parch', 'SibSp', 'Family_Size_Category', 'Ticket'],axis=1,inplace=True) 将训练数据和测试数据分开： 12345678train_data = combined_train_test[:891]test_data = combined_train_test[891:]titanic_train_data_X = train_data.drop(['Survived'],axis=1)titanic_train_data_Y = train_data['Survived']titanic_test_data_X = test_data.drop(['Survived'],axis=1)titanic_train_data_X.shape 模型融合以及测试需要按照下面的这些步骤来进行： 利用不同的模型来对特征进行筛选，选出较为重要的特征：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586from sklearn.ensemble import RandomForestClassifierfrom sklearn.ensemble import AdaBoostClassifierfrom sklearn.ensemble import ExtraTreesClassifierfrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.tree import DecisionTreeClassifierdef get_top_n_features(titanic_train_data_X, titanic_train_data_Y, top_n_features): # random forest rf_est = RandomForestClassifier(random_state=0) rf_param_grid = &#123;'n_estimators': [500], 'min_samples_split': [2, 3], 'max_depth': [20]&#125; rf_grid = model_selection.GridSearchCV(rf_est, rf_param_grid, n_jobs=25, cv=10, verbose=1) rf_grid.fit(titanic_train_data_X, titanic_train_data_Y) print('Top N Features Best RF Params:' + str(rf_grid.best_params_)) print('Top N Features Best RF Score:' + str(rf_grid.best_score_)) print('Top N Features RF Train Score:' + str(rf_grid.score(titanic_train_data_X, titanic_train_data_Y))) feature_imp_sorted_rf = pd.DataFrame(&#123;'feature': list(titanic_train_data_X), 'importance': rf_grid.best_estimator_.feature_importances_&#125;).sort_values('importance', ascending=False) features_top_n_rf = feature_imp_sorted_rf.head(top_n_features)['feature'] print('Sample 10 Features from RF Classifier') print(str(features_top_n_rf[:10])) # AdaBoost ada_est =AdaBoostClassifier(random_state=0) ada_param_grid = &#123;'n_estimators': [500], 'learning_rate': [0.01, 0.1]&#125; ada_grid = model_selection.GridSearchCV(ada_est, ada_param_grid, n_jobs=25, cv=10, verbose=1) ada_grid.fit(titanic_train_data_X, titanic_train_data_Y) print('Top N Features Best Ada Params:' + str(ada_grid.best_params_)) print('Top N Features Best Ada Score:' + str(ada_grid.best_score_)) print('Top N Features Ada Train Score:' + str(ada_grid.score(titanic_train_data_X, titanic_train_data_Y))) feature_imp_sorted_ada = pd.DataFrame(&#123;'feature': list(titanic_train_data_X), 'importance': ada_grid.best_estimator_.feature_importances_&#125;).sort_values('importance', ascending=False) features_top_n_ada = feature_imp_sorted_ada.head(top_n_features)['feature'] print('Sample 10 Feature from Ada Classifier:') print(str(features_top_n_ada[:10])) # ExtraTree et_est = ExtraTreesClassifier(random_state=0) et_param_grid = &#123;'n_estimators': [500], 'min_samples_split': [3, 4], 'max_depth': [20]&#125; et_grid = model_selection.GridSearchCV(et_est, et_param_grid, n_jobs=25, cv=10, verbose=1) et_grid.fit(titanic_train_data_X, titanic_train_data_Y) print('Top N Features Best ET Params:' + str(et_grid.best_params_)) print('Top N Features Best ET Score:' + str(et_grid.best_score_)) print('Top N Features ET Train Score:' + str(et_grid.score(titanic_train_data_X, titanic_train_data_Y))) feature_imp_sorted_et = pd.DataFrame(&#123;'feature': list(titanic_train_data_X), 'importance': et_grid.best_estimator_.feature_importances_&#125;).sort_values('importance', ascending=False) features_top_n_et = feature_imp_sorted_et.head(top_n_features)['feature'] print('Sample 10 Features from ET Classifier:') print(str(features_top_n_et[:10])) # GradientBoosting gb_est =GradientBoostingClassifier(random_state=0) gb_param_grid = &#123;'n_estimators': [500], 'learning_rate': [0.01, 0.1], 'max_depth': [20]&#125; gb_grid = model_selection.GridSearchCV(gb_est, gb_param_grid, n_jobs=25, cv=10, verbose=1) gb_grid.fit(titanic_train_data_X, titanic_train_data_Y) print('Top N Features Best GB Params:' + str(gb_grid.best_params_)) print('Top N Features Best GB Score:' + str(gb_grid.best_score_)) print('Top N Features GB Train Score:' + str(gb_grid.score(titanic_train_data_X, titanic_train_data_Y))) feature_imp_sorted_gb = pd.DataFrame(&#123;'feature': list(titanic_train_data_X), 'importance': gb_grid.best_estimator_.feature_importances_&#125;).sort_values('importance', ascending=False) features_top_n_gb = feature_imp_sorted_gb.head(top_n_features)['feature'] print('Sample 10 Feature from GB Classifier:') print(str(features_top_n_gb[:10])) # DecisionTree dt_est = DecisionTreeClassifier(random_state=0) dt_param_grid = &#123;'min_samples_split': [2, 4], 'max_depth': [20]&#125; dt_grid = model_selection.GridSearchCV(dt_est, dt_param_grid, n_jobs=25, cv=10, verbose=1) dt_grid.fit(titanic_train_data_X, titanic_train_data_Y) print('Top N Features Best DT Params:' + str(dt_grid.best_params_)) print('Top N Features Best DT Score:' + str(dt_grid.best_score_)) print('Top N Features DT Train Score:' + str(dt_grid.score(titanic_train_data_X, titanic_train_data_Y))) feature_imp_sorted_dt = pd.DataFrame(&#123;'feature': list(titanic_train_data_X), 'importance': dt_grid.best_estimator_.feature_importances_&#125;).sort_values('importance', ascending=False) features_top_n_dt = feature_imp_sorted_dt.head(top_n_features)['feature'] print('Sample 10 Features from DT Classifier:') print(str(features_top_n_dt[:10])) # merge the three models features_top_n = pd.concat([features_top_n_rf, features_top_n_ada, features_top_n_et, features_top_n_gb, features_top_n_dt], ignore_index=True).drop_duplicates() features_importance = pd.concat([feature_imp_sorted_rf, feature_imp_sorted_ada, feature_imp_sorted_et, feature_imp_sorted_gb, feature_imp_sorted_dt],ignore_index=True) return features_top_n , features_importance 上面的代码不需要看着害怕，其实无非就是调用一些神奇的函数而已，上面的代码就是在 多个模型中去寻找重要的特征，并且进行排序，为后面模型训练作出贡献。 依据我们筛选出的特征构建训练集和测试集但如果在进行特征工程的过程中，产生了大量的特征，而特征与特征之间会存在一定的相关性。太多的特征一方面会影响模型训练的速度，另一方面也可能会使得模型过拟合。所以在特征太多的情况下，我们可以利用不同的模型对特征进行筛选，选取出我们想要的前n个特征。 1234feature_to_pick = 30feature_top_n, feature_importance = get_top_n_features(titanic_train_data_X, titanic_train_data_Y, feature_to_pick)titanic_train_data_X = pd.DataFrame(titanic_train_data_X[feature_top_n])titanic_test_data_X = pd.DataFrame(titanic_test_data_X[feature_top_n]) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100Fitting 10 folds for each of 2 candidates, totalling 20 fits [Parallel(n_jobs=25)]: Done 13 out of 20 | elapsed: 13.7s remaining: 7.3s [Parallel(n_jobs=25)]: Done 20 out of 20 | elapsed: 19.2s finished Top N Features Best RF Params:&#123;'n_estimators': 500, 'min_samples_split': 3, 'max_depth': 20&#125; Top N Features Best RF Score:0.822671156004 Top N Features RF Train Score:0.979797979798 Sample 10 Features from RF Classifier 15 Name_length 0 Age 2 Fare 7 Sex_0 9 Title_0 8 Sex_1 27 Family_Size 3 Pclass 31 Ticket_Letter 11 Title_2 Name: feature, dtype: object Fitting 10 folds for each of 2 candidates, totalling 20 fits [Parallel(n_jobs=25)]: Done 13 out of 20 | elapsed: 10.3s remaining: 5.5s [Parallel(n_jobs=25)]: Done 20 out of 20 | elapsed: 14.9s finished Top N Features Best Ada Params:&#123;'n_estimators': 500, 'learning_rate': 0.01&#125; Top N Features Best Ada Score:0.81593714927 Top N Features Ada Train Score:0.820426487093 Sample 10 Feature from Ada Classifier: 9 Title_0 2 Fare 27 Family_Size 7 Sex_0 3 Pclass 28 Family_Size_Category_0 1 Cabin 8 Sex_1 15 Name_length 0 Age Name: feature, dtype: object Fitting 10 folds for each of 2 candidates, totalling 20 fits [Parallel(n_jobs=25)]: Done 13 out of 20 | elapsed: 9.8s remaining: 5.3s [Parallel(n_jobs=25)]: Done 20 out of 20 | elapsed: 14.2s finished Top N Features Best ET Params:&#123;'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 20&#125; Top N Features Best ET Score:0.828282828283 Top N Features ET Train Score:0.971941638608 Sample 10 Features from ET Classifier: 9 Title_0 8 Sex_1 7 Sex_0 15 Name_length 0 Age 2 Fare 1 Cabin 31 Ticket_Letter 11 Title_2 10 Title_1 Name: feature, dtype: object Fitting 10 folds for each of 2 candidates, totalling 20 fits [Parallel(n_jobs=25)]: Done 13 out of 20 | elapsed: 25.9s remaining: 13.9s [Parallel(n_jobs=25)]: Done 20 out of 20 | elapsed: 27.9s finished Top N Features Best GB Params:&#123;'n_estimators': 500, 'learning_rate': 0.1, 'max_depth': 20&#125; Top N Features Best GB Score:0.789001122334 Top N Features GB Train Score:0.996632996633 Sample 10 Feature from GB Classifier: 0 Age 2 Fare 15 Name_length 31 Ticket_Letter 9 Title_0 27 Family_Size 23 Pclass_2 3 Pclass 18 Fare_2 14 Title_5 Name: feature, dtype: object Fitting 10 folds for each of 2 candidates, totalling 20 fits [Parallel(n_jobs=25)]: Done 13 out of 20 | elapsed: 6.3s remaining: 3.3s [Parallel(n_jobs=25)]: Done 20 out of 20 | elapsed: 9.6s finished Top N Features Best DT Params:&#123;'min_samples_split': 4, 'max_depth': 20&#125; Top N Features Best DT Score:0.784511784512 Top N Features DT Train Score:0.959595959596 Sample 10 Features from DT Classifier: 9 Title_0 0 Age 2 Fare 15 Name_length 27 Family_Size 14 Title_5 26 Pclass_5 3 Pclass 31 Ticket_Letter 23 Pclass_2 Name: feature, dtype: object 上面就是对之前的一个函数进行的一个调整 用视图可视化不同算法筛选的特征排序： 1234567891011121314151617181920212223242526272829rf_feature_imp = feature_importance[:10]Ada_feature_imp = feature_importance[32:32+10].reset_index(drop=True)# make importances relative to max importancerf_feature_importance = 100.0 * (rf_feature_imp['importance'] / rf_feature_imp['importance'].max())Ada_feature_importance = 100.0 * (Ada_feature_imp['importance'] / Ada_feature_imp['importance'].max())# Get the indexes of all features over the importance thresholdrf_important_idx = np.where(rf_feature_importance)[0]Ada_important_idx = np.where(Ada_feature_importance)[0]# Adapted from Gradient Boosting regressionpos = np.arange(rf_important_idx.shape[0]) + .5plt.figure(1, figsize = (18, 8))plt.subplot(121)plt.barh(pos, rf_feature_importance[rf_important_idx][::-1])plt.yticks(pos, rf_feature_imp['feature'][::-1])plt.xlabel('Relative Importance')plt.title('RandomForest Feature Importance')plt.subplot(122)plt.barh(pos, Ada_feature_importance[Ada_important_idx][::-1])plt.yticks(pos, Ada_feature_imp['feature'][::-1])plt.xlabel('Relative Importance')plt.title('AdaBoost Feature Importance')plt.show() 模型融合前面已经训练了多个模型，这个时候就可以直接展开融合了。 常见的模型融合方法有：Bagging、Boosting、Stacking、Blending 常见的相关介绍，直接去看笔记中 Stacking框架融合: 这里我们使用了两层的模型融合，Level 1使用了：RandomForest、AdaBoost、ExtraTrees、GBDT、DecisionTree、KNN、SVM ，一共7个模型，Level 2使用了XGBoost使用第一层预测的结果作为特征对最终的结果进行预测。 Stacking框架是堆叠使用基础分类器的预测作为对二级模型的训练的输入。 然而，我们不能简单地在全部训练数据上训练基本模型，产生预测，输出用于第二层的训练。如果我们在Train Data上训练，然后在Train Data上预测，就会造成标签泄露。为了避免标签泄露，我们需要对每个基学习器使用K-fold，将K个模型对Valid Set的预测结果拼起来，作为下一层学习器的输入。 所以这里我们建立输出K-fold预测的方法： 1234567891011121314151617181920212223242526from sklearn.model_selection import KFold# Some useful parameters which will come in handy later onntrain = titanic_train_data_X.shape[0]ntest = titanic_test_data_X.shape[0]SEED = 0 # for reproducibilityNFOLDS = 7 # set folds for out-of-fold predictionkf = KFold(n_splits = NFOLDS, random_state=SEED, shuffle=False)def get_out_fold(clf, x_train, y_train, x_test): oof_train = np.zeros((ntrain,)) oof_test = np.zeros((ntest,)) oof_test_skf = np.empty((NFOLDS, ntest)) for i, (train_index, test_index) in enumerate(kf.split(x_train)): x_tr = x_train[train_index] y_tr = y_train[train_index] x_te = x_train[test_index] clf.fit(x_tr, y_tr) oof_train[test_index] = clf.predict(x_te) oof_test_skf[i, :] = clf.predict(x_test) oof_test[:] = oof_test_skf.mean(axis=0) return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1) 构建不同的基学习器，这里我们使用了RandomForest、AdaBoost、ExtraTrees、GBDT、DecisionTree、KNN、SVM 七个基学习器：（这里的模型可以使用如上面的GridSearch方法对模型的超参数进行搜索选择） 上面GridSearch就是对参数的搜索选择 1234567891011121314151617from sklearn.neighbors import KNeighborsClassifierfrom sklearn.svm import SVCrf = RandomForestClassifier(n_estimators=500, warm_start=True, max_features='sqrt',max_depth=6, min_samples_split=3, min_samples_leaf=2, n_jobs=-1, verbose=0)ada = AdaBoostClassifier(n_estimators=500, learning_rate=0.1)et = ExtraTreesClassifier(n_estimators=500, n_jobs=-1, max_depth=8, min_samples_leaf=2, verbose=0)gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.008, min_samples_split=3, min_samples_leaf=2, max_depth=5, verbose=0)dt = DecisionTreeClassifier(max_depth=8)knn = KNeighborsClassifier(n_neighbors = 2)svm = SVC(kernel='linear', C=0.025) 将pandas转换为arrays： 123x_train = titanic_train_data_X.values # Creates an array of the train datax_test = titanic_test_data_X.values # Creats an array of the test datay_train = titanic_train_data_Y.values 1234567rf_oof_train, rf_oof_test = get_out_fold(rf, x_train, y_train, x_test) # Random Forestada_oof_train, ada_oof_test = get_out_fold(ada, x_train, y_train, x_test) # AdaBoost et_oof_train, et_oof_test = get_out_fold(et, x_train, y_train, x_test) # Extra Treesgb_oof_train, gb_oof_test = get_out_fold(gb, x_train, y_train, x_test) # Gradient Boostdt_oof_train, dt_oof_test = get_out_fold(dt, x_train, y_train, x_test) # Decision Treeknn_oof_train, knn_oof_test = get_out_fold(knn, x_train, y_train, x_test) # KNeighborssvm_oof_train, svm_oof_test = get_out_fold(svm, x_train, y_train, x_test) # Support Vector 预测并提交文件。我们利用XGBoost，使用第一层预测的结果作为特征对最终的结果进行预测。 12345from xgboost import XGBClassifiergbm = XGBClassifier( n_estimators= 2000, max_depth= 4, min_child_weight= 2, gamma=0.9, subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread= -1, scale_pos_weight=1).fit(x_train, y_train)predictions = gbm.predict(x_test) 12StackingSubmission = pd.DataFrame(&#123;'PassengerId': PassengerId, 'Survived': predictions&#125;)StackingSubmission.to_csv('StackingSubmission.csv',index=False,sep=',') 最后的步骤就是验证了 验证：学习曲线在我们对数据不断地进行特征工程，产生的特征越来越多，用大量的特征对模型进行训练，会使我们的训练集拟合得越来越好，但同时也可能会逐渐丧失泛化能力，从而在测试数据上表现不佳，发生过拟合现象。 当然我们建立的模型可能不仅在预测集上表型不好，也很可能是因为在训练集上的表现就不佳，处于欠拟合状态。 所以我们通过学习曲线观察模型处于什么样的状态。从而决定对模型进行如何的操作。当然，我们把验证放到最后，并不是是这一步是在最后去做。对于我们的Stacking框架中第一层的各个基学习器我们都应该对其学习曲线进行观察，从而去更好地调节超参数，进而得到更好的最终结果。 123456789101112131415161718192021222324252627282930from sklearn.learning_curve import learning_curvedef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5), verbose=0): plt.figure() plt.title(title) if ylim is not None: plt.ylim(*ylim) plt.xlabel("Training examples") plt.ylabel("Score") train_sizes, train_scores, test_scores = learning_curve( estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes) train_scores_mean = np.mean(train_scores, axis=1) train_scores_std = np.std(train_scores, axis=1) test_scores_mean = np.mean(test_scores, axis=1) test_scores_std = np.std(test_scores, axis=1) plt.grid() plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r") plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g") plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score") plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score") plt.legend(loc="best") return plt 逐一观察不同模型的学习曲线 12345678910111213141516171819202122232425262728X = x_trainY = y_train# RandomForestrf_parameters = &#123;'n_jobs': -1, 'n_estimators': 500, 'warm_start': True, 'max_depth': 6, 'min_samples_leaf': 2, 'max_features' : 'sqrt','verbose': 0&#125;# AdaBoostada_parameters = &#123;'n_estimators':500, 'learning_rate':0.1&#125;# ExtraTreeset_parameters = &#123;'n_jobs': -1, 'n_estimators':500, 'max_depth': 8, 'min_samples_leaf': 2, 'verbose': 0&#125;# GradientBoostinggb_parameters = &#123;'n_estimators': 500, 'max_depth': 5, 'min_samples_leaf': 2, 'verbose': 0&#125;# DecisionTreedt_parameters = &#123;'max_depth':8&#125;# KNeighborsknn_parameters = &#123;'n_neighbors':2&#125;# SVMsvm_parameters = &#123;'kernel':'linear', 'C':0.025&#125;# XGBgbm_parameters = &#123;'n_estimators': 2000, 'max_depth': 4, 'min_child_weight': 2, 'gamma':0.9, 'subsample':0.8, 'colsample_bytree':0.8, 'objective': 'binary:logistic', 'nthread':-1, 'scale_pos_weight':1&#125; 123title = "Learning Curves"plot_learning_curve(RandomForestClassifier(**rf_parameters), title, X, Y, cv=None, n_jobs=4, train_sizes=[50, 100, 150, 200, 250, 350, 400, 450, 500])plt.show() 提交结果终于到达了87左右了，后面还是可以尝试一下在模型融合这里慢慢加强。 但是 后面就是无尽无尽的调整参数的过程咯]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[改善深层神经网络]]></title>
    <url>%2F2020%2F03%2F11%2F%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[深度学习的相关实践数据集合紧接着前面 关于 欠拟合和过拟合的情况，所以这个地方直接将数据集分成了，训练，验证，测试集 然后这几个集合之间的定义就是： 训练集（train set）：用训练集对算法或模型进行训练过程；验证集（development set）：利用验证集或者又称为简单交叉验证集（hold-out cross validation set）进行交叉验证，选择出最好的模型；测试集（test set）：最后利用测试集对模型进行测试，获取模型运行的无偏估计。 小数据时代在小数据量的时代，如：100、1000、10000的数据量大小，可以将data做以下划分： 无验证集的情况：70% / 30%；有验证集的情况：60% / 20% / 20%；通常在小数据量时代，以上比例的划分是非常合理的。 大数据时代但是在如今的大数据时代，对于一个问题，我们拥有的data的数量可能是百万级别的，所以验证集和测试集所占的比重会趋向于变得更小。 验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大能够验证大约2-10种算法哪种更好就足够了，不需要使用20%的数据作为验证集。如百万数据中抽取1万的数据作为验证集就可以了。 测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中1000条数据足以评估单个模型的效果。 100万数据量：98% / 1% / 1%；超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%） 注意 建议验证集和测试集来自于同一个分布，这样可以使得机器学习算法变得更快；如果不需要用无偏估计来评估模型的性能，则可以不需要测试集。 偏差、方差对应上面过拟合，与欠拟合的情况，关于如何界定的问题，也在相应的章节中有讲述，所以这里就不再过多赘述了。 只需要记住一个小小的总结即可： 如果训练集误差与验证集误差相差过大，那么一定是出现了过拟合的问题，方差过大 如果 训练集误差与验证集误差不大，但是 二者的数值较大，那么一定是出现欠拟合的问题，偏差过大。 解决上述问题的方法 是否存在High bias ?增加网络结构，如增加隐藏层数目；训练更长时间；寻找合适的网络架构，使用更大的NN结构； 是否存在High variance？获取更多的数据；正则化（ regularization）；寻找合适的网络结构； 在大数据时代，深度学习对监督式学习大有裨益，使得我们不用像以前一样太过关注如何平衡偏差和方差的权衡问题，通过以上方法可以使得再不增加另一方的情况下减少一方的值。 正则化（惩罚参数）利用正则化来解决High variance 的问题，正则化是在 Cost function 中加入一项正则化项，惩罚模型的复杂度。 那为什么正则化可以减少神经网络的过拟合情况呢 对于神经网络的 Cost function：加入正则化项，直观上理解，正则化因子lambd设置的足够大的情况下，为了使代价函数最小化，权重矩阵 weight 就会被设置为接近于0的值。则相当于消除了很多神经元的影响，那么图中的大的神经网络就会变成一个较小的网络。 当然上面这种解释是一种直观上的理解，但是实际上隐藏层的神经元依然存在，但是他们的影响变小了，便不会导致过拟合。 而下面则是一种 较好的数学解释，可以拿来参考借鉴： 这里还存在一种正则化的方式 Dropout正则化 Dropout（随机失活）就是在神经网络的Dropout层，为每个神经元结点设置一个随机消除的概率，对于保留下来的神经元，我们得到一个节点较少，规模较小的网络进行训练。 意思就是随机失活类型之类的 这里解释下为什么要有最后一步：a3 /= keep_prob 依照例子中的 keep_prob = 0.8 ，那么就有大约20%的神经元被删除了，也就是说 a3 中有20%的元素被归零了，在下一层的计算中有 z4 = w4 a3 + b4 ，所以为了不影响 Z4 的期望值，所以需要W4 a3 的部分除以一个keep_prob。 Inverted dropout 通过对“a3 /= keep_prob”,则保证无论 keep_prob 设置为多少，都不会对W4 * a3的期望值产生影响。 Notation：在测试阶段不要用dropout，因为那样会使得预测结果变得随机。 理解Dropout 另外一种对于Dropout的理解。 这里我们以单个神经元入手，单个神经元的工作就是接收输入，并产生一些有意义的输出，但是加入了Dropout以后，输入的特征都是有可能会被随机清除的，所以该神经元不会再特别依赖于任何一个输入特征，也就是说不会给任何一个输入设置太大的权重。 所以通过传播过程，dropout将产生和L2范数相同的收缩权重的效果。 对于不同的层，设置的keep_prob也不同，一般来说神经元较少的层，会设 keep_prob =1.0，神经元多的层，则会将keep_prob设置的较小。 dropout的一大缺点就是其使得 Cost function不能再被明确的定义，以为每次迭代都会随机消除一些神经元结点，所以我们无法绘制出每次迭代cost函数下降的图 其他正则化的方法数据增强，将一些数据进行一些维度意义上面的增强 归一化处理输入数据由图可以看出不使用归一化和使用归一化前后 Cost function 的函数形状会有很大的区别。 在不使用归一化的代价函数中，如果我们设置一个较小的学习率，那么很可能我们需要很多次迭代才能到达代价函数全局最优解；如果使用了归一化，那么无论从哪个位置开始迭代，我们都能以相对很少的迭代次数找到全局最优解。 提前停止数据等 如果神经网络过于深，那么就一定会发生 梯度消失的问题，所以这个地方就涉及到应用初始化去缓解梯度消失的问题 梯度检验下面用前面一节的方法来进行梯度检验。 不要在训练过程中使用梯度检验，只在debug的时候使用，使用完毕关闭梯度检验的功能；如果算法的梯度检验出现了错误，要检查每一项，找出错误，也就是说要找出哪个的值相差比较大；不要忘记了正则化项；梯度检验不能与dropout同时使用。因为每次迭代的过程中，dropout会随机消除隐层单元的不同神经元，这时是难以计算dropout在梯度下降上的代价函数J；在随机初始化的时候运行梯度检验，或许在训练几次后再进行。（没听懂大师这个点的意思？） 深度学习的优化算法这个地方很多东西 在pytorch里面已经封装好了，不需要自己去实现，但是对于这一章而言，需要弄清楚的就是，如何去用，如何去调整里面超参数 Mini-batch 梯度下降法对整个训练集进行梯度下降法的时候，我们必须处理整个训练数据集，然后才能进行一步梯度下降，即每一步梯度下降法需要对整个训练集进行一次处理，如果训练数据集很大的时候，如有500万或5000万的训练数据，处理速度就会比较慢。 但是如果每次处理训练数据的一部分，即用其子集进行梯度下降，则我们的算法速度会执行的更快。而处理的这些一小部分训练子集即称为Mini-batch。 对于普通的梯度下降法，一个epoch只能进行一次梯度下降；而对于Mini-batch梯度下降法，一个epoch可以进行Mini-batch的个数次梯度下降。 不同size大小的比较 普通的batch梯度下降法和Mini-batch梯度下降法代价函数的变化趋势，如下图所示： batch梯度下降： 对所有m个训练样本执行一次梯度下降，每一次迭代时间较长； Cost function 总是向减小的方向下降。 随机梯度下降： 对每一个训练样本执行一次梯度下降，但是丢失了向量化带来的计算加速； Cost function总体的趋势向最小值的方向下降，但是无法到达全局最小值点，呈现波动的形式。 Mini-batch梯度下降： 选择一个 size 的合适的size进行Mini-batch梯度下降，可以实现快速学习，也应用了向量化带来的好处； Cost function的下降处于前两者之间。 Mini-batch 大小的选择如果训练样本的大小比较小时，如 m &lt;= 2000 时 ——— 选择batch梯度下降法；如果训练样本的大小比较大时，典型的大小为： 2的次方 ；Mini-batch的大小要符合CPU/GPU内存。 指数加权平均这里主要有一个指数加权平均的关键函数： 因为，在计算当前时刻的平均值，只需要前一天的平均值和当前时刻的值，所以在数据量非常大的情况下，指数加权平均在节约计算成本的方面是一种非常有效的方式，可以很大程度上减少计算机资源存储和内存的占用。 指数加权平均的偏差修正 在我们执行指数加权平均的公式时，当beta = 0.98时，我们得到的并不是图中的绿色曲线，而是下图中的紫色曲线，其起点比较低。 动量（Momentum）梯度下降法前面介绍了一大啪啦听不懂的东西 实际上就是为后面的动量梯度下降法做贡献的 动量梯度下降的基本思想就是计算梯度的指数加权平均数，并利用该梯度来更新权重。 在我们优化 Cost function 的时候，以下图所示的函数图为例： 在利用梯度下降法来最小化该函数的时候，每一次迭代所更新的代价函数值如图中蓝色线所示在上下波动，而这种幅度比较大波动，减缓了梯度下降的速度，而且我们只能使用一个较小的学习率来进行迭代。 如果用较大的学习率，结果可能会如紫色线一样偏离函数的范围，所以为了避免这种情况，只能用较小的学习率。 但是我们又希望在如图的纵轴方向梯度下降的缓慢一些，不要有如此大的上下波动，在横轴方向梯度下降的快速一些，使得能够更快的到达最小值点，而这里用动量梯度下降法既可以实现，如红色线所示。 其最本质的解释 在对应上面的计算公式中，将Cost function想象为一个碗状，想象从顶部往下滚球，其中： 微分项 dw, db 想象为球提供的加速度；动量项 Vdw,Vdb 相当于速度；小球在向下滚动的过程中，因为加速度的存在使得速度会变快，但是由于 beta 的存在，其值小于1，可以认为是摩擦力，所以球不会无限加速下去。 RMSprop 算法除了上面所说的Momentum梯度下降法，RMSprop（root mean square prop）也是一种可以加快梯度下降的算法。 这里假设参数b的梯度处于纵轴方向，参数w的梯度处于横轴方向（当然实际中是处于高维度的情况），利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，如图中蓝色线所示，使其梯度下降的速度变得更快，如图绿色线所示。 在如图所示的实现中，RMSprop将微分项进行平方，然后使用平方根进行梯度更新，同时为了确保算法不会除以0，平方根分母中在实际使用会加入一个很小的值如 [公式] 。 Adam 优化算法Adam （Adaptive Moment Estimation）优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法。 这个弄懂的地方 实际上需要去看相关的数学证明才可以弄清楚 这里只介绍一些调试的办法 学习率衰减当这个地方使用学习率去衰减变化的时候，因为训练到后期的时候，如果再去使用大的学习率，容易造成不太好的影响 在我们利用 mini-batch 梯度下降法来寻找Cost function的最小值的时候，如果我们设置一个固定的学习速率 ，则算法在到达最小值点附近后，由于不同batch中存在一定的噪声，使得不会精确收敛，而一直会在一个最小值点较大的范围内波动，如下图中蓝色线所示。 但是如果我们使用学习率衰减，逐渐减小学习速率，在算法开始的时候，学习速率还是相对较快，能够相对快速的向最小值点的方向下降。但随着学习率的减小，下降的步伐也会逐渐变小，最终会在最小值附近的一块更小的区域里波动，如图中绿色线所示。 局部最优解建议在构造模型的时候多去尝试，因为可能在构造过程中达到了局部最优解，而不是全局最优解，所以需要初始值选取的得当，才可以。 但是，如果我们建立一个高维度的神经网络。通常梯度为零的点，并不是如左图中的局部最优点，而是右图中的鞍点（叫鞍点是因为其形状像马鞍的形状）。 在一个具有高维度空间的函数中，如果梯度为0，那么在每个方向，Cost function可能是凸函数，也有可能是凹函数。但如果参数维度为2万维，想要得到局部最优解，那么所有维度均需要是凹函数，其概率为特别特别小，可能性非常的小。也就是说，在低维度中的局部最优点的情况，并不适用于高维度，在梯度为0的点更有可能是鞍点，而不是局部最小值点。 在高纬度的情况下： 几乎不可能陷入局部最小值点； 处于鞍点的停滞区会减缓学习过程，利用如Adam等算法进行改善。 超参数的调试和Batch Norm超阐述的调试处理前面已经讲了很多超参数，这里就要集中进行一个处理过程 在机器学习领域，超参数比较少的情况下，我们之前利用设置网格点的方式来调试超参数；但在深度学习领域，超参数较多的情况下，不是设置规则的网格点，而是随机选择点进行调试。这样做是因为在我们处理问题的时候，是无法知道哪个超参数是更重要的，所以随机的方式去测试超参数点的性能，更为合理，这样可以探究更超参数的潜在价值。 为超参数选择合适的范围Scale均匀随机 在超参数选择的时候，一些超参数是在一个范围内进行均匀随机取值，如隐藏层神经元结点的个数、隐藏层的层数等。但是有一些超参数的选择做均匀随机取值是不合适的，这里需要按照一定的比例在不同的小范围内进行均匀随机取值，以学习率的选择为例，在 0.001 到 1 范围内进行选择： 如上图所示，如果在0.001～1的范围内进行进行均匀随机取值，则有90%的概率 选择范围在0.1～1之间，而只有10%的概率才能选择到0.001～0.1之间，显然是不合理的。 所以在选择的时候，在不同比例范围内进行均匀随机取值，如 0.0001～0.001 、0.001～0.01、0.01～0.1， 0.1～1范围内选择。 同样，在使用指数加权平均的时候，超参数beta 也需要用上面这种方向进行选择。 超参数调试实践—Pandas vs. Caviar不要看名字起的这么高端，其实就是一句话在超参数调试的实际操作中，我们需要根据我们现有的计算资源来决定以什么样的方式去调试超参数，进而对模型进行改进。下面是不同情况下的两种方式： 在计算资源有限的情况下，使用第一种，仅调试一个模型，每天不断优化；在计算资源充足的情况下，使用第二种，同时并行调试多个模型，选取其中最好的模型。 网络中激活值的归一化在Logistic Regression 中，将输入特征进行归一化，可以加速模型的训练。那么对于更深层次的神经网络，我们是否可以归一化隐藏层的输出al或者经过激活函数前的zl ，以便加速神经网络的训练过程？答案是肯定的。 常用的方式是将隐藏层的经过激活函数前的zl进行归一化。 比如卷积网络和RNN中如果应用这个的化，那么就会造成不需要bias的情况，因为其已经将bias的情况给剔除了。 这里不太需要去弄清楚其的底层实现，pytorch已经将其封装好了，可以直接去使用了 可以直接加入到输入函数和激活函数之间就可以了 Batch Norm 起作用的原因First Reason首先Batch Norm 可以加速神经网络训练的原因和输入层的输入特征进行归一化，从而改变Cost function的形状，使得每一次梯度下降都可以更快的接近函数的最小值点，从而加速模型训练过程的原理是有相同的道理。 只是Batch Norm 不是单纯的将输入的特征进行归一化，而是将各个隐藏层的激活函数的激活值进行的归一化，并调整到另外的分布。 Second ReasonBatch Norm 可以加速神经网络训练的另外一个原因是它可以使权重比网络更滞后或者更深层。 下面是一个判别是否是猫的分类问题，假设第一训练样本的集合中的猫均是黑猫，而第二个训练样本集合中的猫是各种颜色的猫。如果我们将第二个训练样本直接输入到用第一个训练样本集合训练出的模型进行分类判别，那么我们在很大程度上是无法保证能够得到很好的判别结果。 这是因为第一个训练集合中均是黑猫，而第二个训练集合中各色猫均有，虽然都是猫，但是很大程度上样本的分布情况是不同的，所以我们无法保证模型可以仅仅通过黑色猫的样本就可以完美的找到完整的决策边界。第二个样本集合相当于第一个样本的分布的改变，称为：Covariate shift。 上面的意思 说人话就是 每一个集合的协和特征得出来，进行归纳即可，意思就是保存了数据之间的均值和方差，不会被下一个不一样的集合所影响 Batch Norm 正则化效果Batch Norm还有轻微的正则化效果。 这是因为在使用Mini-batch梯度下降的时候，每次计算均值和偏差都是在一个Mini-batch上进行计算，而不是在整个数据样集上。这样就在均值和偏差上带来一些比较小的噪声。那么用均值和偏差计算得到的 Zl 也将会加入一定的噪声。 所以和Dropout相似，其在每个隐藏层的激活值上加入了一些噪声，（这里因为Dropout以一定的概率给神经元乘上0或者1）。所以和Dropout相似，Batch Norm 也有轻微的正则化效果。 这里引入一个小的细节就是，如果使用Batch Norm ，那么使用大的Mini-batch如256，相比使用小的Mini-batch如64，会引入跟少的噪声，那么就会减少正则化的效果。 在测试数据上使用 Batch Norm Softmax 回归在多分类问题中，有一种 logistic regression的一般形式，叫做Softmax regression。Softmax回归可以将多分类任务的输出转换为各个类别可能的概率，从而将最大的概率值所对应的类别作为输入样本的输出类别。 计算公式 下图是Softmax的公式以及一个简单的例子： 训练 Sotfmax 分类器为什么叫做Softmax？我们以前面的例子为例， 通常我们判定模型的输出类别，是将输出的最大值对应的类别判定为该模型的类别，也就是说最大值为的位置1，其余位置为0，这也就是所谓的“hardmax”。而Sotfmax将模型判定的类别由原来的最大数字5，变为了一个最大的概率0.842，这相对于“hardmax”而言，输出更加“soft”而没有那么“hard”。 Sotfmax回归 将 logistic回归 从二分类问题推广到了多分类问题上。说白了与全链接层类似。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑回归--深度学习网络雏型]]></title>
    <url>%2F2020%2F03%2F10%2F%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%BB%9C%E9%9B%8F%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[逻辑回归前面有讲过，相应的线性回归方程，一般用在对于数据的拟合和预测上，甚至还是可以放下多维度的数字。 而这里要总结的就是 逻辑回归模型，虽然这里命名为回归，其实是一个分类问题。 比如邮件的归类，以及在线的资源判断，或者是医学上面的肿瘤 良性以及恶性的判断。 一般很常用的 分类函数里面有 sigmoid函数，或者深度学习中的Tanh 另外在机器学习中，逻辑回归，还负责一类问题，就是将多个数据群进行一个有效的划分，如果拟合的函数 太过于欠拟合的话，考虑采用复杂的函数来拟合 甚至还会存在非线性的分界线情况，就像如下： 目前这个地方只会去介绍一下 二元分类的问题，后面再去涉及到多元分类的问题 另外 关于其梯度下降的相关知识点，由于pytorch框架已经给封装好了，所以这里不多在赘述了，与前面的线性回归的梯度下降类似，就是换了一个方程而已 另外，在机器学习的课程李，给出了一对多的分类方式，如果这样分类的话，每次只看一种数据，并且将其与所有的物质进行相反的链接 就像下面的图所示： 这里又提到一个过拟合的概念，这个概念也是在后面机器学习甚至是深度学习中反复提到的，处理过拟合的方法，这个具体就在后面说，这里只会提到一点点。 具体就两种办法，要么正则化，要么就直接减少特征数（机器学习数据拟合中的特征是自己去设置的） 机器学习中 过渡到深度学习神经网络的构建是直接从非线性回归问题，直接去分类。 上面的每一个节点都是相同的运算（拟合运算 + 激活函数） 在后面深度学习中 这个是分开的。 正是因为有神经网络这样的结构在，正好就可以满足多元分类，最后输出的节点就可以来判断出 多个分类对象。（注意，这里 机器学习课程上面讲述的是hardmax是硬性分类，而一般采用的是softmax 求出概率而不是直接得出结果） 神经网络首先 先必须注意一点，输入到神经网络中数据的形状 一定是 batch_size * n(特征) 基于上面 逻辑回归，梯度下降，前向传播，反向传播，构建神经网络 下面需要弄清楚的有一点就是 python的notation 虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape()函数来对矩阵设定所需要进行计算的维度，这是个好的习惯； 如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。 其实也可以在pytorch中使用view来进行一个更改，这里也不多赘述了，因为毕竟是基础中的基础。 浅层网络除输入层之外每层的计算输出可由下图总结出： 其中，每个结点都对应这两个部分的运算，z运算和a运算。 在编程中，我们使用向量化去计算神经网络的输出： 假定在m个训练样本的神经网络中，计算神经网络的输出，用向量化的方法去实现可以避免在程序中使用for循环，提高计算的速度。 向量化，说白了就是线性代数的另外一种说法而已 另外需要纠结的是 激活函数的选择： sigmoid函数和tanh函数比较： 隐藏层：tanh函数的表现要好于sigmoid函数，因为tanh取值范围为 -1～+1 ，输出分布在0值的附近，均值为0，从隐藏层到输出层数据起到了归一化（均值为0）的效果。输出层：对于二分类任务的输出取值为 0～1 ，故一般会选择sigmoid函数。然而sigmoid和tanh函数在当 z 很大的时候，梯度会很小，在依据梯度的算法中，更新在后期会变得很慢。在实际应用中，要使 [公式] 尽可能的落在0值附近。 ReLU弥补了前两者的缺陷，当 z 时，梯度始终为1，从而提高神经网络基于梯度算法的运算速度。然而当 [公式] 时，梯度一直为0，但是实际的运用中，该缺陷的影响不是很大。 Leaky ReLU保证在 z &lt; 0 的时候，梯度仍然不为0。 在选择激活函数的时候，如果在不知道该选什么的时候就选择ReLU，当然也没有固定答案，要依据实际问题在交叉验证集合中进行验证分析。 对于神经网络中的梯度下降法 就是直接用框架就可以去解决。 最后，初始化问题会在后面优化神经网络的办法中详细的去讲述，这里只是随机初始化，是最简单的一种初始化办法 如果在初始时，两个隐藏神经元的参数设置为相同的大小，那么两个隐藏神经元对输出单元的影响也是相同的，通过反向梯度下降去进行计算的时候，会得到同样的梯度大小，所以在经过多次迭代后，两个隐藏层单位仍然是对称的。无论设置多少个隐藏单元，其最终的影响都是相同的，那么多个隐藏神经元就没有了意义。 在初始化的时候， W 参数要进行随机初始化， b 则不存在对称性的问题它可以设置为0。 以2个输入，2个隐藏神经元为例： 12W = np.random.rand((2,2))* 0.01b = np.zero((2,1)) 这里我们将W的值乘以0.01是为了尽可能使得权重W初始化为较小的值，这是因为如果使用sigmoid函数或者tanh函数作为激活函数时，W比较小，则 Z = WX + b所得的值也比较小，处在0的附近，0点区域的附近梯度较大，能够大大提高算法的更新速度。而如果W设置的太大的话，得到的梯度较小，训练过程因此会变得很慢。 ReLU和Leaky ReLU作为激活函数时，不存在这种问题，因为在大于0的时候，梯度均为1。 深度网络在深度网络中，因为现在有框架可以去帮助coding，以及集成好的相关操作但是自己需要注意的是四点 矩阵的维度，一定要在神经网络里面对应好 深度学习的一些建构好的模型，比如后面将要学习到的CNN 以及 RNN 这都是后面将会学习到的 前向传播，以及反向传播的时候不要写错，虽然现在有框架帮忙，可以减少很多体力活，但是需要注意的是在构建自己模型的时候需要去好好深思一下 参数，超参数。 这估计就是深度学习中最核心的话题了，因为基本上一大部分时间都回去调整一下参数， 以上就是从逻辑回归到达 深度学习基础的内容，下一篇博客就会主要讲在构建深度学习的过程中，需要去改善，优化。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep learning of Structuring Machine Learning Projects]]></title>
    <url>%2F2020%2F03%2F06%2FDeep-learning-of-Structuring-Machine-Learning-Projects%2F</url>
    <content type="text"><![CDATA[首先声明 本篇所涉及到的知识点 全部来自于 Courase deeplearning.ai Structuring Machine Learning Projects week one —- week two 这一门课没有太多的实践内容，帮助构建自己的机器学习项目，错误分析已经相关优化，已经调整参数，介绍一些常用的策略，也算是深度学习中非常重要的课程了。 Orthogonalization（正交化）我们在机器学习模型建立的整个流程中，我们需要根据不同部分反映的问题，去做相应的调整，从而更加容易地判断出是在哪一个部分出现了问题，并做相应的解决措施。 正交化或正交性是一种系统设计属性，其确保修改算法的指令或部分不会对系统的其他部分产生或传播副作用。 相互独立地验证使得算法变得更简单，减少了测试和开发的时间。 而正交化表现在四个方面： 系统在训练集上表现的好 否则使用更大的神经网络、更好的优化算法 系统在开发集上表现的好 否则使用正则化、更大的训练集 系统在测试集上表现的好 否则使用更大的开发集 在真实的系统环境中表现的好 否则修改开发测试集、修改代价函数 setting your goal(单一数字评估指标)在训练机器学习的模型的时候，无论是调整超参数，还是尝试更好的办法，为你的目标设置一个评估指标，这样有利于你在这个方向上面前进 在二分类问题之中，通过预测可以得到真实值以及下面的预测值的表: 下面就是指标的计算方法，一般都是用这个来对付二元分类问题 那么 如果在多元问题的分类上面呢？如果仅仅是上面的查准率以及查全率的化反而不太准确。 如果是多元问题的化，那么就采用地区的平均值来对模型效果进行评估。 该模型在各个地区有着不同的表现，这里用地区平均值对模型效果进行评估的化，反而会显示的性能好一点。 满足和优化指标 训练、开发、测试集 训练、开发、测试集的设置会对产品带来非常大的影响 在选择开发集和测试集时要使二者来自同一分布，且从所有数据中随机选取 所选择的开发集和测试集中的数据，要与未来想要或者能够得到的数据类似，即模型数据和未来数据要具有相似性 设置的测试集只要足够大，使其能够在过拟合的系统中给出高方差的结果就可以，也许10000左右的数目足够 设置开发集只要足够使其能够检测不同算法、不同模型之间的优劣差异就可以，百万大数据中1%的大小就足够 总之 只需要记住三者之间的比例，一般较小的数据中，训练60% 然后开发、测试占%20如果是深度学习，大数据的项目，那么训练980000:10000:10000 这样的比例就行了 训练集 训练模型开发集 选取模型，以及模型调优测试集 选择解决问题最适合的模型有的时候没有测试集，直接用在了测试集中 根据需要改变指标在针对某一问题我们设置开发集和评估指标后，这就像把目标定在某个位置，后面的过程就聚焦在该位置上。但有时候在这个项目的过程中，可能会发现目标的位置设置错了，所以要移动改变我们的目标。 比如课程中举出的相应的例子 评估指标：分类错误率算法A： 3% 错误率算法B： 5% 错误率 这样来看，算法A的表现更好。但是在实际的测试中，算法A可能因为某些原因，将很多色情图片分类成了猫。所以当我们在线上部署的时候，算法A会给爱猫人士推送更多更准确的猫的图片（因为其误差率只有 3% ），但同时也会给用户推送一些色情图片，这是不能忍受的。所以，虽然算法A的错误率很低，但是它却不是一个好的算法。 这个时候我们就需要改变开发集、测试集或者评估指标。 假设开始我们的评估指标如下： 该评估指标对色情图片和非色情图片一视同仁，但是我们希望，分类器不会错误将色情图片标记为猫。 修改的方法，在其中加入权重w ： 总结来说就是：如果评估指标无法正确评估算法的排名，则需要重新定义一个新的评估指标。 与人类表现进行比较假设针对两个问题分别具有相同的训练误差和交叉验证误差，如下所示： 对于左边的问题，人类的误差为 1% ，对于右边的问题，人类的误差为 7.5%。 对于某些任务如计算机视觉上，人类能够做到的水平和贝叶斯误差相差不远。（这里贝叶斯误差指最好的分类器的分类误差，也就是说没有分类器可以做到100%正确）。这里将人类水平误差近似为贝叶斯误差。 左边的例子： 8% 与 1% 差距较大主要着手减少偏差，即减少训练集误差和人类水平误差之间的差距，来提高模型性能。 右边的例子： 8% 与 7.5% 接近主要着手减少方差，即减少开发集误差和测试集误差之间的差距，来提高模型性能。 对人类水平误差有一个大概的估计，可以让我们去估计贝叶斯误差，这样可以让我们更快的做出决定：减少偏差还是减少方差。 而这个决策技巧通常都很有效果，直到系统的性能开始超越人类，那么我们对贝叶斯误差的估计就不再准确了，再从减少偏差和减少方差方面提升系统性能就会比较困难了。 如果二者与人类表现相差过大，那么应该改善偏差，如果训练集与开发集相差过大，那么应该改善方差 改善模型的表现根据课程上面提到的例子，以及进行的总结来看 减少偏差的办法： 训练更大的模型 训练更长时间、训练更好的优化算法（Momentum、RMSprop、Adam） 寻找更好的网络架构（RNN、CNN）、寻找更好的超参数 减少方差的办法： 收集更多的数据 正则化（L2、dropout、数据增强） 寻找更好的网络架构（RNN、CNN）、寻找更好的超参数 误差分析当我们在训练一个模型的时候，如一个猫和狗分类模型，最终得到了90%的精确度，即有10%的错误率。所以我们需要对模型的一些部分做相应调整，才能更好地提升分类的精度。 如果不加分析去做，可能几个月的努力对于提升精度并没有作用。所以一个好的误差分析的流程就相当重要。 下面就是错误分析的样例 收集错误样例在开发集（测试集）中，获取大约100个错误标记的例子，并统计其中有多少个是狗。 假设一种情况是100个数据中，有5个样例是狗，那么如果我们对数据集的错误标记做努力去改进模型的精度，那么可以提升的上限就是 5%，即仅仅可以达到 95% 的准确率，这有时称为性能上限。那么这种情况下，可能这样耗时的努力方向就不是很值得的一件事情。 另外一种假设是100个数据中，有50多个样例是狗，那么这种情况下，我们去改进数据集的错误标记，就是一个比较值得的改进方向，可以将模型的精确度提升至 95% 。 并行分析 修改那些被分类成猫的狗狗图片标签 修改那些被错误分类的大型猫科动物，如：狮子，豹子等 提升模糊图片的质量。 为了并行的分析，建立表格来进行。以单个错误分类样本为对象，分析每个样本错误分类的原因。 最后，统计错误类型的百分比，这个分析步骤可以给我们一个粗略的估计，让我们大致确定是否值得去处理每个不同的错误类型。 清楚错误标记的样本下面还是以猫和狗分类问题为例子，来进行分析。如下面的分类中的几个样本：（来源于视频中的样例） 情况一： 深度学习算法对训练集中的随机误差具有相当的包容性。 只要我们标记出错的例子符合随机误差，如：做标记的人不小心错误，或按错分类键。那么像这种随机误差导致的标记错误，一般来说不管这些误差可能也没有问题。 情况二： 虽然深度学习算法对随机误差具有很好的包容性，但是对于系统误差就不是这样了。 如果做标记的人一直把如例子中的白色的狗标记成猫，那么最终导致我们的分类器就会出现错误。 dev、test集中错误标记的情况： 如果在开发集和测试集中出现了错误标记的问题，我们可以在误差分析的过程中，增加错误标记这一原因，再对错误的数据进行分析，得出修正这些标记错误的价值。 修正开发、测试集上面的错误样例 对开发集和测试集上的数据进行检查，确保他们来自于相同的分布。使得我们以开发集为目标方向，更正确地将算法应用到测试集上。 考虑分类正确的成本 训练集和开发集 来自不同的分布 搭建系统 设置开发、测试集和优化指标（确定方向） 快速地建立基本的系统 使用偏差方差分析、误差分析去确定后面步骤的优先步骤 总的来说，如果我们想建立自己的深度学习系统，我们就需要做到：快速的建立自己的基本系统，并进行迭代。而不是想的太多，在一开始就建立一个非常复杂，难以入手的系统。 不同分布上的训练以及测试在深度学习的时代，因为需求的数据量非常大，现在很多的团队，使用的训练数据都是和开发集和测试集来自不同的分布。 下面是一些处理训练集和测试集存在差异的最佳的做法。以前一周中的猫的分类问题为例： 我们可以从网上获取大量的高清晰的猫的图片去做分类，如200000张，但是只能获取少量利用手机拍摄的不清晰的图片，如10000张。但是我们系统的目的是应用到手机上做分类。 也就是说，我们的训练集和开发集、测试集来自于不同的分布。 方法一： 将两组数据合并到一起，总共得到21万张图片样本。将这些样本随机分配到训练、开发、测试集中。 好处：三个集合中的数据均来自于同一分布；坏处： 我们设立开发集的目的是瞄准目标，而现在我们的目标绝大部分是为了去优化网上获取高清晰度的照片，而不是我们真正的目标。 该方法不是一个好的方法，不推荐。 方法二： 训练集均是来自网上下载的20万张高清图片，当然也可以加上5000张手机非高清图片；对于开发和测试集都是手机非高清图片。 好处：开发集全部来自手机图片，瞄准目标；坏处：训练集和开发、测试集来自不同的分布。 从长期来看，这样的分布能够给我们带来更好的系统性能。 不同分布上的方差与偏差通过估计学习算法的偏差和方差，可以帮助我们确定接下来应该优先努力的方向。但是当我们的训练集和开发、测试集来自不同的分布时，分析偏差和方差的方式就有一定的不同。 方差和分布原由分析 以猫分类为例，假设以人的分类误差 0% 作为贝叶斯误差。若我们模型的误差为 Training error： 1%Dev error： 10% 如果我们的训练集和开发、测试集来自相同的分布，那么我们可以说模型存在很大的方差问题。但如果数据来自不同的分布，那么我们就不能下这样的定论了。 那么我们如何去确定是由于分布不匹配的问题导致开发集的误差，还是由于算法中存在的方差问题所致？ 设立“训练开发集” 训练开发集，其中的数据和训练数据来自同一分布，但是却不用于训练过程。 如果最终，我们的模型得到的误差分别为： Training error： 1%Training-dev error： 9%Dev error： 10%那么，由于训练开发集尽管和训练集来自同一分布，但是却有很大的误差， 模型无法泛化到同分布的数据，那么说明我们的模型存在方差问题。 但如果我们的模型得到的误差分别为： Training error： 1%Training-dev error： 1.5%Dev error： 10% 现在就可以明确看出来，前者是模型存在方差问题，而后者可能就是分布不匹配导致的问题 分布不同的偏差方差分析 通过：Human level、Training set error、Training-dev set error、Dev error、Test error 之间误差的大小，可以分别得知我们的模型，需要依次在：可避免的偏差、方差、数据分布不匹配、开发集的或拟合程度，这些方面做改进。 通常情况下来说，通过不同的集合上的误差分析，我们得出的结果会是中间一列误差由小变大，即误差上升的情况。但是也有一定的可能会出现右边一列误差在开发测试集上又表现的好的情况。 下面通过一个后视镜语音检测的例子来说明。我们以该例子建立更加一般的表格。 其中，横向分别是：普通语音识别数据、后视镜语音识别数据；纵向分别是：Human level、训练数据误差、未训练数据误差。表格中不同的位置分别代表不同的数据集。 通常情况下，我们分析误差会是一个递增的情况，但是对于我们的模型，在后视镜语音识别的数据数据上，可能已经可以达到人类水平误差的6%了，而最终的开发测试集也会6%的误差，要比训练误差和训练开发误差都要小。所以如果遇到这种情况，就要利用上表进行分析。 解决数据分布不匹配问题如果通过上一节的误差分析，我们可以得知，模型最终在开发和测试集上的误差最终是由于数据分布不匹配而导致。那么这样的情况下如何解决？ 进行人工误差分析，尝试去了解训练集和开发测试集的具体差异在哪里。如：噪音等；尝试把训练数据变得更像开发集，或者收集更多的类似开发集和测试集的数据，如增加噪音； 迁移学习将从一个任务中学到的知识，应用到另一个独立的任务中。 迁移学习适合以下场合：迁移来源问题有很多数据，但是迁移目标问题却没有那么多的数据。 假设图像识别任务中有1百万个样本，里面的数据相当多；但对与一些特定的图像识别问题，如放射科图像，也许只有一百个样本，所以对于放射学诊断问题的数据很少。所以从图像识别训练中学到的很多知识可以迁移，来帮助我们提升放射科识别任务的性能。 同样一个例子是语音识别，可能在普通的语音识别中，我们有庞大的数据量来训练模型，所以模型从中学到了很多人类声音的特征。但是对于触发字检测任务，可能我们拥有的数据量很少，所以对于这种情况下，学习人类声音特征等知识就显得相当重要。所以迁移学习可以帮助我们建立一个很好的唤醒字检测系统。 其的意义就在于 任务A和任务B有着相同的输入；任务A所拥有的数据要远远大于任务B（对于更有价值的任务B，任务A所拥有的数据要比B大很多）；任务A的低层特征学习对任务B有一定的帮助。 多任务学习与迁移学习的串行学习方式不同，在多任务学习中，多个任务是并行进行学习的，同时希望各个任务对其他的任务均有一定的帮助。 假设在自动驾驶的例子中，我们需要检测的物体很多，如行人、汽车、交通灯等等。 对于现在的任务，我们的目标值变成了一个向量的形式向量中的每一个值代表检测到是否有如行人、汽车、交通灯等，一张图片有多个标签。 模型的神经网络结构如下图所示： 这个问题的cost函数为 对于这样的问题，我们就是在做多任务学习，因为我们建立单个神经网络，来解决多个问题。 特定的对于一些问题，例如在我们的例子中，数据集中可能只标注了部分信息，如其中一张只标注了人，汽车和交通灯的标识没有标注。那么对于这样的数据集，我们依旧可以用多任务学习来训练模型。当然要注意这里Loss function求和的时候，只对带0、1标签的 j 进行求和。 多任务学习有意义的情况： 如果训练的一组任务可以共用低层特征；通常，对于每个任务大量的数据具有很大的相似性；（如，在迁移学习中由任务A“100万数据”迁移到任务B“1000数据”；多任务学习中，任务多的，每个任务均有1000个数据，合起来就有1000n个数据，共同帮助任务的训练）可以训练一个足够大的神经网络并同时做好所有的任务。 端到端深度学习端到端学习的定义： 相对于传统的一些数据处理系统或者学习系统，它们包含了多个阶段的处理过程，而端到端的深度学习则忽略了这些阶段，用单个神经网络来替代。 语音识别例子： 在少数据集的情况下传统的特征提取方式可能会取得好的效果；如果在有足够的大量数据集情况下，端到端的深度学习会发挥巨大的价值。 优缺点 优点：端到端学习可以直接让数据“说话”；所需手工设计的组件更少。缺点：需要大量的数据；排除了可能有用的手工设计组件。应用端到端学习的 Key question：是否有足够的数据能够直接学习到从 x 映射到 y 的足够复杂的函数。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning: Programming Exercise 1: Linear Regression]]></title>
    <url>%2F2020%2F01%2F20%2FMachine-Learning-Programming-Exercise-1-Linear-Regression%2F</url>
    <content type="text"><![CDATA[知识梗概这一周首先一开始就直接介绍，机器学习以及深度学习的相关概念，介绍了两个概念 一个是监督学习，另一个就是非监督学习，简要的区分了上述两种基本学习的形式。 以下重点关注了线性回归，分为了两个部分来讲解，首先是一个参数的线性回归方程，另外一个就是多个参数的线性回归方程。 机器学习的介绍总的来说，简而言之就是通过数据来预测，识别，分类。 （目前自己所能接触到的地方） 监督学习 房价的预测，通过数据来整合出特征量，然后模拟出函数（假设），最后通过给出的特征量来得出房价 癌症肿瘤检测，通过数据来根据肿瘤大小，进行一个分类，然后下次预测检测肿瘤大小判断良性或者恶性。 总结： 监督学习就是每一个数据都会有一个结果量（标签量）来和其他数据进行区分，比如房价的特征量最终的结果是房价的多少，肿瘤的大小决定了是否为良性。 需要一个结果标签量 非监督学习 人群分类，天文数据分析，市场比重分析 这一类的数据不需要结果标签量来区分彼此，每一个其他量没有其他的分别。主要用于没有区分的数据，进行相互组合及分类。 线性回归线性回归属于监督学习。 线性回归一个参数具体的步骤就是 所以接下来的步骤就是要得出这个假设函数。 所以接下来引出了cost function （代价函数） 现在已经得出了代价函数，接下来就是需要通过使代价函数最小来模拟出假设函数。 Gradient descent（梯度下降） 就像下图一样可以直接得出 梯度下降的算法如下图所示 注意注意 梯度下降算法 必须要同时进行，如果没有同时进行，那么不算数。 并且在$\alpha$的选择上，一定要适合，不然的话就会造成以下的后果，不过一般这种情况题目会提前给予相应的情况。 最终将上述两者结合起来 梯度下降算法如下 以上就被称为：“Batch” Gradient Descent。（后面的章节会着重讲到） 线性回归多个参数由于之前 只有一个参数就能够模拟出相应的假设，但是现在有更复杂的徒刑，需要更多的参数 就想着样子： 所以更改下来 新的梯度下降算法，便成为了这个： 参数缩放以及归一化由于多个参数之后，有的特征量与其他的特征量相比，过于大了，所以现在需要采用的是 参数缩放将参数除以其的范围，限制在0到1之间。 归一化 减去平均值 然后再除上最大范围 正确的选择\alpha的值 选择参数的时候可以灵活一点 就想这样 Normal Equation 第二种计算线性回归的方法 作业要求作业就是要求使用matlab 运用线性代数的知识，来模拟线性回归，已经上传到github上面，这里就不再重复叙述了。后面有时间，使用pytorch来重新练习一遍。 ·]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[告别2019，初遇2020]]></title>
    <url>%2F2020%2F01%2F01%2F%E5%91%8A%E5%88%AB2019%EF%BC%8C%E5%88%9D%E9%81%872020%2F</url>
    <content type="text"><![CDATA[2019年有很多遗憾，有很多没有达成的目标，曾经以为特别重要的东西，随着时间流逝，反而觉得没有那么重要了，曾经消极的看待世界，沉迷于世界的阴霾，绝望，无奈，以及看不到生活的希望，开始质疑生活的初心。一次又一次的被打击自信心，又一次又一次进行了信心的重塑。 在2019年 参加过很多辩论赛，打过acm，蓝桥杯，去过北京，去过其他的各大高校，同时也遇见过形形色色的很多人，感谢这些出现在我生命里的人，是他们让我们知道人生的多种可能性，也是他们让我不再纠结于自己的人生不能够在多元化迈进。 曾经觉得自己的一生一定是精彩的一生，曾经觉得自己是世界上最独一无二的人，只不过还没有觉醒发力，曾经觉得自己能做很多其他常人做不到的事情。 到最后才发现自己可能真的是一个普通人，平凡的家庭，平凡的经历，以及平凡的生活，以前会觉得这种思想是消极的懦弱的想法，但是现在只是觉得 早点认清事实，也许可以为平凡的生活增添一些不平凡的地方，就像是疲惫的平凡生活中增添几丝无限向往的英雄梦想。 2019年又很多从2018年继承下来的期望，以前的以前觉得世界很大，大到自己无法想象的程度，恐惧，无知有的时候真的会占据一大半你对这个世界的想象。有的时候其实走向未来最大的阻力真的可能就是自己。 也许真的应了那句话，奥力给。 虽然迈向2020年之前的前几天，还陷在无数考试和实验报告中，自己也曾经抑郁过一个星期不怎么起床。不过，那都是过去了，我相信未来的一年，一定是充满朝阳的一年。 任何情绪都有存在的必要，任何感觉都有被诉说的可能，任何需求都应该有发泄的可能，我自己不再阻塞，不再自闭，不再责怪自己，拥抱希望，相信时间会给你所有想要的，才是迈向人生终极梦想的道路。 现在是6点43分，跟喜欢狼人杀的同号打了一晚上的狼人杀游戏，大家有的睡着了，有的还在打游戏，真的很庆幸有一群志趣相同的朋友陪着自己度过这些天的紧张生活。 狼人杀，希望新的一年爆爆爆吧。 也许2020年会遭受很多痛苦，会有很多时间花在怀疑自己这个过程中，也许会对生活失去原本的热心。真的很害怕自己会最终成为失去光华的人，就像游戏蔚蓝一样，如果真的爬不到山顶，真的完成不了自己的目标，那么该怎么办？就像蔚蓝的女主角一样“那就失败吧，你是我需要放下的一切，在此之前，请接受自己。” 最后以一句话结束自己的告别，与迎接新的一年 我的一生注定是与自己抗争的一生，但同时也是逐渐接受自己的一生。]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>年终总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人生第一场话剧---一个人的莎士比亚]]></title>
    <url>%2F2019%2F12%2F08%2F%E4%BA%BA%E7%94%9F%E7%AC%AC%E4%B8%80%E5%9C%BA%E8%AF%9D%E5%89%A7-%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%9A%84%E8%8E%8E%E5%A3%AB%E6%AF%94%E4%BA%9A%2F</url>
    <content type="text"><![CDATA[这次可以说人生的第一场话剧，本来就是有一点不想去，毕竟最近自己的状态并没有恢复过来，上次生日的花费预算，也是超了一点，然后秉持着不太想乱花钱的想，于是就有点不想去。 感谢朋友的坚持，让我感受到了又浅到深的心灵交流。 这是我接触到的第一场全英文独白的话剧了，全程就是一个年过半百的美国老爷爷上台表演，通过多种表情，姿态，语气，台词展现多个角色的独角戏。而展示的角色大致如下： 主角的学生时代 主角的父亲 主角的莎士比亚老师 主角的成年时代 主角莎士比亚老师的学生 说句实话，自己实在是算个粗人，对比话剧人士来说，我实在是无法接收到这种不是特别强烈的画面感以及动情的背景音乐的交流。以至于我刚开始看这个话剧的时候，觉得有点带有低俗性质的无法共情。正是由于是全英文独白，没有任何额外的配音，与道具，考验观众的共情能力，以及英语能力（虽然我每个单词都能够大致听懂，但是连成一个句子实在是有点强人所难了）。但是更考验的却是演员的临场能力，以及各种情绪语气的转变能力。只能说观众向有点精湛，如果读过莎士比亚的选集再来观看可能又是不太一样的感受吧。 个人理解，这部话剧是将作者亲身经历的故事，和莎士比亚的剧本话剧，代入到一个莎士比亚悲剧精神的校长之间发生的故事。 如果由剧情上进行一个划分，基本上可以分成四个部分 主角与莎士比亚话剧集的初识这个地方就是作者被老师校长逼迫读皆大欢喜中间的一段，由于总是读错，于是紧张的尿裤子。剧情上显得很一般，主要角色有两个，但是演员厉害的是在两种角色中转变中游刃有余，并且将学生的紧张感表现的唯妙唯俏，要知道，这仅仅只是靠了台词以及肢体语言，并没有其他多余的表现形式。 这个地方也是刚刚开始共情的地方了，从最先开始的看不懂的惊讶，到后面对于一个词语 遗赠 产生了莫大的兴趣 这也是主角尿裤子的主要原因了，这一场戏反而结合大家的想象力，反而显得特别有趣，因为每一种场景被赋予了想象力获得了独特的生命力，剧情的推进也到了下一个阶段。 主角与父亲的对话主角由于在学校里面出了丑，不敢再去学校，被父亲开解，于是敢于去学校了。父亲开解主角的那段话，让我记忆深刻，可能是最近对于细节情感的再现，真心的觉得中国普通家庭的亲子关系充满了沉重，被经济压的只剩下现实，希望自己以后能够冲破束缚改变这一切。我希望与父母或者是子女的关系（如果有的话）能够多一些轻松愉悦，不要被焦虑的担心所束缚。所谓父母子女一场，不过真切关系中最有缘分的相连，不要越爱越沉重。 主角与发生悲剧老师的故事「有时间再去补上」 主角与老年老师的故事换言之，整部话剧最令我感动的就是这个地方，由老年的校长说出全世界是一个大舞台，所有的男男女女不过是一些演员；他们都有下场的时候，也有上场的时候。一个人的一生中扮演着好几个角色，他的表演可以分为七个时期。最初是婴孩，在保姆的怀中啼哭呕吐。然后是背着书报、满面红光的学童，像蜗牛一样慢腾腾地拖着脚步，不情愿地呜咽着上学堂。然后是情人，像炉灶一样叹着气，写了一首悲哀的诗歌咏着他恋人地眉毛。然后是一个军人，满口发着古怪地誓，胡须长得像豹子一样，爱惜着名誉，动不动就要打架，在炮口上寻求着泡沫一样得荣名。然后是法官，胖胖圆圆的肚子塞满了阉鸡，凛然的眼光，整洁的胡须，满嘴都是格言和老生常谈；他这样扮了他的一个角色。第六个时期变成了精瘦的趿着拖鞋的龙钟老叟，鼻子上架着眼镜，腰边悬着钱袋；他那年轻时候节省下来的长袜子套在他皱瘪的小腿上显得宽大异常；他那朗朗的男子的口音又变成了孩子似的尖声，像是吹着风笛和哨子。终结着这段古怪的多事的历史的最后一场，是孩提时代的再现，全然的遗忘，没有牙齿，没有眼睛，没有口味，没有一切。]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>话剧</tag>
        <tag>莎士比亚</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Data Compression --- the course of algorithm]]></title>
    <url>%2F2019%2F10%2F10%2FData-Compression-the-course-of-algorithm%2F</url>
    <content type="text"><![CDATA[数据压缩introduction压缩数据可以节省存储数据需要的空间和传输数据需要的时间，虽然摩尔定律说集成芯片上的晶体管每 18-24 个月翻一倍，帕金森定律说数据会自己拓展来填满可用空间，但数据压缩还是最经济的做法。 数据压缩的基本模型如下，很简单，压缩和解压，压缩率即 C(B) 和 B 的比特数之比。 数据压缩对象的本质实际上就是将二进制文件，抽象层次为比特流， 下面直接给出了相应读写二进制的类 这里 java的默认处理是基于8位字节流 这里我举出一个简单的数据压缩的例子 将日期 12/31/1990 这个字符串进行压缩 上面就可以轻而易举的看出来 压缩的好处。第一张图就是原来的写法，第二张图就是将其换成int类型进行压缩第三张图则按照特定的压缩进行压缩 这里需要注意的是，并不存在通用的压缩算法 当然，这里存在一种可以供人类阅读的比特流形式，这个被称为 转储。下面图，就是一些例子： BinaryDump 将比特流按 0 和 1 输出来；HexDump 将比特流组织成 8 位并用两位的 16 进制数表示；PictureDump 则将比特流变为 Picture 对象，其中白色像素表示 0，黑色像素表示 1。 run-length Coding游程编码，就是专门用来处理冗杂的数据，他是通过计算重复的个数，来最终决定压缩的形式，就像下图： 上面这里就是用的4位计数，而下面的代码则是使用了8位计数。 1234567891011121314151617181920212223242526272829303132333435363738public class RunLength &#123; private final static int R = 256; // maximum run-length conut private final static int lgR = 8; // number of bits per conut public static void compress() &#123; char cnt = 0; boolean b, old = false; while (!BinaryStdIn.isEmpty()) &#123; b = BinaryStdIn.readBoolean(); if (b != old) &#123; BinaryStdOut.write(cnt); cnt = 0; old = !old; &#125; else &#123; // 由于这个地方是八位计数，所以最大的限制也就是255 if (cnt == 255) &#123; BinaryStdOut.write(cnt); cnt = 0; BinaryStdOut.write(cnt); &#125; &#125; cnt++; &#125; BinaryStdOut.write(cnt); BinaryStdOut.close(); &#125; public static void expand() &#123; boolean bit = false; while (!BinaryStdIn.isEmpty()) &#123; int run = BinaryStdIn.readInt(lgR); // read 8-bit conut from standard input for (int i = 0; i &lt; run; i++) BinaryStdOut.write(bit); // write 1 bit to standard output bit = !bit; &#125; BinaryStdOut.close(); // pad 0s for byte alignment &#125;&#125; 这种策略专门对付经常出现的，冗杂的比特流是十分有效的，游程编码的一个应用就是压缩位图，位图被广泛的用于保存图片和扫描文档。 就像这张图，左边经过压缩之后极大程度上小了很多。 这里的游程编码不适用于含有大量短游程的输入，而不是所有我们希望压缩的比特都能像上面一样重复个数多，且冗杂。所以接下来我们就介绍两种适用于多种类型的文件压缩算法。 Huffman Compression哈夫曼压缩 这里直接介绍了一个摩斯密码，但是像摩斯密码这一类的编码很容易产生多义性，所以密码之间还有一定的间隙隔开。 多义性的本质原因是有些字符的编码是其它字符编码的前缀，所以才可能会有不同的解读。而有种特殊的变长编码——前缀码（prefix-free code），字符编码肯定不是其它字符编码的前缀，也就不存在多义性的问题。 这里表示这种前缀码，可以很自然的使用字典树来进行表示 节点代码这里直接用代码表示： 1234567891011121314151617181920private static class Node implements Comparable&lt;Node&gt; &#123; private final char ch; // used only for leaf nodes private final int freq; // used only for compress private final Node left, right; public Node(char ch, int freq, Node left, Node right) &#123; this.ch = ch; this.freq = freq; this.left = left; this.right = right; &#125; private boolean isLeaf() &#123; return left == null &amp;&amp; right == null; &#125; public int compareTo(Node that) &#123; return this.freq - that.freq; &#125;&#125; 字符频率在下面生成最优前缀码的时候会使用到。 当然，在下面使用前，得将这个表示前缀码的字典树一样给压缩进入到比特流，而这里就直接使用前序遍历了。 当然，需要将叶子节点与其他的节点区分开来的话，到叶子节点的时候会先输出一个true，意思就是1，而其他的节点则是0，附在开头的Trie相对就会显得很小，没有什么关系。 上面已经将压缩字典树，以及解压缩字典树都讲到了，接下来就是构造这个前缀码字典树了。 实际上，哈夫曼的做法很好描述：首先你要知道字符出现的频率，然后每次挑两个最小的加起来，加起来的值再和原来的那些一起重复挑两个最小的加起来，从下往上接成 Trie。 构造代码12345678910111213141516171819private static Node buildTrie(int[] freq) &#123; MinPQ&lt;Node&gt; pq = new MinPQ&lt;Node&gt;(); for (char i = 0; i &lt; R; i++) if (freq[i] &gt; 0) pq.insert(New Node(i, freq[i], null, null)); // merge two smallest tries while (pq.size() &gt; 1) &#123; Node x = pq.delMin(); Node y = pq.delMin(); Node parent = new Node('\0', x.freq + y.freq, x, y); // 这里有点类似于广搜的操作，这样的做法就是直接将每一个最小的值弄出来，然后分别给其设置父亲节点 pq.insert(parent); &#125; // 最后一定一定就是根节点了。 return pa.delMin();&#125; 最优解证明这个地方目前对自己不作要求，贴两个网址 文字讲解 视频讲解 LZW-compressionLZW 压缩算法是自适应性的（adaptive）模型，在读入文本的时候学习并更新模型，不需要将模型附在比特流中用于解压，但解压的时候只能从文本开头开始。 压缩例子展开和压缩类似，有下面几个步骤： 创建符号表，但这次编码为键，对应的字符串为值。初始化符号表，加入单个字符的键值对。从压缩文件读入 W 位的编码，输出编码对应的字符串。预读下一个编码，得到下个字符，类似地更新符号表。重复上两步直到读入结束编码。例图即展开上面压缩形成的编码。 一开始读入 8 位编码 41，从符号表可知对应字符串 A，输出 A 后预读下一个编码 42，对应 B，于是往符号表中加入新键值对 (81, AB)；现在读到编码 42，输出 B 并预读 52 得到 R，所以加入 (82, BR) … 直到读入编码 80，表示文件结束。 似乎展开和压缩差不多，甚至更简单，因为不需要找最长前缀，符号表直接用数组简单实现。但是，展开有时会碰到一个特殊的情况： 压缩字符串 ABABABA 编码成 41 42 81 83 80，现在对这编码进行展开。编码 41 输出 A，预读 42 后加入 (81, AB) 更新符号表；编码 42 输出 B，预读 81 知道下个字符是 A，加入 (82, BA)；编码 81 输出 AB，预读 83 卡住，因为符号表中还没有这个键。 但是，这种时候我们还是可以知道 AB 的下一个字符是什么的。假设 AB 后面的字符分别为 𝑐1，𝑐2，𝑐3，卡住的时候（更新要加入的编码和预读到的编码一样）肯定有 AB𝑐1=𝑐1𝑐2𝑐3,所以下个字符即 A，加入 (83, ABA) 即可。 1234567891011121314151617181920212223public static void expand() &#123; int i; // 当前更新符号表要加入的编码 String[] st = new String[L]; for (i = 0; i &lt; R; i++) st[i] = "" + (char) i; st[i++] = " "; // 例图中表示文件结束的 0x80 int codeword = BinaryStdIn.readInt(W); String val = st[codeword]; while (true) &#123; BinaryStdOut.write(val); codeword = BinaryStdIn.readInt(W); // 预读的编码 if (codeword == R) break; String s = st[codeword]; if (i == codeword) // 要加入的编码和预读的编码相同 s = val + val.charAt(0); if (i &lt; L) st[i++] = val + s.charAt(0); val = s; &#125; BinaryStdOut.close();&#125; 关于第二种压缩方式 有点不是很好理解，可以配合算法视频课一起食用，这里就可以不用传输模型展开压缩，编码文件了。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
        <tag>数据压缩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Regular Expressions --- the course of algorithm]]></title>
    <url>%2F2019%2F10%2F09%2FRegular-Expressions-the-course-of-algorithm%2F</url>
    <content type="text"><![CDATA[Regular Expressions正则表达式在文本中查找子字符串只是寻找一个单一的字符串，但经常的我们可能不知道这个字符串的完整信息，或是寻找的是吻合某种模式的一些字符串，即所谓 模式匹配（Pattern Matching）。 正则表达式（Regular Expressions） 就是用来描述模式的，表示符合某种模式的字符串的集合（可能是无限的），它有下面几种基本操作： 就是普通的正则表达式里面的操作。 连接、或、闭包和括号，都不难理解。其中闭包表示若干个自身连接，可以是零个。 然后他一般有以下这些缩略方式 关于完整的正则表达式 可以去看看 正则表达式速查表 基本上常用的正则表达式 因为之前接触过正则表达式，所以这个地方也就不再多余赘述了。 REs And NFAs其实，正则表达式和确定型有穷自动机间存在着二元性（duality），即 Kleene 定理所说：对任意 DFA 存在着描述同样字符串集合的正则表达式，对任意正则表达式存在着识别同样字符串集合的 DFA。 就像之前学习KMP的时候构造的DFA，这里其实也可以构造一个DFA，就像这样 当然应用在KMP上面的DFA是线性时间的性能保证，但是这个办法并不可行，因为正则表达式对应的DFA的状态数目可能是指数级的。 于是，就来了解一下 非确定型有限状态自动机，状态之间的转移并不是确定的。 正则表达式用括号括起。 正则每个符号对应 NFA 一个状态，再加个接受状态。 接受空串𝜖，不扫描下个字符而直接改变状态（下图红线），不确定性所在。 扫描字符，匹配转移到一下个状态（下图黑线）。 在扫描完全部文本字符后，如果有 任一 转移序列到达接受状态，则匹配成功。 NFA-construction首先先讲一下它的构造过程 最先开始的状态，最后一个位置表示完成匹配 所有字符直接指向下一个 括号或者空的，就直接往下面指就行了 闭包，比较巧妙 不过分两种情况，例子里面的就是第一种情况 符号 ‘|’ 最后再来两个空转移 当然，在完成上面的构造的过程中，需要借助数据结构栈，碰到左括号或者‘|’的时候就直接将其的编号压到栈内，碰到右括号就弹出栈顶，如果对于的是其他东西，就直接根据上面的图来顺应结果，具体看代码。 12345678910111213141516171819202122232425// 这里就是直接用有向图来进行表示。private Digraph buildNFA() &#123; Digraph g = new Digraph(M + 1); // 顶点数加1 Stack&lt;Integer&gt; ops = new Stack&lt;Integer&gt;(); for (int i = 0; i &lt; M; i++) &#123; int lp = i; if (re[i] == '(' || re[i] == '|') ops.push(i); else if (re[i] == ')') &#123; int or = ops.pop(); if (re[or] == '|') &#123; lp = ops.pop(); g.addEdge(lp, or + 1); g.addEdge(or + 1, lp); &#125; else lp = or; &#125; if (i &lt; M - 1 &amp;&amp; re[i + 1] == '*') &#123; g.addEdge(lp, i + 1); g.addEdge(i + 1, lp); &#125; if (re[i] == '(' || re[i] == '*' || re[i] == ')') g.addEdge(i, i + 1); &#125; return g;&#125; NFA-simulation首先我们这样来表示 NFA：用整数 0 到 M（正则长度）来标号状态（像上图），用数组 re 来存储正则表达式，用有向图来存储空转移 至于怎么模拟 NFA 输入文本运行，感觉类似广搜，维护每一步所有可能走到的状态，下一步再拓展这些状态，要是文本流结束那步的状态里包含接受状态，就表示匹配成功。例图： 1234567891011121314151617181920212223242526272829303132333435363738394041public class NFA &#123; private char[] re; // match transitions private Digraph G; // epsilon transition digraph private int M; // number of states public NFA(String regexp) &#123; M = regexp.length(); re = regexp.toCharArray(); G = buildEpsilonTransitionDigraph(); &#125; public boolean recognizes(String txt) &#123; // states reachable from start by epsilon transitions Bag&lt;Integer&gt; pc = new Bag&lt;Integer&gt;(); DirectedDFS dfs = new DirectedDFS(G, 0); for (int v = 0; v &lt; G.V(); v++) if (dfs.marked(v)) pc.add(v); for (int i = 0; i &lt; txt.length(); i++) &#123; // states reachable after scanning past txt.charAt(i) Bag&lt;Integer&gt; match = new Bag&lt;Integer&gt;(); for (int v : pc) &#123; if (v == M) continue; // 匹配时直接加上下一个状态 if ((re[v] == txt.charAt(i)) || re[v] == '.') match.add(v + 1); &#125; //最坏的结果就是 match 重新复制了一遍上述的全部 dfs = new DirectedDFS(G, match); // 拓展上一步的所有状态 pc = new Bag&lt;Integer&gt;(); for (int v = 0; v &lt; G.V(); v++) if (dfs.marked(v)) pc.add(v); &#125; // accept if can end in state M for (int v : pc) if (v == M) return true; return false; &#125;&#125; 图文 大部分借鉴 博客 若侵权，必删。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BoggleSolver]]></title>
    <url>%2F2019%2F09%2F28%2FBoggleSolver%2F</url>
    <content type="text"><![CDATA[题目 解析这道题的意思就是 给你一个四乘以四的方块，然后再这个方块里面遍历所有能到的位置，八个方向，每个位置只能走一次，方块上面各有一个字母，走过每一个字母之后构成一个单词，然后看这个单词最后在不在字典中，且能得到多少分？ 最先开始的想法，是用一个bfs，然后将每一个遍历每一个单词，然后再讲每一个单词放入到其中进行判断，这样的话，时间复杂度会特别高，没一个单词都要遍历全部位置，并且 一些单词没有的前缀，比如，没有Y 开头的单词的话，那么我在从Y这里开始走的话，会浪费特别多的精力。 所以，看了一下解析，是直接用字典树去存储，然后遍历位置，就相当于遍历字典树一样。 找时间得重新写一下。自己做的很不对的地方就在于，自己用的bfs，注意的是这个状态并不是循序渐进的变化，而是每一个状态都不一样，如果要用bfs的话，那么每一个状态都要存进去大量的东西重置，所以，这就是不准确的地方。 贴代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import edu.princeton.cs.algs4.Bag;import java.util.HashSet;import edu.princeton.cs.algs4.Stack;public class BoggleSolver&#123; //自己建立的 字典树，这样方便后面dfs查询的时候的剪枝。 private Node root; private BoggleBoard board; private int col,row; private HashSet&lt;String&gt; allwords; private Bag&lt;Integer&gt;[] adj; private boolean[] vis; private Stack&lt;Integer&gt; dice; private class Node &#123; int val = 0; private Node[] next = new Node[26]; &#125; public BoggleSolver(String[] dictionary) &#123; root = new Node(); for (int i = 0; i &lt; dictionary.length; i++) &#123; put(dictionary[i]); &#125; &#125; private void put(String word) &#123; root = put(root, word, 0); &#125; //这里就是直接构造出一个字典树，通过这个字典树来存储所有字符，并且剪枝dfs。 private Node put(Node x, String word, int d) &#123; if (x == null) x = new Node(); if (d == word.length()) &#123; x.val = 1; return x; &#125; int c = word.charAt(d) - 'A'; x.next[c] = put(x.next[c], word, d + 1); return x; &#125; private int get(String word) &#123; Node x = get(root, word, 0); if (x == null) return 0; return x.val; &#125; private Node get(Node x, String word, int d) &#123; if (x == null) return null; if (d == word.length()) return x; int c = word.charAt(d) - 'A'; return get(x.next[c], word, d + 1); &#125; private boolean check(int i, int j) &#123; return i &gt;= 0 &amp;&amp; i &lt; row &amp;&amp; j &gt;= 0 &amp;&amp; j &lt; col; &#125; public Iterable&lt;String&gt; getAllValidWords(BoggleBoard board) &#123; this.board = board; allwords = new HashSet&lt;&gt;(); row = board.rows(); col = board.cols(); //这个地方的写法需要注意一下。 adj = (Bag&lt;Integer&gt;[]) new Bag[row * col]; for (int i = 0; i &lt; row; i++) &#123; for (int j = 0; j &lt; col; j++) &#123; int v = i * col + j; adj[v] = new Bag&lt;Integer&gt;(); //这里就相当于图论里面的建立边，直接给后面dfs提供条件 if (check(i - 1, j)) adj[v].add((i - 1) * col + j); if (check(i + 1, j)) adj[v].add((i + 1) * col + j); if (check(i, j - 1)) adj[v].add(i * col + j - 1); if (check(i, j + 1)) adj[v].add(i * col + j + 1); if (check(i + 1, j - 1)) adj[v].add((i + 1) * col + j - 1); if (check(i + 1, j + 1)) adj[v].add((i + 1) * col + j + 1); if (check(i - 1, j - 1)) adj[v].add((i - 1) * col + j - 1); if (check(i - 1, j + 1)) adj[v].add((i - 1) * col + j + 1); &#125; &#125; //接下来就到了 dfs搜图的时候 //最先开始我个人的想法是在这个地方用bfs来进行，当时发现到后面存在很多的问题，比如时间复杂度是特别高的。 for(int i = 0; i &lt; row * col; i++) &#123; vis = new boolean[row * col]; dice = new Stack&lt;Integer&gt;(); vis[i] = true; dice.push(i); //这个地方需要留意的是 root在这里并没有其他的含义 char c = getLetter(i); if (c == 'Q') dfs(i, root.next['Q' - 'A'].next['U' - 'A'], "QU", dice); else dfs(i, root.next[c - 'A'], c + "", dice); //由于这个地方前面就直接重新定义了，所以就不需要采用清空操作了。 &#125; return allwords; &#125; private char getLetter(int v) &#123; return board.getLetter(v / col , v % col); &#125; private void dfs(int v, Node x, String prefix, Stack&lt;Integer&gt;dices) &#123; if (prefix.length() &gt; 2 &amp;&amp; x != null &amp;&amp; x.val == 1) &#123; allwords.add(prefix); &#125; for (int w : adj[v]) &#123; char c = getLetter(w); if (!vis[w] &amp;&amp; x != null &amp;&amp; x.next[c - 'A'] != null) &#123; dice.push(w); vis[w] = true; if (c == 'Q') &#123; dfs(w, x.next['Q' - 'A'].next['U' - 'A'], prefix + "QU", dice); &#125; else dfs(w, x.next[c - 'A'], prefix + c, dice); int d = dice.pop(); vis[d] = false; &#125; &#125; &#125; public int scoreOf(String word) &#123; if (get(word) == 0) return 0; else &#123; int len = word.length(); if (len &lt;= 2) return 0; else if(len == 3 || len == 4) return 1; else if (len == 5) return 2; else if (len == 6) return 3; else if (len == 7) return 5; else return 11; &#125; &#125;&#125; 当然，这次的作业后面还有后续，后续的地方就是 直接构成一个框架进行写，直接将这个游戏具象化，等自己熟悉了之后，再将代码贴出来。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法大作业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Substring Search --- kmp]]></title>
    <url>%2F2019%2F09%2F20%2FSubstring-Search-kmp%2F</url>
    <content type="text"><![CDATA[Substring Search这里主要讲的是kmp算法。 java from the course of algorithmIntroduction在长度为 N 的文本里寻找长度为 M 的模式（子串），典型情况是 N &gt;&gt; M。 这里就需要扩展两种做法，暴力与kmp算法了。 Brute Force首先先来看一下暴力查找。 就暴力地两个循环，查找文本的每个位置，最坏情况下需要近似MN次字符比较 123456789101112public static int search(String pat, String txt) &#123; int M = pat.length(); int N = txt.length(); for (int i = 0; i &lt;= N - M; i++) &#123; int j; for (j = 0; j &lt; M; j++) if (txt.charAt(i + j) != pat.charAt(j)) break; if (j == M) return i; // index in txt where pattern starts return N; // not found &#125;&#125; 暴力算法大多数情况下会跑的特别慢，因为建立在纯暴力的做法，会存在很多回退的情况，于是就会跑的很慢。 所以暴力算法并不是总能满足我们的需求，我们希望有线性时间级别的性能保证，希望避免在文本流中回退。 Knuth-Morris-PrattKMP算法就可以解决上面所说的问题，不用回退，最多也就访问一次就可以解决问题 首先先要了解一个名词 Deterministic Finite State Automaton 确定型有穷（状态）自动机（DFA），是一个抽象的字符串查找机器。 状态数目是有穷的（包括初始状态和终结状态）。 每个状态对每个字符有且仅有一个转移。 转移到终结状态则接受这个字符串，即含有我们寻找的子串（模式）。 其中 dfa[i][j] 表示状态 j 遇到字符 i 会转移到下一个状态，并不包括终结状态。 现在查找子串就很简单啦，一开始在初始状态，文本流读到哪个字符就往哪条路走，要是走到了终结状态，也就表示找到了子串。像我们这样构造的 DFA，走到状态几，就说明已经匹配了多少个字符其实，所以走到终结状态就表示全部匹配。 就像这样 12345678public int seach (String txt) &#123; int i,j,N = txt.length(); for (i = 0, j = 0; i &lt; N &amp;&amp; j &lt; M; i++) j = dfa[txt.chaAt(i)][j]; if (j == M) return i - M; //这种情况就是没有找到 else return N;&#125; 以上的匹配过程特别轻松，重要的就是下面构造dfa这个数组的过程。 Construct DFA 匹配情况 匹配的时候转移就特别好办，直接进行到下一个状态就可以了。 不匹配的情况 关键在不匹配时该如何转移。 假设在状态 j 时读到的下一个字符 c 不等于要找的子串的第 j + 1 个字符（pat.charAt(j)，从 0 标号），那么这个时候，我们从文本流中最近读出的 j - 1 个字符即为 pat[1..j - 1] + c，就是暴力算法要重新扫描的部分。 当前首字母到状态 j 出现了不匹配，按暴力算法该丢弃它从下一个字母再开始，即 pat[1]，再一路重新扫描到 c。所以，现在状态 j 遇到 c 该怎么转移，实际上和字符串 pat[1.. j - 1] + c 在 DFA 中所到状态碰到 c 的转移目标一样才对。于是我们这么计算 dfa[c][j]：在 DFA 上模拟 pat[1.. j - 1]，然后直接取字符 c 的转移。 下面举个例子 计算状态5的时候 如何去考虑字符A 和 字符B的转移 具体可以看下面的代码，因为这里存在一个 restart state 直接用 x来表示，因为这里的状态有的时候可以直接转移初始状态 1234567891011121314public KMP (String pat) &#123; this.pat = pat; M = pat.length(); dfa = new int [R][M]; //设置初始状态 //这里的版本就是构造有限类型的自动机，帮助记录状态迁移 dfa[pat.chaAt(0)][0] = 1; for (int x = 0, j = 1; j &lt; M; j++) &#123; for (int c = 0; c &lt; R; c++) dfa[c][j] = dfa[c][x]; dfa[pat.charAt(j)][j] = j + 1; x = dfa[pat.charAt(j)][x]; &#125;&#125; 不过这个算法的复杂度 优化之后 也达到了 (o(M) + o(N)) * 字母表 于是 C++ 版本里面会再次进行优化 注： 这里还有两张算法Boyer-Moore 与 Rabin-Karp 这个博客中有详细的讲解，就不再重复记录了。 C++ from some template in acm当上面的有限型自动机优化的版本，最后导致的结果就是 每一都得遍历一遍字母表 所以有没有其他办法来进行优化呢 所以就有了 改进的kmp算法利用 模式串中的 最长前缀与最长后缀的关系来构造next数组 就像这个样子 于是这里就先讲解一下 构造next数组的过程我们规定任何一个串，next[1]=0。(不用next[0]，与串的所有对应)，仍是一张动图搞定问题： 通过把next值“看”出来，我们再来分析next值，这就很容易得到超级有名的公式了，这个式子对后面的算法理解很重要！所以先要看懂这个式子，如果上面的内容通下来了，这个应该很容易看懂了： 首先是构造next数组的过程。 代码如下：12345678910111213int getNext(string p) &#123; int lenp = p.size(); next[0] = -1; int j = -1; int i = 0; while (i &lt; lenp - 1) &#123; if (j == -1 || p[j] == p[i]) &#123; next[++i] = ++j; &#125; else j = next[j]; &#125;&#125; 当然 这样写next数组是完全没有问题，但是 如果有一种情况p[next[j]] == p[j] 当出现这样的情况该如何解决呢？直接看图。 比如，如果用之前的next 数组方法求模式串“abab”的next 数组，可得其next 数组为-1 0 0 1（0 0 1 2整体右移一位，初值赋为-1），当它跟下图中的文本串去匹配的时候，发现b跟c失配，于是模式串右移j - next[j] = 3 - 1 =2位。 右移2位后，b又跟c失配。事实上，因为在上一步的匹配中，已经得知p[3] = b，与s[3] = c失配，而右移两位之后，让p[ next[3] ] = p[1] = b 再跟s[3]匹配时，必然失配。问题出在哪呢？ 问题出在不该出现p[j] = p[ next[j] ]。为什么呢？理由是：当p[j] != s[i] 时，下次匹配必然是p[ next [j]] 跟s[i]匹配，如果p[j] = p[ next[j] ]，必然导致后一步匹配失败（因为p[j]已经跟s[i]失配，然后你还用跟p[j]等同的值p[next[j]]去跟s[i]匹配，很显然，必然失配），所以不能允许p[j] = p[ next[j ]]。如果出现了p[j] = p[ next[j] ]咋办呢？如果出现了，则需要再次递归，即令next[j] = next[ next[j] ]。 所以就需要更改一下 下面的代码 12345678910111213141516171819int getNext(string p) &#123; int lenp = p.size(); next[0] = -1; int j = -1; int i = 0; while (i &lt; lenp - 1) &#123; if (j == -1 || p[j] == p[i]) &#123; //重点就在下面这个地方 i++; j++; if (p[i] != p[j]) next[i] = j; //这个地方就放入其继续进入递归。 else next[i] = next[j]; &#125; else j = next[j]; &#125;&#125; 后面就只剩下一开始匹配过程了。 1234567891011121314int kmp (string s,string p) &#123; int i = 0,j = 0; int slen = s.size(); int plen = p.size(); while (i &lt; slen &amp;&amp; j &lt; plen) &#123; if (j == -1 || s[i] = p[j]) &#123; i ++ ; j ++ ; &#125; else j = next[j]; &#125; if (j == plen) return i - j; else return -1;&#125; 后面还有两种拓展类型的算法BM算法 与 sunday算法这两种算法 有时间的情况下再来总结 这里直接贴出网址博客]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>字符串</tag>
        <tag>kmp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tries --- the course of algorithm]]></title>
    <url>%2F2019%2F09%2F17%2FTries-the-course-of-algorithm%2F</url>
    <content type="text"><![CDATA[单词查找树(字典树)首先先贴出 要实现的api: R-way Tries这里实现的要点就是在每一个node类里面加入一个数组去记录每一个字符可能存在的node 意思就是 256个 算上所有ASCII里面的 这里就不贴出具体函数表示功能的示意图了。 Tries: Java implementaion1234567891011121314151617181920212223242526272829303132333435363738394041public class TriesST&lt;Value&gt; &#123; private static final int R = 256; private Node root = new Node(); private static class Node &#123; private Object value; private Node[] next = new Node[R]; &#125; public void put (String key, Value val) &#123; root = put(root, key, val, 0); &#125; private Node put(Node x, String key, Value val, int d) &#123; if (x == null) x = new Node(); if (d == key.length()) &#123; x.val = val; return x; &#125; char c = key.charAt(d); x.next[c] = put(x.next[c], key, val, d + 1); return x; &#125; public boolean contains (String key) &#123; return get(key) != null; &#125; public Value get(String key) &#123; Node x = get(root, key, 0); if (x == null) return null; return (Value)x.val; &#125; private Node get(Node x, String key, int d) &#123; if (x == null) return null; if (d == key.length()) return x; char c = key.charAt(d); return get(x.next[c], key, d + 1); &#125;&#125; 总的来说，上面这个算法可以很快匹配到字符串，但是特别郎芬空间，因为其有很多误用的空节点，并且空链接也太多了。 Tries: deletion删除单词查找树中的某个字符串时，首先要找到它，然后把最后一个节点的值置空，再递归删除没有非空链接的空值节点。例子： 这里没有例子，就直接给出相应的图了。 Ternary Search Tries这里有点借鉴快排的思想，将每一个节点分成三个链接，大于，小于，等于三向单词查找树，如图： 这里也不再详细讲解其插入，构造，删除的过程了，类似于前面。 TST: Java implementation123456789101112131415161718192021222324252627282930313233343536373839404142434445public class TST&lt;Value&gt; &#123; private Node root; private class Node &#123; private Value val; private char c; private Node left, mid, right; &#125; public void put(String key, Value val) &#123; root = put(root, key, val, 0); &#125; private Node put(Node x, String key, Value val, int d) &#123; char c = key.charAt(d); if (x == null) &#123; x = new Node(); x.c = c; &#125; if (c &lt; x.c) x.left = put(x.left, key, val, d); else if (c &gt; x.c) x.right = put(x.right, key, val, d); else if (d &lt; key.length() - 1) x.mid = put(x.mid, key, val, d + 1); else x.val = val; return x; &#125; public boolean contains(String key) &#123; return get(key) != null; &#125; public Value get(String key) &#123; Node x = get(root, key, 0); if (x == null) return null; return x.val; &#125; private Node get(Node x, String key, int d) &#123; if (x == null) return null; char c = key.charAt(d); if (c &lt; x.c) return get(x.left, key, d); else if (c &gt; x.c) return get(x.right, key, d); else if (d &lt; key.length() - 1) return get(x.mid, key, d + 1); else return x; &#125;&#125; TST的复杂度其实有点时候是和红黑是相当，查找的效率有的时候是跟哈希的符号表也差不多，所以可能通过相应的平衡操作来保持其的性能。 不过有的时候还可以将其与R-way tries 结合起来 上面虽然空间上面会多花一点，但是查找性能会大大提升。 Character-based OperationsKeys 返回其的所有的存储的字符串 就像中序遍历这棵树 123456789101112131415public Iterable&lt;String&gt; keys() &#123; Queue&lt;String&gt; queue = new Queue&lt;String&gt;(); collect(root, "", queue); return queue;&#125;// prefix: sequence of characters on path from root to xprivate void collect(Node x, String prefix, Queue&lt;String&gt; q) &#123; if (x == null) return; //只有在满足了这个条件才会入队。 if (x. val != null) q.enqueue(prefix); for (char c = 0; c &lt; R; c++) collect(x.next[c], prefix + c, q);&#125; Prefix 12345678public Iterable&lt;String&gt; keyWithPrefix(String prefix) &#123; Queue&lt;String&gt; queue = new Queue&lt;String&gt;(); // x: root of subtrie for all strings // beginning with given prefix Node x = get(root, prefix, 0); collect(x, prefix, queue); return queue;&#125; Longest Prefix 123456789101112public String longestPrefixOf(String query) &#123; int length = search(root, query, 0, 0); return query.substring(0, length);&#125;private int search(Node x, String query, int d, int length) &#123; if (x == null) return length; if (x.val != null) length = d; if ( d == query.length()) return length; char c = query.charAt(d); return search(x.next[c], query, d + 1, length);&#125; 后面继续提到了 前缀树与后缀树。 参考该博客 侵删]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Radix Sort --- the course of algorithm]]></title>
    <url>%2F2019%2F09%2F17%2FRadix-Sort-the-course-of-algorithm%2F</url>
    <content type="text"><![CDATA[基数排序课程地址 String in javaChar Data TypeC 语言中的字符数据类型占一个字节（8 比特），最多只能表示 256 个字符。支持 7 位的标准 ASCII(American Standard Code for Information Interchange，美国标准信息交换编码)，最高位用于奇偶校验。或是拓展的 ASCII，最高位用来确定附加的 128 个特殊的字符。 而java中的字符数据类型占两个字节，支持16位的Unicode编码。 String Data Typejava String api 接下来就是java中两种字符串类型的比较，一种是String，另外一种就是StringBuilder 这两种之间的区别就在于 一个是内部可变，另外一种就是内部不可变。 然而 还有一种StringBuffer 这种与前面后者的相比就是线程安全与否的区别了。 Key-indexed counting因为一般字符串中基于排序的比较 基本上至少都是需要NlgN的比较，然后有一种基数比较的办法诞生，称作键索引计数比较法 设想有个数组 a = {d, a, c, f, f, b, d, b, f, b, e, a} 要排序，知道总共有 6 个不同的字母，要先统计它们出现的频数。 字母 a 的键为 0 （a[i] - ‘a’），出现的次数在 count 数组中的索引为键值加一。 java implements 123456789101112131415int R = 6;int N = a.length;int[] count = new int[R + 1];for (int i = 0; i &lt; N; i++) count[a[i] - 'a' + 1]++;//遍历一遍count数组for (int i = 0; i &lt; R; i++) count[i + 1] += count[i];//现在 count 数组中保存的即对应字母在排好序的数组中开始的索引值，像两个 d 应该放在 a[6] 和 a[7]。char[] aux = new char[N];for (int i = 0; i &lt; N; i++) aux[count[a[i] - 'a']++] = a[i]; 辅助数组 aux 借助 count 数组找到了每个 a[i] 的位置。注意 count 数组在这一步中还会改变，每次要加一，下次相同的 a[i] 就会放在下一个位置。所以这个算法也是稳定的（stable），相同元素间的相对顺序不会改变。 最后把 aux 数组一个个赋值回原数组，即完成了排序。 键索引计数法排序只需要几个一重循环，不需要比较，只要 R 在 N 的一个常数因子范围内，它就是一个线性时间级别的排序方法。 LSD Radix Sort低位优先排序，就是将等长的字符串进行排序，必须是等长的字符串进行排序，需要做的是从右向左进行排序 这个排序是稳定的，相同键之间的相对顺序是不会改变的，意思就是在i前面的，在i + 1排完字后，依然还是在i前面，如果是相同键的情况下。 LSD: Java Implementation123456789101112131415161718192021public class LSD &#123; public static void sort(String []a,int w) &#123; int R = 256; int N = a.length; String[] aux = new String[N]; //从后往前面依次进行排序 for (int d = w - 1; d &gt;= 0; d--) &#123; int[] count = new int [R + 1]; for (int i = 0; i &lt; N; i++) count[a[i].charAt(d) + 1] ++; for (int r = 0; r &lt; R; r++) count[r + 1] += count[r]; for (int i = 0; i &lt; N; i++) aux[count[a[i].charAt(d)]++] = a[i]; for (int i = 0; i &lt; N; i++) a[i] = aux[i]; &#125; &#125;&#125; 对于典型的应用,R(基数)远小于N(总数),对定长(W)的字符串排序的时间是MN级别。 MSD Radix Sort高位排序，有别于低位排序的是，其可以对不等长的字符串进行排序，从左向右进行一位一位的扫描，然后再递归的对子字符串进行基数排序。 就像这样： 因为涉及到递归，所以必须得设置一下递归出口，用一下函数直接设置递归出口 1234private static int charAt(String s, int d) &#123; if (d &lt; s.length) return s.charAt(d); else return -1;&#125; MSD: Java Implementation由于上面多了一个键，所以现在count的数组大小必须是R + 2 12345678910111213141516171819202122232425262728293031323334public static void sort(String[] a) &#123; aux = new String[a.length]; sort(a, aux, 0, a.length - 1, 0);&#125;private static void sort(String[] a, String[] aux, int lo, int hi, int d) &#123; if (hi &lt;= lo) return; int[] count = new int[R + 2]; for (int i = lo; i &lt;= hi; i++) count[charAt(a[i], d) + 2]++; for (int r = 0; r &lt; R + 1; r++) count[r + 1] += count[r]; for (int i = lo; i &lt;= h; i++) aux[count[charAt(a[i], d) + 1]++] = a[i]; for (int i = lo; i &lt;= hi; i++) a[i] = aux[i -lo]; // sort R subarrays recursively for (int r = 0; r &lt; R; r++) sort(a, aux, lo + count[r], lo + count[r + 1] - 1, d + 1);&#125;//另外用于辅助的数组aux可以重复使用，但是每一次都需要新的count数组，不仅耗费空间，还需要时间去初始化，所以对于小型的子数组，可以直接使用插入排序直接进行改善public static void sort(String[] a, int lo, int hi, int d) &#123; for (int i = lo; i &lt;= hi; i++) for (int j = i; j &gt; lo &amp;&amp; less(a[j], a[j - 1], d); j--) exch(a, j, j -1);&#125;private static boolean less(String v, String w, int d) &#123; return v.substring(d).compareTo(w.substring(d)) &lt; 0;&#125; MSD算法的性能取决于要输入的数据，最坏的情况下需要检查的所有的字符，和LSD一样都是线性的时间级别。 3-way Radix Quicksort三相切分的思想其实很简单，基于MSD的思想，加入了快排，将第一个字符串的首字母，进行切分，分成大于，小于，等于该字母的组合，然后再分别进入到子字符串中进行递归使用。 3-way String Quicksort: Java Implementation12345678910111213141516171819202122private static void sort(String[] a) &#123; sort(a, 0, a.length - 1, 0);&#125;private static void sort(String []a, int lo, int hi, int d) &#123; if (lo &gt;= hi) return; int lt = lo, gt = hi; int v = charAt(a[lo], d); int i = lo + 1; while (i &lt;= gt) &#123; int t = charAt(a[i], d); if (t &lt; v) exch(a, lt++, i++); else if (t &gt; v) exch(a,i,gt--); else i++; &#125; //这里是再次比较前面的数组进行三相切分。 sort(a, lo, lt - 1, d); //这里的意思第一个字母是相同的，所以可以开始递归第二个字母了 if (v &gt;= 0) sort(a, lt, gt, d + 1); sort(a, gt + 1, hi, d);&#125; Suffix Arrays字符串后缀数组 有很多应用，比如关键词查找，最长重复子字符等等。 1234567public static String[] suffixes(String s) &#123; int N = s.length(); String[] suffixes = new String[N]; for (int i = 0; i &lt; N; i++) suffixes[i] = s.substring(i, N); return suffixes;&#125; 对于后缀数组进行排序，就可以把相同的字符串给安排到一起了，这样的话查找关键词也就快了很多。 就像这样，最长重复子字符串也差不多 LRS: Java Implementation12345678910111213141516171819public String lrs(String s) &#123; int N = s.length(); String[] suffixes = new String[N]; for (int i = 0; i &lt; N; i++) suffixes[i] =s.substring(i, N); Arrays.sort(suffixes); String lrs = ""; for (int i = 0; i &lt; N - 1; i++) &#123; // compute longest common prefix // between adjacent suffixes insorted order int len = lcp(suffixes[i], suffixes[i + 1]); if (len &gt; lrs.length()) lrs = suffixes[i].substring(0, len); &#125; return lrs;&#125; 不过最坏的情况,应该会达到 n$^{2}$。因为输入字符串重复时，需要很多次比较才能完成排序，所以这里介绍了另外一种算法 Manber-Myer MSD 算法 有兴趣的话 可以自己去查一查 这里就不在多说了。 本篇文章借鉴该博客 若侵删。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BaseballElimination]]></title>
    <url>%2F2019%2F09%2F14%2FBaseballElimination%2F</url>
    <content type="text"><![CDATA[题目链接题目 解析题目意思给你n支队伍，然后每一个队伍有三个参数，赢得比赛，输的比赛，以及还有多少场比赛没打，然后再给一个所有剩余比赛的示意图，来表示剩余比赛谁与谁去打。获胜条件是 只有一支队伍胜利，其余的全部直接被淘汰。 现在需要做的是评估其中的一支队伍是否被淘汰。 淘汰方式有两种 第一种，评估队伍的最大获胜数，（算上其还没有打的比赛全部赢），还是没有某些队伍已经获取的胜利比赛数多，那么则可以说这个队伍已经被淘汰了。 第二种，需要建立一个最大流的图，然后通过最大流的图，来判断是否已经在数学上被淘汰了。 最大流的建立方法这里一共需要建立 2 + n - 1 + $C_{2}^{n - 1}\textrm{}$ 个节，分别是源点与汇点，加上队伍节点与比赛节点，就像下面这一张图 如上图所示，评判方式，如果从S点出发的边里 流量都等于容量的话，那么 此时的flow 一定等同于 最大流， 说明其他队伍用了九牛二虎之力所做到的最好的结果也就是与评估队伍打成平手。 而如果flow大于最大流，则说明，有一些从s出发的边并没有达到容量， 再还有比赛没有打完的时候，就已经有队伍分数跟评估队伍的分数一样了，则说明评估队伍已经被淘汰了。 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185package Programming_Assignment_8;import edu.princeton.cs.algs4.FlowEdge;import edu.princeton.cs.algs4.FlowNetwork;import edu.princeton.cs.algs4.FordFulkerson;import edu.princeton.cs.algs4.In;import java.util.HashMap;import java.util.HashSet;import java.util.Map;public class BaseballElimination &#123; private int flows; private final int[] win; private final int[] lose; private final int[] left; private final int[][] remain; private String[] teams; private final int teamnum; private HashMap&lt;Integer,Integer&gt;pos; private final HashMap&lt;String, Integer&gt; map; private HashSet&lt;String&gt; set; private int allv; private int gameTeams; public BaseballElimination(String filename) &#123; if (filename == null) throw new IllegalArgumentException("Wrong file name..."); In in = new In(filename); teamnum = Integer.parseInt(in.readLine()); teams = new String[teamnum]; map = new HashMap&lt;String, Integer&gt;(); win = new int[teamnum]; lose = new int [teamnum]; left = new int[teamnum]; remain = new int[teamnum][teamnum]; int tot = 0; while (in.hasNextLine()) &#123; String readline = in.readLine().trim(); String []token = readline.split(" +"); map.put(token[0], tot); teams[tot] = token[0]; win[tot] = Integer.parseInt(token[1]); lose[tot] = Integer.parseInt(token[2]); left[tot] = Integer.parseInt(token[3]); for (int i = 0; i &lt; teamnum; i++) &#123; if (i == tot) remain[tot][i] = 0; else remain[tot][i] = Integer.parseInt(token[4 + i]); &#125; tot++; &#125; &#125; public int numberOfTeams() &#123; return teamnum; &#125; public Iterable&lt;String&gt; teams() &#123; return map.keySet(); &#125; public int wins(String team) &#123; valid(team); Integer id = map.get(team); return win[id]; &#125; public int losses(String team) &#123; valid(team); Integer id = map.get(team); return lose[id]; &#125; public int remaining(String team) &#123; valid(team); Integer id = map.get(team); return left[id]; &#125; public int against(String team1, String team2) &#123; valid(team1); valid(team2); Integer id1 = map.get(team1); Integer id2 = map.get(team2); return remain[id1][id2]; &#125; private FlowNetwork buildFlowNetwrok(String team) &#123; valid(team); Integer id = map.get(team); int most = win[id] + left[id]; gameTeams = (teamnum - 1) * (teamnum - 2) / 2; allv = gameTeams + teamnum - 1 + 2; flows = 0; pos = new HashMap&lt;&gt;(); int s = 0, t = allv - 1; int gameIndex = 1; //比赛结点 int indexi = gameTeams;// 球队节点 int indexj = indexi; double max = Double.POSITIVE_INFINITY; FlowNetwork flowNetwork = new FlowNetwork(allv); for (int i = 0; i &lt; teamnum; i++) &#123; if (id == i) continue; indexi++; indexj = indexi; if(win[i] &gt; most) return null; for (int j = i + 1; j &lt; teamnum; j++) &#123; if (j == id) continue; indexj++; flows += remain[i][j]; flowNetwork.addEdge(new FlowEdge(s,gameIndex,remain[i][j])); flowNetwork.addEdge(new FlowEdge(gameIndex,indexi,max)); flowNetwork.addEdge(new FlowEdge(gameIndex,indexj,max)); gameIndex++; &#125; pos.put(indexi,i); flowNetwork.addEdge(new FlowEdge(indexi,t,most - win[i])); &#125; return flowNetwork; &#125; private void valid(String team) &#123; if (team == null) throw new IllegalArgumentException("Wrong teams"); if (!map.containsKey(team)) throw new IllegalArgumentException("Not in the team"); &#125; public boolean isEliminated(String team) &#123; valid(team); FlowNetwork flowNetwork = buildFlowNetwrok(team); int id = map.get(team); if (flowNetwork == null) &#123; set = new HashSet&lt;&gt;(); for (int i = 0; i &lt; teamnum; i++) &#123; if (id == i) continue; if (win[id] + left[id] &lt; win[i]) &#123; set.add(teams[i]); &#125; &#125; return true; &#125; FordFulkerson fordFulkerson = new FordFulkerson(flowNetwork,0,allv - 1); if (flows &gt; fordFulkerson.value()) &#123; set = new HashSet&lt;&gt;(); for (int i = gameTeams + 1; i &lt; allv - 1 ;i++) &#123; //其实这个地方是一直弄不清楚这个函数，主要是弄不清 为什么这个点在最小割上面 就可以证明出 来自s点的边 流量不等于容量 //查阅了相关资料，最后发现，其实 这里incut 就相当于割边直接将整张图一分为2，这里是靠近源点s的 //换言之，就是在跑完最后一遍寻找增广路的时候，是否会有在其剩余的路径上，意思就是 当我查看队伍的点的时候，只要没有剩余的流量，就一定不会遍历到这个点上 if (fordFulkerson.inCut(i)) &#123; int Id = pos.get(i); set.add(teams[Id]); &#125; &#125; return true; &#125; return false; &#125; public Iterable&lt;String&gt; certificateOfElimination(String team) &#123; valid(team); if (isEliminated(team)) return set; return null; &#125;&#125; 注意上面所说的位置，incut 这里就是标记是否有位置还有剩余，当最后一次在找增广路的时候，那么这些位置就是没有满的位置 总结觉得这次大作业做的特别诡异，主要是题目好了好久时间才理解其真正的意思，还有可能是对于最大流的概念理解的还是不够透彻，这就是我个人的问题，接下来所需要做的就是 下一次的大作业，以及好好理解一下 最大流 最小割定理之间的变化。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SeamCarver]]></title>
    <url>%2F2019%2F09%2F10%2FSeamCarver%2F</url>
    <content type="text"><![CDATA[题目题目链接 题目详图 解析这道题是我这几次做这个java大作业里面，还特别有意思的一次作业，主要是这次介绍的这个算法特别流弊，感觉特别常见，就是发现于2007年的算法，并且应用于 Photoshop内核的算法，用于图片的拉伸与缩放。 先开始是作为最短路里面的算法出现，感觉特别的懵逼，因为完全不知道该怎么下手，不过后面就好很多了，意思就是使用一个特定的公式，将每一个像素点与周围8个方向的点的差异相联系，作为整个像素点的权值，然后从不同于拉伸的方向，从顶部到底部找一条像素点权值最小的路线，然后将这条路线进行删除，最后便得到结果。 然后找最短路的办法，这里使用的就是 对每一个点，至上而下的松弛，最终得到结果，这次作业只是看着有点吓人，但是其实还是特别简单的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223import edu.princeton.cs.algs4.Picture;public class SeamCarver &#123; //这里图像会发生改变，所以这里不能直接写定义成不变量 private int width; private int height; private int [][] picture; private double [][] energy; // create a seam carver object based on the given picture public SeamCarver(Picture picture) &#123; if (picture == null) throw new IllegalArgumentException(); this.height = picture.height(); this.width = picture.width(); this.picture = new int [width][height]; for (int i = 0; i &lt; this.width; i++) &#123; for (int j = 0; j &lt; this.height; j++) &#123; this.picture[i][j] = picture.getRGB(i, j); &#125; &#125; renewenergy(); &#125; private void validateindex(int col, int row) &#123; if (row &lt; 0 || row &gt;= height || col &lt; 0 || col &gt;= width) &#123; throw new IllegalArgumentException("Wrong index"); &#125; return; &#125; private void renewenergy() &#123; energy = new double[width][height]; for (int i = 0; i &lt; width; i++) &#123; for (int j = 0; j &lt; height; j++) &#123; calculatenergy(i, j); &#125; &#125; &#125; private void calculatenergy(int x, int y) &#123; validateindex(x, y); if (x == 0 || y == 0 || x == width - 1 || y == height - 1) &#123; energy[x][y] = 1000.0; return; &#125; int rgbUp = picture[x][y - 1]; int rgbDown = picture[x][y + 1]; int rgbLeft = picture[x - 1][y]; int rgbRight = picture[x + 1][y]; double rx = Math.pow(((rgbLeft &gt;&gt; 16) &amp; 0xFF) - ((rgbRight &gt;&gt; 16) &amp; 0xFF), 2); double gx = Math.pow(((rgbLeft &gt;&gt; 8) &amp; 0xFF) - ((rgbRight &gt;&gt; 8) &amp; 0xFF), 2); double bx = Math.pow(((rgbLeft &gt;&gt; 0) &amp; 0xFF) - ((rgbRight &gt;&gt; 0) &amp; 0xFF), 2); double ry = Math.pow(((rgbUp &gt;&gt; 16) &amp; 0xFF) - ((rgbDown &gt;&gt; 16) &amp; 0xFF), 2); double gy = Math.pow(((rgbUp &gt;&gt; 8) &amp; 0xFF) - ((rgbDown &gt;&gt; 8) &amp; 0xFF), 2); double by = Math.pow(((rgbUp &gt;&gt; 0) &amp; 0xFF) - ((rgbDown &gt;&gt; 0) &amp; 0xFF), 2); energy[x][y] = Math.sqrt(rx + gx + bx + ry + gy + by); return; &#125; public Picture picture() &#123; Picture tmp = new Picture(width, height); for (int i = 0; i &lt; width; i++) &#123; for (int j = 0; j &lt; height; j++) &#123; tmp.setRGB(i, j, picture[i][j]); &#125; &#125; return tmp; &#125; public int width() &#123; return width; &#125; public int height() &#123; return height; &#125; public double energy(int x, int y) &#123; validateindex(x, y); return energy[x][y]; &#125; private void transform() &#123; int temp = height; height = width; width = temp; double [][] en = new double[width][height]; int [][] p = new int[width][height]; for (int i = 0; i &lt; width; i++) &#123; for (int j = 0; j &lt; height; j++) &#123; en[i][j] = energy[j][i]; p[i][j] = picture[j][i]; &#125; &#125; energy = en; picture = p; &#125; public int[] findHorizontalSeam() &#123; transform(); int [] res = findVerticalSeam(); transform(); return res; &#125; private void relaxVertical(double[][] disTo, int[][]edgeTo, int x, int y) &#123; validateindex(x, y); if (disTo[x][y + 1] &gt; disTo[x][y] + energy[x][y + 1]) &#123; disTo[x][y + 1] = disTo[x][y] + energy[x][y + 1]; edgeTo[x][y + 1] = x; &#125; if (x &gt; 0 &amp;&amp; disTo[x - 1][y + 1] &gt; disTo[x][y] + energy[x - 1][y + 1]) &#123; disTo[x - 1][y + 1] = disTo[x][y] + energy[x - 1][y + 1]; edgeTo[x - 1][y + 1] = x; &#125; if (x &lt; width - 1 &amp;&amp; disTo[x + 1][y + 1] &gt; disTo[x][y] + energy[x + 1][y + 1]) &#123; disTo[x + 1][y + 1] = disTo[x][y] + energy[x + 1][y + 1]; edgeTo[x + 1][y + 1] = x; &#125; &#125; public int[] findVerticalSeam() &#123; int [] seam = new int[height]; double [][] disTo = new double [width][height]; int [][] edgeTo = new int [width][height]; for (int i = 0; i &lt; width; i++) &#123; for (int j = 0; j &lt; height; j++) &#123; if (j == 0) disTo[i][j] = energy[i][j]; else disTo[i][j] = Double.POSITIVE_INFINITY; &#125; &#125; //这里的顺序错了，因为 这里比较特殊的是矩阵的存法，所以必须将循环翻过来进行存取 for (int j = 0; j &lt; height - 1; j++) &#123; for (int i = 0; i &lt; width; i++) &#123; relaxVertical(disTo, edgeTo, i, j); &#125; &#125; double min = Double.POSITIVE_INFINITY; int index = -1; for (int i = 0; i &lt; width; i++) &#123; if (min &gt; disTo[i][height - 1]) &#123; min = disTo[i][height - 1]; index = i; &#125; &#125; seam[height - 1] = index; for (int i = height - 2; i &gt;= 0; i--) &#123; index = edgeTo[index][i + 1]; seam[i] = index; &#125; return seam; &#125; // remove horizontal seam from current picture public void removeHorizontalSeam(int[] seam) &#123; transform(); removeVerticalSeam(seam); transform(); &#125; private void check(int[] seam) &#123; if (width &lt;= 1 || seam == null || seam.length != height) &#123; throw new IllegalArgumentException(); &#125; for (int i = 0; i &lt; height; i++) &#123; if (seam[i] &lt; 0 || seam[i] &gt; width - 1) &#123; throw new IllegalArgumentException(); &#125; if (i &gt; 0 &amp;&amp; Math.abs(seam[i - 1] - seam[i]) &gt; 1) &#123; throw new IllegalArgumentException(); &#125; &#125; &#125; // remove vertical seam from current picture public void removeVerticalSeam(int[] seam) &#123; check(seam); int min = Integer.MAX_VALUE; int max = 0; for (int i = 0; i &lt; height; i++) &#123; if (seam[i] &gt; max) max = seam[i]; if (seam[i] &lt; min) min = seam[i]; //这个地方可以直接该位置上将每一个位置的元素进行变化 for (int j = seam[i]; j &lt; width - 1; j++) &#123; picture[j][i] = picture[j + 1][i]; &#125; &#125; width = width - 1; if (min &gt; 0) min--; if (max &gt; width - 1) max = width - 1; for (int j = 0; j &lt; height; j++) &#123; for (int i = min; i &lt;= max; i++) &#123; calculatenergy(i, j); &#125; for (int i = max + 1; i &lt; width - 1; i++) &#123; energy[i][j] = energy[i + 1][j]; &#125; &#125; &#125;&#125; 不过这里需要自己重温一下 上一周的作业 就是图的api这些部分，有的只是会用c++跑，用Java总是感觉有点力不从心，希望后面尽快熟悉起来。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法大作业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WordNet]]></title>
    <url>%2F2019%2F09%2F10%2FWordNet%2F</url>
    <content type="text"><![CDATA[题目链接 题目 我个人觉得这一次大作业得重新做一遍，因为对于这次的大作业有一些地方，总还是弄不清楚，最关键的就是这次的图里面有一些api需要花时间去弄清楚 所以这里就不贴讲解了，时间过去太久了，反而自己也搞忘了，所以这里直接贴出代码 代码SAP.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174package Programming_Assignment_6;import edu.princeton.cs.algs4.Digraph;import java.util.LinkedList;import java.util.Queue;import java.util.Stack;public class SAP &#123; private int length; private int ancestor; private final Digraph copyG; private int[] distTo1; private int[] distTo2; private boolean[] marked1; private boolean[] marked2; private final Stack&lt;Integer&gt; stack1; private final Stack&lt;Integer&gt; stack2; // constructor takes a digraph (not necessarily a DAG) public SAP(Digraph G) &#123; if (G == null) throw new IllegalArgumentException("argument to G"); copyG = new Digraph(G); distTo1 = new int [G.V()]; distTo2 = new int [G.V()]; marked1 = new boolean[G.V()]; marked2 = new boolean[G.V()]; stack1 = new Stack&lt;&gt;(); stack2 = new Stack&lt;&gt;(); &#125; private void checkVertex(int x) &#123; int v = marked1.length; if (x &lt; 0 || x &gt;= v) throw new IllegalArgumentException(); &#125; private void checkVertices(Iterable&lt;Integer&gt; x) &#123; if (x == null) throw new IllegalArgumentException(); int v = marked1.length; for (Integer vv :x) &#123; if (vv == null) throw new IllegalArgumentException(); if (vv &lt; 0 || vv &gt;= v) throw new IllegalArgumentException(); &#125; &#125; private void init() &#123; while (!stack1.isEmpty()) &#123; int v = stack1.pop(); marked1[v] = false; &#125; while (!stack2.isEmpty()) &#123; int v = stack2.pop(); marked2[v] = false; &#125; &#125; // length of shortest ancestral path between v and w; -1 if no such path public int length(int v, int w) &#123; checkVertex(v); checkVertex(w); compute(v, w); return length; &#125; private void compute(int v, int w) &#123; length = -1; ancestor = -1; distTo1[v] = 0; distTo2[w] = 0; marked1[v] = true; marked2[w] = true; stack1.push(v); stack2.push(w); Queue&lt;Integer&gt; q1 = new LinkedList&lt;&gt;(); Queue&lt;Integer&gt; q2 = new LinkedList&lt;&gt;(); q1.add(v); q2.add(w); bfs(q1, q2); &#125; private void compute(Iterable&lt;Integer&gt; v, Iterable&lt;Integer&gt; w) &#123; length = -1; ancestor = -1; Queue&lt;Integer&gt; q1 = new LinkedList&lt;&gt;(); Queue&lt;Integer&gt; q2 = new LinkedList&lt;&gt;(); for (int x :v) &#123; marked1[x] = true; stack1.push(x); distTo1[x] = 0; q1.add(x); &#125; for (int x: w) &#123; marked2[x] = true; stack2.push(x); distTo2[x] = 0; q2.add(x); &#125; bfs(q1, q2); &#125; private void bfs(Queue&lt;Integer&gt; q1, Queue&lt;Integer&gt; q2) &#123; while (!q1.isEmpty() || !q2.isEmpty()) &#123; if (!q1.isEmpty()) &#123; int v = q1.remove(); if (marked2[v]) &#123; if (distTo1[v] + distTo2[v] &lt; length || length == -1) &#123; ancestor = v; length = distTo1[v] + distTo2[v]; &#125; &#125; if (distTo1[v] &lt; length || length == -1) &#123; for (int w: copyG.adj(v)) &#123; if (!marked1[w]) &#123; distTo1[w] = distTo1[v] + 1; marked1[w] = true; stack1.push(w); q1.add(w); &#125; &#125; &#125; &#125; if (!q2.isEmpty()) &#123; int v = q2.remove(); if (marked1[v]) &#123; if (distTo1[v] + distTo2[v] &lt; length || length == -1) &#123; ancestor = v; length = distTo1[v] + distTo2[v]; &#125; &#125; if (distTo2[v] &lt; length || length == -1) &#123; for (int w:copyG.adj(v)) &#123; if (!marked2[w]) &#123; distTo2[w] = distTo2[v] + 1; marked2[w] = true; stack2.push(w); q2.add(w); &#125; &#125; &#125; &#125; &#125; init(); &#125; // a common ancestor of v and w that participates in a shortest ancestral path; -1 if no such path public int ancestor(int v, int w) &#123; checkVertex(v); checkVertex(w); compute(v, w); return ancestor; &#125; // length of shortest ancestral path between any vertex in v and any vertex in w; -1 if no such path public int length(Iterable&lt;Integer&gt; v, Iterable&lt;Integer&gt; w) &#123; checkVertices(v); checkVertices(w); compute(v, w); return length; &#125; // a common ancestor that participates in shortest ancestral path; -1 if no such path public int ancestor(Iterable&lt;Integer&gt; v, Iterable&lt;Integer&gt; w) &#123; checkVertices(v); checkVertices(w); compute(v, w); return ancestor; &#125;&#125; Wordnet.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147package Programming_Assignment_6;import edu.princeton.cs.algs4.Digraph;import edu.princeton.cs.algs4.In;import edu.princeton.cs.algs4.Topological;import java.util.Map;import java.util.TreeMap;import java.util.TreeSet;public class WordNet &#123; private Map&lt;String, TreeSet&lt;Integer&gt; &gt; synSets; private Map&lt;Integer, String&gt; ssynsets; private Digraph hyperNyms; private int idSum; private int outSum; private SAP sap; // constructor takes the name of the two input files public WordNet(String synsets, String hypernyms) &#123; if (synsets == null || hypernyms == null) &#123; throw new IllegalArgumentException("arguments to WordNet() is null"); &#125; readsynset(synsets); readhypernyms(hypernyms); &#125; private void readsynset(String synsets) &#123; synSets = new TreeMap&lt;String, TreeSet&lt;Integer&gt; &gt;(); this.ssynsets = new TreeMap&lt;Integer, String&gt;(); In synset = new In(synsets); idSum = 0; while (synset.hasNextLine()) &#123; idSum++; String str = synset.readLine(); String[] field = str.split(","); int id = Integer.parseInt(field[0]); this.ssynsets.put(id, field[1]); String[] nons = field[1].split(" "); for (String tmp : nons) &#123; if (synSets.containsKey(tmp)) &#123; if (synSets.containsKey(tmp)) &#123; synSets.get(tmp).add(id); &#125; &#125; else &#123; TreeSet&lt;Integer&gt; ids = new TreeSet&lt;&gt;(); ids.add(id); synSets.put(tmp, ids); &#125; &#125; &#125; &#125; private void readhypernyms(String hypernyms) &#123; hyperNyms = new Digraph(idSum); In hypernym = new In(hypernyms); boolean[] outToal = new boolean[idSum]; while (hypernym.hasNextLine()) &#123; String str = hypernym.readLine(); String[] field = str.split(","); int v = Integer.parseInt(field[0]); for (int i = 1; i &lt; field.length; i++) &#123; int w = Integer.parseInt(field[i]); hyperNyms.addEdge(v, w); &#125; if (!outToal[v] &amp;&amp; field.length &gt; 1) &#123; outSum++; &#125; outToal[v] = true; &#125; isRootRAG(); sap = new SAP(hyperNyms); &#125; private void isRootRAG() &#123; if (idSum - outSum != 1) &#123; throw new IllegalArgumentException("more than one root"); &#125; Topological TO = new Topological(hyperNyms); if (!TO.hasOrder()) &#123; throw new IllegalArgumentException("is not a Root RAG"); &#125; &#125; // returns all WordNet nouns public Iterable&lt;String&gt; nouns() &#123; return synSets.keySet(); &#125; // is the word a WordNet noun? public boolean isNoun(String word) &#123; if (word == null) throw new IllegalArgumentException("word is null"); return synSets.containsKey(word); &#125; public int distance(String nounA, String nounB) &#123; if (nounA == null || nounB == null) &#123; throw new IllegalArgumentException("nounA or nounB is null"); &#125; if (!isNoun(nounA) || !isNoun(nounB)) &#123; throw new IllegalArgumentException("the two noun is not exist"); &#125; TreeSet&lt;Integer&gt; setA = synSets.get(nounA); TreeSet&lt;Integer&gt; setB = synSets.get(nounB); if (setA.size() == 1 &amp;&amp; setB.size() == 1) &#123; return sap.length(setA.last(), setB.last()); &#125; else return sap.length(setA, setB); &#125; // a synset (second field of synsets.txt) that is the common ancestor of nounA and nounB // in a shortest ancestral path (defined below) public String sap(String nounA, String nounB) &#123; if (nounA == null || nounB == null) &#123; throw new IllegalArgumentException(); &#125; if (!isNoun(nounA) || !isNoun(nounB)) &#123; throw new IllegalArgumentException(); &#125; TreeSet&lt;Integer&gt; setA = synSets.get(nounA); TreeSet&lt;Integer&gt; setB = synSets.get(nounB); int ID; if (setA.size() == 1 &amp;&amp; setB.size() == 1) &#123; ID = sap.ancestor(setA.last(), setB.last()); &#125; else ID = sap.ancestor(setA, setB); return ssynsets.get(ID); &#125;&#125; Outcast.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445package Programming_Assignment_6;import edu.princeton.cs.algs4.In;import edu.princeton.cs.algs4.StdOut;public class Outcast &#123; private final WordNet wordnet; public Outcast(WordNet wordnet) &#123; if (wordnet == null) throw new IllegalArgumentException("wrong wordnet"); this.wordnet = wordnet; &#125; public String outcast(String[] nouns) &#123; if (nouns == null) throw new IllegalArgumentException("this nouns is null"); int Maxn = 0; int index = -1; for (int i = 0; i &lt; nouns.length; i++) &#123; int sum = 0; for (int j = 0; j &lt; nouns.length; j++) &#123; if (i == j) continue; int tmp = wordnet.distance(nouns[i], nouns[j]); if (tmp == -1) continue; sum += tmp; &#125; if (sum &gt; Maxn) &#123; Maxn = sum; index = i; &#125; &#125; if (index == -1) throw new IllegalArgumentException("error"); return nouns[index]; &#125; public static void main(String[] args) &#123; WordNet wordnet = new WordNet(args[0], args[1]); Outcast outcast = new Outcast(wordnet); for (int t = 2; t &lt; args.length; t++) &#123; In in = new In(args[t]); String[] nouns = in.readAllStrings(); StdOut.println(args[t] + ": " + outcast.outcast(nouns)); &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PAT甲级题目解析及考试总结]]></title>
    <url>%2F2019%2F08%2F30%2FPAT%E7%94%B2%E7%BA%A7%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93%E5%8F%8A%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[首先这里贴出 所有题目的解析。甲级题目解析 本来最先开始想的是 一道题一道题的总结，但是到后面发现好像真的没有这个时间（主要还是自己懒，宁愿把这个时间用来刷剧） 这里不能直接插入pdf，所以只能转化为图片一点一点的看咯 考时状况双非新大三，acm铁牌选手，第一次考甲级 92/100 但是觉得排名有点弱 将近300名了 前面满分大佬 这么流弊的吗？ 第一道题的时候卡了半个小时， 用了各种剪枝，把所有没有进位的情况全部剔除掉了，也注意到了排序， 到最后都开始怀疑自己gcd是不是写错了， 于是果断放弃，开始写第二道题。 写第二道题的时候，由于读英文读的很快，然后开始写， 最先开始 我是分三种情况 mod 3 ，3种情况去写，然后考虑到各种情况去终止， 然后写完去测试样例，直接内存崩了，估计超限了， 然后这个时候 我旁边的那位小姐姐，交卷了？！！ 似乎不到一个半小时，直接喊了老师交卷了， 然后我心态就有点崩了,这里想找找那位小姐姐 (西安交大 402考场的 41号 还是 39 号的小姐姐)，小姐姐 你真的厉害... 这个时候由于心态有点炸，觉得强行开这道题不太可能于是转到第三题去了。 第三题跟之前甲级有道题很像，自己轻松写完代码之后，以为是后序遍历， 但是，当没有左子树的时候，就变成前缀表达式了， 先开始没有注意到，各种地方去调试加hello world，去找运行位置，然后，答案跟样例一模一样的时候去提交结果全错， 这个时候我发现，万恶的hello world 还在我的输出答案中！！！ 整个时间花了30多分钟吧 感谢hello world 教会我人生哲理.... 第四道题 一看就觉得是道板子题，直接去写 dijkstra 的板子， 写完之后再看题目，不知道是英文的问题，觉得表述上有点奇怪， 先开始觉得只需要判断是不是在最短路序列上，后来才发现只需要去判断距离就行了， 感觉又变成暴力杯中的找规律，所以就直接过了。 这个时候还有一个小时左右的时间，于是这个时候返回第二题，删掉全部代码，重新写， 认认真真静下来读完题目，才发现贼简单，自己想复杂了， 因为不可能出现，大序列结束，小序列不结束的情况，想通这个就直接开始写， 果然直接就一发ac了，还是心理暗示最重要，只能说小姐姐太厉害了。 还有40分钟左右，只剩下第一题的8分没拿到手了， 于是回去各种找规律，重新仔细扣题目，然后当我再次交的时候，还是有问题 ， 当时就很懵逼，脑海里面各种算法开始交杂，二分，线段树，树状数组？？？ 然后再次冷静下来去写的时候，我记得是还有二十多分钟的时候 服务器炸了， 我这个人还是挺迷信的，觉得天意如此（好像提交的时间也占排名）就直接交了走人了。 不过今年刚大三，得明年考的pat成绩才算，所以这次就当打怪升级练手咯， 不过 听说还会考很多顶级类似的题目，下次得把顶级的题目刷一遍再来考。 看到知乎里面都是满分的大佬，不开心。 sad face... 考后总结第一次考甲级 考了92，分数上还不错，但是排名也太弱鸡了，枉费了我提前了20多分钟交卷，早知道这个排名不是看提交速度的话，我应该坚持到最后一刻的，当时的想法就是觉得 92分够了，因为知道自己明年还会再去考一次式，当时似乎有点轻松，所有有点松懈，希望下次能一步登天，有看这里的朋友，可以一起约着备考明年的pat， 不过最近也不能松懈，再补前面的坑的同时，还要好好准备后面的其他考试了。 加油。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>浙大pat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.27线性dp与区间dp题目解析]]></title>
    <url>%2F2019%2F07%2F27%2F7-27%E7%BA%BF%E6%80%A7dp%E4%B8%8E%E5%8C%BA%E9%97%B4dp%2F</url>
    <content type="text"><![CDATA[A.导弹袭击代码如下：123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;cstdio&gt;using namespace std;int main()&#123; //freopen("test1.in", "r", stdin); //freopen("test1.out", "w", stdout); int T; while (~scanf("%d", &amp;T)) &#123; int dp[T + 5]; int data[T + 5]; data[0] = 0; int num = 0; for (int i = 1; i &lt;= T; i++) &#123; cin &gt;&gt; data[i]; dp[i] = 1; &#125; for (int i = 2; i &lt;= T; i++) &#123; for (int j = i - 1; j &gt;= 1; j--) &#123; if (data[i] &gt; data[j]) &#123; dp[i] = max(dp[i], dp[j] + 1); &#125; num = max(num, dp[i]); &#125; &#125; cout &lt;&lt; num &lt;&lt; endl; &#125; return 0;&#125; B.Common Subsequence代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;string s1, s2, tmp;int main()&#123; //freopen("test1.in", "r", stdin); //freopen("test1.out", "w", stdout); while (cin &gt;&gt; s1 &gt;&gt; s2) &#123; if (s1.size() &lt; s2.size()) &#123; tmp = s1; s1 = s2; s2 = tmp; &#125; int dp[s1.size() + 10][s1.size() + 10]; memset(dp, 0, sizeof dp); int Max = 0; for (int i = 0; i &lt; s2.size(); i++) &#123; int k = i + 1; for (int j = 0; j &lt; s1.size(); j++) &#123; int l = j + 1; if (s1[j] == s2[i]) &#123; dp[k][l] = dp[k - 1][l - 1] + 1; &#125; else dp[k][l] = max(dp[k - 1][l], dp[k][l - 1]); Max = max(Max, dp[k][l]); &#125; &#125; cout &lt;&lt; dp[s2.size()][s1.size()] &lt;&lt; endl; &#125; return 0;&#125; C.滑雪代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;cstdlib&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;map&gt;#define INF 0x3f3f3f3f#define N 110using namespace std;int dis[4][2] = &#123;&#123;0, 1&#125;, &#123;1, 0&#125;, &#123;0, -1&#125;, &#123;-1, 0&#125;&#125;;int len[N][N], a[N][N];int m, n;int dp(int x, int y)&#123; int tx, ty, k, s, ms; ms = 0; if (len[x][y] != 0) //递归出口； return len[x][y]; for (k = 0; k &lt;= 3; k++) &#123; tx = dis[k][0] + x; ty = dis[k][1] + y; if (tx &lt; 0 || ty &lt; 0 || tx &gt; m - 1 || ty &gt; n - 1) continue; if (a[tx][ty] &lt; a[x][y]) &#123; s = dp(tx, ty); ms = max(ms, s); &#125; &#125; len[x][y] = ms + 1; return len[x][y];&#125;int main()&#123; //freopen("test1.in", "r", stdin); //freopen("test1.out", "w", stdout); int i, j, Max; while (~scanf("%d%d", &amp;m, &amp;n)) &#123; memset(a, 0, sizeof(a)); memset(len, 0, sizeof(len)); for (i = 0; i &lt; m; i++) for (j = 0; j &lt; n; j++) scanf("%d", &amp;a[i][j]); Max = -1; for (i = 0; i &lt; m; i++) for (j = 0; j &lt; n; j++) Max = max(Max, dp(i, j)); printf("%d\n", Max); &#125; return 0;&#125; D.小红红益智游戏代码如下： 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;algorithm&gt;using namespace std;const int INF = -0x3f3f3f3f; //定义一个无穷大的值const int maxn = 205;int dp[maxn][maxn];int sum[maxn][maxn], n, x;int main()&#123; sum[0][0] = 0; //初始化 while (scanf("%d", &amp;n) != EOF) &#123; for (int i = 1; i &lt;= n; i++) &#123; scanf("%d", &amp;x); sum[i][i] = x; fill(dp[i], dp[i] + maxn, INF); //初始化 dp[i][i] = 0; &#125; //区间dp for (int len = 2; len &lt;= n; len++) //枚举区间长度 &#123; for (int i = 1; (i + len - 1) &lt;= n; i++) //枚举区间起点 &#123; int j = i + len - 1; for (int k = i; k &lt; j; k++) //枚举中断点 &#123; sum[i][j] = sum[i][k] + sum[k + 1][j]; dp[i][j] = max(dp[i][j], dp[i][k] + dp[k + 1][j] + sum[i][j]); &#125; &#125; &#125; printf("%d\n", dp[1][n]); &#125; return 0;&#125; E.最大括号匹配数代码如下： 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;const int maxn = 105;int dp[maxn][maxn];string V;int main()&#123; while (cin &gt;&gt; V, V[0] != '0') &#123; int n = V.size(); for (int i = 0; i &lt;= n; i++) &#123; memset(dp[i], 0, sizeof(dp[i])); &#125; for (int len = 2; len &lt;= n; len++) &#123; for (int i = 0; i + len - 1 &lt; n; i++) &#123; int j = i + len - 1; if (V[i] == '(' &amp;&amp; V[j] == ')' || V[i] == '[' &amp;&amp; V[j] == ']') &#123; if (i + 1 &gt; j - 1) dp[i][j] = 2; else dp[i][j] = dp[i + 1][j - 1] + 2; &#125; for (int k = i; k &lt; j; k++) &#123; dp[i][j] = max(dp[i][j], dp[i][k] + dp[k + 1][j]); &#125; &#125; &#125; cout &lt;&lt; dp[0][n - 1] &lt;&lt; endl; V.clear(); &#125; return 0;&#125; F.红红跳格子代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;const int maxn = 1005;int dp[maxn];int num[maxn];//总结一下这类的线性DP。//这里dp数组保存的是每一个点为止这个位置上的递增子序列之和//然后这个地方的每一个确定的值再与之前的去比较，最后加上相应的值即可。int main()&#123; //freopen("test1.in", "r", stdin); //freopen("test1.out", "w", stdout); int T; while (cin &gt;&gt; T &amp;&amp; T) &#123; for (int i = 1; i &lt;= T; i++) &#123; cin &gt;&gt; num[i]; &#125; memset(dp, 0, sizeof dp); dp[1] = num[1]; for (int i = 2; i &lt;= T; i++) &#123; dp[i] = num[i]; for (int j = i - 1; j &gt;= 1; j--) &#123; if (num[i] &gt; num[j]) &#123; dp[i] = max(dp[i], dp[j] + num[i]); &#125; &#125; &#125; int Max = 0; for (int i = 1; i &lt;= T; i++) &#123; Max = max(Max, dp[i]); &#125; cout &lt;&lt; Max &lt;&lt; endl; &#125; return 0;&#125; G.请客的红红代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/* 这道题就是被前面的思想所影响，其实这道题不像前面前面几个状态一定会影响到后面的状态， 仅仅只是一个一维的线性dp，考虑到前面的这些情况，他是另外的两个dp方程组进行放与不放的操作 所以不会涉及到多个循环反复到前面之前的状态去寻找， 只需要在一次遍历的过程中去实现究竟是一次还是两次的操作。 跟着每一个状态往下面找出每一个位置的局部最优解 最后得到结果。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;using namespace std;const int maxn = 2005;int dp[maxn];int s[maxn];int d[maxn];int main()&#123; //freopen("test1.in", "r", stdin); //freopen("test1.out", "w", stdout); int T; cin &gt;&gt; T; while (T--) &#123; int n; cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; s[i]; dp[i] = s[i]; &#125; d[0] = 0; d[1] = 0; for (int i = 2; i &lt;= n; i++) &#123; cin &gt;&gt; d[i]; &#125; dp[0] = 0; dp[1] = s[1]; for (int i = 2; i &lt;= n; i++) &#123; dp[i] = min(dp[i - 1] + s[i], dp[i - 2] + d[i]); &#125; int h = dp[n] / 3600 + 8; int m = dp[n] / 60 % 60; int s = dp[n] % 60; if (h &lt;= 12) printf("%02d:%02d:%02d am\n", h, m, s); else printf("%02d:%02d:%02d pm\n", h, m, s); &#125; return 0;&#125; H.红红与糖果代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;cstdio&gt;using namespace std;const int maxn = 100005;int n;int dp[maxn][11];int date[maxn][11];int _time, pie;int main()&#123; //freopen("test1.in", "r", stdin); //freopen("test1.out", "w", stdout); while (scanf("%d", &amp;n) &amp;&amp; n != 0) &#123; memset(date, 0, sizeof date); memset(dp, 0, sizeof dp); int maxTime = 0; for (int i = 0; i &lt; n; i++) &#123; scanf("%d %d", &amp;pie, &amp;_time); date[_time][pie]++; maxTime = max(maxTime, _time); &#125; //第一秒的运行时间，里面所有的运行情况 dp[1][4] = date[1][4]; dp[1][5] = date[1][5]; dp[1][6] = date[1][6]; //这里其实是由第二次运转的时间来看，因为第一秒的时间我已经全部标记下来了。 for (int i = 2; i &lt;= maxTime; i++) &#123; for (int j = 0; j &lt; 11; j++) &#123; dp[i][j] = dp[i - 1][j]; //不过需要注意的是 这些全部都是前几秒的动作，上一秒更新的状态，到下一秒后执行的状态 //下面这个地方就是很奇幻的地方了，一共三个状态，取出来还是不取出来，就是这三种状态 //左边一个位置取，还是右边一个位置取，还是原本的位置去出来。 if (j &gt; 0) dp[i][j] = max(dp[i][j], dp[i - 1][j - 1]); if (j &lt; 10) dp[i][j] = max(dp[i][j], dp[i - 1][j + 1]); dp[i][j] += date[i][j]; &#125; &#125; int Max = 0; for (int i = 0; i &lt; 11; i++) &#123; Max = max(Max, dp[maxTime][i]); &#125; cout &lt;&lt; Max &lt;&lt; endl; &#125; return 0;&#125; I.老左的矩阵代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/* 这个地方就直接就是答案的思路了，由一种倒叙的方法往前面推，将对角线存储的数， 就是当前能存储到的最大的矩阵。 状态转移方程就是 dp[i][j] 由 dp[i - k][j]与 dp[i][j - k] 是否相等然后再来存储 不过这里有一个技巧就是 每一个仅仅只是存储这个数组能够承受的最大值、 自己想的办法没有考虑到状态的迁移，也就是没有考虑到状态与状态之间的联系，这里就展现出来了。 将每一个值存储到dp[i - 1][j + 1] 上，然后再一次对其进行验证。 */#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int n;const int maxn = 1005;char ch[maxn][maxn];int dp[maxn][maxn];int main()&#123; //freopen("test2.in", "r", stdin); //freopen("test2.out", "w", stdout); while (cin &gt;&gt; n &amp;&amp; n) &#123; getchar(); for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; cin &gt;&gt; ch[i][j]; dp[i][j] = 1; &#125; getchar(); &#125; int Max = 1; for (int i = 1; i &lt;= n; i++) &#123; for (int j = n; j &gt;= 1; j--) &#123; if (i == 1 || j == n) continue; int tmp = dp[i - 1][j + 1]; for (int k = 1; k &lt;= tmp; k++) &#123; if (ch[i - k][j] == ch[i][j + k]) dp[i][j]++; else break; &#125; Max = max(Max, dp[i][j]); &#125; &#125; printf("%d\n", Max); &#125; return 0;&#125; J.阿春取数字代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* 这道题目就是典型的区间DP的题目了，对一个区间里面的值进行动态规划的求解，就像下面的状态转移方程 dp[i][j] = max(dp[i + 1][j] + num[i] *(n + i - j), dp[i][j - 1] + num[j] * (n + i - j)); 这道题唯一特别难想到的是，这道题目是一道逆序求解的问题， 意思就是从后面的状态往前面推，这当时的我就完全没有想到了。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;using namespace std;int n;const int maxn = 2005;int dp[maxn][maxn];int num[maxn];int main()&#123; //freopen("test3.in", "r", stdin); //freopen("test3.out", "w", stdout); while (~scanf("%d", &amp;n)) &#123; memset(dp, 0, sizeof dp); for (int i = 1; i &lt;= n; i++) &#123; scanf("%d", &amp;num[i]); dp[i][i] = num[i]; &#125; for (int i = n; i &gt;= 1; i--) &#123; for (int j = i; j &lt;= n; j++) &#123; //这里乘以 n + i - j 其实一开始的变形就是 n - (j - i + 1) + 1 dp[i][j] = max(dp[i + 1][j] + num[i] * (n + i - j), dp[i][j - 1] + num[j] * (n + i - j)); &#125; &#125; printf("%d\n", dp[1][n]); &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>习题解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.26_记忆化搜索和背包习题解析]]></title>
    <url>%2F2019%2F07%2F26%2F7-26-%E8%AE%B0%E5%BF%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%92%8C%E8%83%8C%E5%8C%85%E4%B9%A0%E9%A2%98%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[A.小辉辉玩积木代码如下：1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;#include &lt;cmath&gt;using namespace std;long long a[60] = &#123;1, 2&#125;;long long f(int n) &#123; if (a[n]) return a[n]; return a[n] = f(n - 2) + f(n - 1);&#125;int main()&#123; std::ios::sync_with_stdio(false); cin.tie(0); int N; while (cin &gt;&gt; N) &#123; cout &lt;&lt; f(N - 1) &lt;&lt; endl; &#125; return 0; return 0;&#125; 这道题就仅仅只是用到了一个递归和记忆化搜索，属于基础简单的题目。 B.入侵和反击代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;#include &lt;cmath&gt;using namespace std;int main()&#123; std::ios::sync_with_stdio(false); cin.tie(0); int T; cin &gt;&gt; T; while (T--) &#123; int n; cin &gt;&gt; n; int dp[n + 5]; int num[n + 5]; for (int i = 0; i &lt; n;i ++) &#123; cin &gt;&gt; num[i]; &#125; //memset(dp,1,sizeof dp); //fill (num,num+n,1); dp[0] = 1; for (int i = 1;i &lt; n; i++) &#123; dp[i] = 1; //这个地方的状态转移方程，需要去细想比较一下。 for (int j = 0; j &lt; i; j++) &#123; if (num[i] &lt;= num[j]) &#123; dp[i] = max(dp[i],dp[j] + 1); &#125; &#125; &#125; int Max = -1; for (int i = 0; i &lt; n; i++) &#123; Max = max(Max,dp[i]); &#125; cout &lt;&lt; n - Max &lt;&lt; endl; // 9 17 8 19 3 // 1 1 2 1 3 &#125; return 0;&#125; C.红红数钞票代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* 其实这道题也算是一道特别简单的题目，还是动态规划里面最基础的问题，但是总是容易去弄混。 记得自己当时的问题就在于 这里每一次相加的和，如何保证后面加了负数之后，再次加上一个正数不被影响呢， 下面的注释里面有写， 因为题目中限制了，如果这道题有多个答案，比如说 前面与后面相加为零，但是后面的那个正数正好作为最后的正确答案的话 比如 1 2 -3 8 10 -1 1 2 -3 正好相加为0 但是题目中要求的 序列 1 2 -3 8 作为最后的结果序列。 自己当时也在这一块上面纠结。*/#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;cstdio&gt;#include&lt;queue&gt;#include&lt;map&gt;#include&lt;cmath&gt;using namespace std;int main()&#123; std::ios::sync_with_stdio(false); int m; cin &gt;&gt; m; int num[m + 5]; for (int i = 0; i &lt; m; i++) &#123; cin &gt;&gt; num[i]; &#125; int left = 0; int tmpleft = 0; int right = m - 1; int tmp = 0; int Max = -1; for (int i = 0; i &lt; m; i ++) &#123; tmp += num[i]; if (tmp &lt; 0) &#123; tmp = 0; tmpleft = i + 1; &#125; else if (tmp &gt; Max) &#123; Max = tmp; right = i; left = tmpleft; &#125; &#125; if (Max &gt;= 0) cout &lt;&lt; Max &lt;&lt; " " &lt;&lt; num[left] &lt;&lt; " " &lt;&lt; num[right] &lt;&lt; endl; else cout &lt;&lt; 0 &lt;&lt; " " &lt;&lt; num[0] &lt;&lt; " " &lt;&lt; num[m - 1] &lt;&lt; endl; return 0;&#125; D.Charm Bracelet代码如下：12345678910111213141516171819202122232425262728293031323334/* 第一道题属于一个简单的01背包模板题目，这里不多说 可以直接套模板。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int n,m;int dp[13000];int w[3500],v[3500];int main()&#123; while (cin &gt;&gt; n &gt;&gt; m) &#123; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; w[i] &gt;&gt; v[i]; &#125; memset(dp,0,sizeof dp); for (int i = 1; i &lt;= n; i++) &#123; for (int j = m; j &gt;= w[i]; j--) &#123; dp[j] = max(dp[j],dp[j - w[i]] + v[i]); &#125; &#125; cout &lt;&lt; dp[m] &lt;&lt; endl; &#125; return 0;&#125; E.红红绝地求生代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* 一段简单的模板题目，不过需要弄清楚的 一维数组与二维数组在这里相应的区别，往往这里会产生很大的区别， 比如第二个循环的开始条件，因为这里是由子问题的堆积，然后一点一点向上升最终得到的问题，所以这李最好控制背包的放与不放的问题、 就比如我在这道题目的第二个问题中出现的错误，就是将j=0这个条件直接掠过去了，其实这里是不对的。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;const int maxn = 1010;long long weight[maxn],value[maxn],dp[maxn][maxn];long v,w;int main()&#123; int T; cin &gt;&gt; T; while(T--) &#123; cin &gt;&gt; w &gt;&gt; v; value[0] = 0; weight[0] = 0; for (int i = 1; i &lt;= w; i++) &#123; cin &gt;&gt; value[i]; &#125; for (int i = 1; i &lt;= w; i++) &#123; cin &gt;&gt; weight[i]; &#125; memset(dp, 0, sizeof dp); for (int i = 1; i &lt;= w; i++) &#123; for (int j = 0; j &lt;= v; j++) &#123; if (j &gt;= weight[i]) &#123; dp[i][j] = max(dp[i - 1][j],dp[i - 1][j - weight[i]] + value[i]); &#125; else dp[i][j] = dp[i - 1][j]; &#125; &#125; cout &lt;&lt; dp[w][v] &lt;&lt; endl; &#125; return 0;&#125; F.一卡通代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/* 一维滚动数组的做法，由于是01背包，所以直接套模板*/#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123; int n; int d[1010]; int dp[1010]; while (cin &gt;&gt; n &amp;&amp; n) &#123; memset(d, 0, sizeof(d)); memset(dp, 0, sizeof(dp)); for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; d[i]; &#125; int p; cin &gt;&gt; p; sort(d + 1, d + n + 1); if (p &lt; 5) &#123; cout &lt;&lt; p &lt;&lt; endl; &#125; else &#123; for (int i = 1; i &lt; n; i++) &#123; for (int j = p - 5; j &gt;= d[i]; j--) &#123; dp[j] = max(dp[j], dp[j - d[i]] + d[i]); &#125; &#125; cout &lt;&lt; p - dp[p - 5] - d[n] &lt;&lt; endl; &#125; &#125; return 0;&#125; 第二种方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* 二维数组直接套模板*//* 这道题神奇的地方就在于 其的重量限制于价值重合在了一起，所以对于这道题而言就是只能重合的去写状态转移方程了 另外需要注意的是最后输出结果的办法，是将最后一个物品交给剩下的最大的钱去购买，这样能彻底用光最后的钱财*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int n,m;const int maxn = 1010;int num[maxn],dp[maxn][maxn];int main()&#123; while (cin &gt;&gt; n &amp;&amp; n) &#123; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; num[i]; &#125; cin &gt;&gt; m; sort(num + 1, num + 1 + n); if (m &lt; 5) &#123; cout &lt;&lt; m &lt;&lt; endl; continue; &#125; memset(dp,0,sizeof dp); //这里与上面一维滚动数组不太一样的是，一维滚动数组是不能有对物品限制的操作。 //意思就是 我二维数组可以算出n-1个数，然后算出最后一个数给出的钱数dp[i - 1][j] //而一维数组由于只有一个参数就是体积容量的参数dp[i] //所以下面多算了一个，最后再通过计算出n-1个物品的体积，再减去相应的钱数，得到最终答案。 for (int i = 1; i &lt;= n; i++) &#123; for (int j = 0; j &lt;= m - 5; j++) &#123; if (j &gt;= num[i]) &#123; dp[i][j] = max(dp[i - 1][j],dp[i - 1][j - num[i]] + num[i]); &#125; else dp[i][j] = dp[i - 1][j]; &#125; &#125; cout &lt;&lt; m - dp[n - 1][m - 5] - num[n] &lt;&lt; endl; &#125; return 0;&#125; G.红红减肥记代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* 这道题使用二维数组就一直就会超时 具体的我也不太清楚，但是 没有办法 只能使用一维滚动数组，进行了相应的空间优化 不过这里需要补充几个知识点 第一 关于二维数组的完全背包状态转移方程 dp[i][j] = max (dp[i - 1][j],dp[i - 1][j - k * c[i]] + k * v[i]); 由上面这个式子就可以得出，状态转移方程 于是 一种空间优化的写法 是直接写成 max(dp[i - 1][j]，dp[i][j - w[i]] + v[i]) 第二 如果换成滚动数组的话 记住 第二个循环的两个顺序，如果是倒叙的话 则就是要保证每一个物品只会取一次，但是如果是正序的话，那么就不需要保证上面所说的顺序了。 而这里官方的解释 就在这里 ： 让 v 递减是为了保证第i次循环中的状态F[i;v]是由状态F[i-1;v-Ci]递推而来。 换句话说，这正是为了保证每件物品只选一次，保证在考虑“选入第 i 件物品”这件策 略时，依据的是一个绝无已经选入第 i 件物品的子结果F[i-1;v-Ci]。而现在完全背 包的特点恰是每种物品可选无限件，所以在考虑“加选一件第 i 种物品”这种策略时， 却正需要一个可能已选入第 i 种物品的子结果F[i;v-Ci]，所以就可以并且必须采用v 递增的顺序循环。这就是这个简单的程序为何成立的道理。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include&lt;cstdio&gt;using namespace std;int n, a, b, m;const int maxn = 110;int happiness[maxn], kaluli[maxn];int dp[110000];int main()&#123; while (~scanf("%d",&amp;n)) &#123; for (int i = 1; i &lt;= n; i++) &#123; scanf("%d %d",&amp;happiness[i],&amp;kaluli[i]); &#125; scanf("%d",&amp;m); memset(dp,0,sizeof dp); for (int i = 1; i &lt;= n; i++) &#123; for (int j = kaluli[i]; j &lt;= m; j++) &#123; dp[j] = max(dp[j],dp[j - kaluli[i]] + happiness[i]); &#125; &#125; printf("%d\n",dp[m]); &#125; return 0;&#125; H.Piggy-Bank代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* 这道题是一个完全背包的裸题，对于这道题而言更加神奇的地方就在于其实求最小值而不是求最大值 所以在最先开始初始化的时候不应该去初始化为0，而应该初始化为无穷大 而千万不要忘记了再初始化的时候一定要对第一个状态进行一个单独赋值是等于0，还是等于无穷大，这个等到时候再看。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt; using namespace std;int _beg,_end;const int maxn = 505;int v[maxn],w[maxn];int dp[10010];int main()&#123; int T; cin &gt;&gt; T; while (T--) &#123; scanf("%d %d",&amp;_beg,&amp;_end); int bottle = _end - _beg; int n; scanf("%d",&amp;n); for (int i = 1; i &lt;= n; i++)&#123; scanf("%d %d",&amp;v[i],&amp;w[i]); &#125; memset(dp,0x3f3f3f3f,sizeof dp); dp[0] = 0; for (int i = 1; i &lt;= n;i ++) &#123; for (int j = w[i]; j &lt;= bottle; j++) &#123; dp[j] = min(dp[j],dp[j - w[i]] + v[i]); &#125; &#125; if (dp[bottle] != 0x3f3f3f3f) cout &lt;&lt; "The minimum amount of money in the piggy-bank is " &lt;&lt; dp[bottle] &lt;&lt; "." &lt;&lt; endl; else cout &lt;&lt; "This is impossible." &lt;&lt; endl; &#125; return 0;&#125; I.美元的困惑代码如下： 12345678910111213141516171819202122232425import java.util.Scanner;import java.math.BigInteger;public class Main &#123; public static void main(String[] args) &#123; int n,k; Scanner in = new Scanner(System.in); while (in.hasNext()) &#123; BigInteger[] dp = new BigInteger[1005]; n = in.nextInt(); k = in.nextInt(); dp[0] = new BigInteger("1"); for (int i = 1; i &lt;= n; i++) &#123; dp[i] = new BigInteger("0"); &#125; for (int i = 1; i &lt;= k; i++) &#123; for (int j = i; j &lt;= n; j++) &#123; dp[j] = dp[j].add(dp[j - i]); &#125; &#125; System.out.println(dp[n]); &#125; &#125;&#125; J.Coins123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* 这道题神奇的地方就是将多重背包的裸题进行了改变， 主要就是每一次增加的价值会发生改变，这才是最关键的地方。 这里的价值就不再是个数，而是进行一个打表，通过这个打表来判断这个重量是否能够达到。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int n;int bag;bool dp[100040];int value[105],number[105];int cnt = 0;void zeroonepack(int weight, int value)&#123; for (int j = bag; j &gt;= weight; j--) &#123; if (!dp[j] &amp;&amp; dp[j - weight])&#123; dp[j] = true; cnt ++; &#125; &#125;&#125;//完全背包void completepack(int weight, int value)&#123; for (int j = weight; j &lt;= bag; j++) &#123; if (!dp[j] &amp;&amp; dp[j - weight]) &#123; dp[j] = true; cnt ++; &#125; &#125;&#125;//多重背包void multilpack(int weight, int number, int value)&#123; //第一种情况就是 如果这件物品所有的重量是小于背包的重量的话 //那么对于背包而言 这个物品是可以取无限大。 if (bag &lt;= number * weight) &#123; completepack(weight, value); return; &#125; //而超过的这个范围的就只能使用01背包 然后使用二进制的方法 //将每一类型的背包进行一个分组 //后面再依次分别使用多重背包。 int k = 1; while (k &lt; number) &#123; zeroonepack(k * weight, k * value); number = number - k; k = k * 2; &#125; zeroonepack(number * weight, number * value);&#125;int main()&#123; while (cin &gt;&gt; n &gt;&gt; bag &amp;&amp; n &amp;&amp; bag) &#123; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; value[i]; &#125; for (int i = 1; i &lt;= n;i ++) &#123; cin &gt;&gt; number[i]; &#125; cnt = 0; memset(dp,0,sizeof dp); dp[0] = 1; for (int i = 1; i &lt;= n ;i ++) &#123; multilpack(value[i],number[i],value[i]); &#125; cout &lt;&lt; cnt &lt;&lt; endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>习题解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTA 1013 两种方法解决点与路径的关系]]></title>
    <url>%2F2019%2F07%2F24%2FPTA-1013-%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%E8%A7%A3%E5%86%B3%E7%82%B9%E4%B8%8E%E8%B7%AF%E5%BE%84%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[这道题很有趣，这里直接贴出题目。 这道题纯粹就是给出一系列边与点的关系，然后再去掉一个点，看看剩余需要多少个点才能连接成一个完整的图。 第一种方法并查集123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* 这道题最先开始真的是不知道何从入手，因为本身对于图论的相关知识并不是特别在行 这道题的两种方法，第一就是并查集，第二就是利用dfs遍历完所有需要遍历的点。*/#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;cstdio&gt;#include&lt;queue&gt;#include&lt;map&gt;#include&lt;cmath&gt;using namespace std;int N,M,K;const int maxn = 1005;int fa[maxn];//再次错在了这种地方，范围小了，这里题目虽然并没有给出相应的范围//但是按照每一条边之间的链接来看，这里需要加大其的范围。pair&lt;int,int&gt; pp[maxn * maxn];void init() &#123; for (int i = 0; i &lt;= N; i++) &#123; fa[i] = i; &#125;&#125;int find(int x) &#123; if (fa[x] != x) fa[x] = find(fa[x]); return fa[x];&#125;void merge(int x,int y) &#123; int fx = find(x); int fy = find(y); if (fx != fy) &#123; fa[fx] = fy; &#125;&#125;int main()&#123; std::ios::sync_with_stdio(false); cin.tie(0); cin &gt;&gt; N &gt;&gt; M &gt;&gt; K; int a,b; for (int i = 0; i &lt; M; i++) &#123; cin &gt;&gt; a &gt;&gt; b; pp[i].first = a; pp[i].second = b; &#125; int tmp; for (int i = 0; i &lt; K; i++) &#123; cin &gt;&gt; tmp; init(); for (int j = 0; j &lt; M; j++) &#123; if (pp[j].first != tmp &amp;&amp; pp[j].second != tmp) &#123; merge(pp[j].first,pp[j].second); &#125; &#125; int cnt = 0; for (int i = 1; i &lt;= N; i++) &#123; if (fa[i] == i) cnt++; &#125; if (N == 1) cout &lt;&lt; 0 &lt;&lt; endl; else if (N == 2) cout &lt;&lt; 0 &lt;&lt; endl; else cout &lt;&lt; cnt - 2 &lt;&lt; endl; &#125; return 0;&#125; 第二种方法 通过dfs深搜后进行标记1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;#include &lt;cmath&gt;using namespace std;const int maxn = 1008;int N,M,K;bool dis[maxn][maxn];bool vis[maxn];void dfs(int x) &#123; vis[x] = true; for (int i = 1; i &lt;= N; i++) &#123; if (vis[i] == false &amp;&amp; dis[x][i] == true) &#123; dfs(i); &#125; &#125;&#125;int main()&#123; std::ios::sync_with_stdio(false); cin.tie(0); cin &gt;&gt; N &gt;&gt; M &gt;&gt; K; int a,b; memset(dis,false,sizeof dis); for (int i = 0; i &lt; M; i++) &#123; cin &gt;&gt; a &gt;&gt; b; dis[a][b] = dis[b][a] = true; &#125; int tmp; for (int i = 0; i &lt; K; i++) &#123; memset(vis,false,sizeof vis); cin &gt;&gt; tmp; vis[tmp] = true; int cnt = 0; for (int i = 1; i &lt;= N; i++) &#123; if (vis[i] == false) &#123; dfs(i); cnt++; &#125; &#125; cout &lt;&lt; cnt - 1 &lt;&lt; endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>PAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTA 1010 二分的基本应用]]></title>
    <url>%2F2019%2F07%2F14%2FPTA-1010-%E4%BA%8C%E5%88%86%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[这道题目是一个边界的二分问题，可以按照顺序进行求解，但是后面有问题会出错，然后更加坑爹的是，最前面的前置条件需要弄清楚 直接贴出代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;cstdio&gt;#include&lt;queue&gt;#include&lt;map&gt;#include&lt;cmath&gt;using namespace std;long long to_num(const string &amp;b,long long radix) &#123; long long res = 0; int lenb = b.size() - 1; for (int i = 0; i &lt; b.size();i++) &#123; if (b[i] &gt;= '0' &amp;&amp; b[i] &lt;='9') &#123; res += (b[i] - '0') * pow(radix,lenb--); &#125; else &#123; res += (b[i] - 'a' + 10) * pow(radix,lenb--); &#125; if (res &lt; 0) return -1; &#125; return res;&#125;int main()&#123; std::ios::sync_with_stdio(false); string a,b; int tag; long long radix; cin &gt;&gt; a &gt;&gt; b &gt;&gt; tag &gt;&gt; radix; if (a == b) &#123; cout &lt;&lt; radix &lt;&lt; endl; return 0; &#125; if (tag == 2) &#123; swap(a,b); &#125; long long tmp = 0; int len = a.size() - 1; for (int i = 0; i &lt; a.size(); i++) &#123; if (a[i] &gt;= '0' &amp;&amp; a[i] &lt;='9') &#123; tmp += (a[i] - '0') * pow(radix,len--); &#125; else &#123; tmp += (a[i] - 'a' + 10) * pow(radix,len--); &#125; &#125; int Max = -1; int mm; for (int i = 0; i &lt; b.size(); i++) &#123; if (b[i] &gt;= '0' &amp;&amp; b[i] &lt;='9') &#123; mm = b[i] - '0'; &#125; else &#123; mm = b[i] - 'a' + 10; &#125; Max = max(Max,mm); &#125; int lenb = b.size() - 1; bool flag = false; //就是这里关于边界的问题，真的要把我搞死了 // 这里的第一个样例就是 就应该是他的值小于其的边界，正好就是 Max 等于2的时候。 //将两个边界值给弄清楚。 long long low = Max + 1; long long high = max(tmp,low); long long mid = -1; while (low &lt;= high) &#123; mid = (low + high) &gt;&gt; 1; long long tp = to_num(b,mid); if (tp == -1 || tp &gt; tmp) &#123; high = mid - 1; &#125; else if (tp &lt; tmp) low = mid + 1; else if (tp == tmp) &#123; flag = true; break; &#125; &#125; /* 这里其实是一个顺序查找的过程，但是由于循环次数太多，所以必须进行二分优化。 for (ans = Max; ans &lt;= tmp; ans++) &#123; res = 0; for (int i = 0; i &lt; b.size();i++) &#123; if (b[i] &gt;= '0' &amp;&amp; b[i] &lt;='9') &#123; res += (b[i] - '0') * pow(ans,lenb--); &#125; else &#123; res += (b[i] - 'a' + 10) * pow(ans,lenb--); &#125; &#125; if (tmp == res) &#123; flag = true; break; &#125; &#125;*/ if (flag == true &amp;&amp; mid &gt;= 1) cout &lt;&lt; mid &lt;&lt; endl; else cout &lt;&lt; "Impossible" &lt;&lt; endl; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>PAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTA 1007 最大序列和问题]]></title>
    <url>%2F2019%2F07%2F13%2FPTA-1007-%E6%9C%80%E5%A4%A7%E5%BA%8F%E5%88%97%E5%92%8C%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[这道题是一道简单的动态规划，可能是太久没有做这方面的题目了，总是对这一部分忘记，其实最终结果就是一个贪心解决问题。 贴出代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/* 其实这道题也算是一道特别简单的题目，还是动态规划里面最基础的问题，但是总是容易去弄混。 记得自己当时的问题就在于 这里每一次相加的和，如何保证后面加了负数之后，再次加上一个正数不被影响呢， 下面的注释里面有写， 因为题目中限制了，如果这道题有多个答案，比如说 前面与后面相加为零，但是后面的那个正数正好作为最后的正确答案的话 比如 1 2 -3 8 1 2 -3 正好相加为0 但是题目中要求的 序列 1 2 -3 8 作为最后的结果序列。 自己当时也在这一块上面纠结。*/#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;cstdio&gt;#include&lt;queue&gt;#include&lt;map&gt;#include&lt;cmath&gt;using namespace std;int main()&#123; std::ios::sync_with_stdio(false); int m; cin &gt;&gt; m; int num[m + 5]; for (int i = 0; i &lt; m; i++) &#123; cin &gt;&gt; num[i]; &#125; int left = 0; int tmpleft = 0; int right = m - 1; int tmp = 0; int Max = -1; for (int i = 0; i &lt; m; i ++) &#123; tmp += num[i]; //In case that the maximum subsequence is not unique, //output the one with the smallest indices i and j (as shown by the sample case). if (tmp &lt; 0) &#123; tmp = 0; tmpleft = i + 1; &#125; else if (tmp &gt; Max) &#123; Max = tmp; right = i; left = tmpleft; &#125; &#125; //If all the K numbers are negative, then its maximum sum is defined to be 0, //and you are supposed to output the first and the last numbers of the whole sequence. if (Max &gt;= 0) cout &lt;&lt; Max &lt;&lt; " " &lt;&lt; num[left] &lt;&lt; " " &lt;&lt; num[right] &lt;&lt; endl; else cout &lt;&lt; 0 &lt;&lt; " " &lt;&lt; num[0] &lt;&lt; " " &lt;&lt; num[m - 1] &lt;&lt; endl; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>PAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTA 1004 简单的dfs]]></title>
    <url>%2F2019%2F06%2F27%2FPTA-1004-%E7%AE%80%E5%8D%95%E7%9A%84dfs%2F</url>
    <content type="text"><![CDATA[这里直接贴出题目： 代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;#include &lt;cmath&gt;using namespace std;int n,m;vector&lt;int&gt; kids[105];int maxlever = 0;int nums[105];void dfs(int root,int depth) &#123; if (kids[root].size() == 0) &#123; maxlever = max(depth,maxlever); nums[depth]++; return; &#125; for (int i = 0; i &lt; kids[root].size() ; i++) &#123; dfs(kids[root][i],depth + 1); &#125;&#125;int main()&#123; std::ios::sync_with_stdio(false); cin &gt;&gt; n &gt;&gt; m; int fa,num; int tmp; memset(nums,0,sizeof nums); for (int i = 0; i &lt; m; i++) &#123; cin &gt;&gt; fa &gt;&gt; num; for (int i = 0 ; i &lt; num; i ++) &#123; cin &gt;&gt; tmp; kids[fa].push_back(tmp); &#125; &#125; dfs(1,0); cout &lt;&lt; nums[0] ; for (int i = 1; i &lt;= maxlever; i++ ) &#123; cout &lt;&lt; " " &lt;&lt; nums[i]; &#125; cout &lt;&lt; endl; return 0;&#125; 我可能是太久没有写代码了，上面这样一道水题，我先开始就被完完全全的弄糊涂了，这道题就是一个简单的dfs，首先先把数之间的对应关系一点一点的打通，然后再根据后面dfs的递归可以得出来，就是一个简单的根据根节点一点一点的往后面递归搜索，然后达到终点之后，记得把这一个层的叶子结点数加一，这里注意两点，可以发现 在cin的处理里面，可以直接将00，01，02，直接变成相应的0，1，2；]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>PAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PTA 1003 Dijkstra ---- 关于Dijkstra单源最短路的相应总结]]></title>
    <url>%2F2019%2F06%2F25%2FPTA-1003-Dijkstra-%E5%85%B3%E4%BA%8EDijkstra%E5%8D%95%E6%BA%90%E6%9C%80%E7%9F%AD%E8%B7%AF%E7%9A%84%E7%9B%B8%E5%BA%94%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[首先 这里先贴出题目 解题代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;#include &lt;cmath&gt;using namespace std;const int maxn = 505;const int inf = 0x3f3f3f3f;int n,m,_beg,_end;int people[maxn];bool vis[maxn];int _map[maxn][maxn];int dis[maxn];int paths[maxn];int Maxvalue[maxn];void Dijkstra(int beg) &#123; memset(dis,inf,sizeof dis); memset(vis,false,sizeof vis); dis[beg] = 0; paths[beg] = 1; Maxvalue[beg] = people[beg]; for (int i = 0; i &lt; n; i++) &#123; int Min = 0x3f3f3f, index = -1; for (int j = 0; j &lt; n; j++) &#123; if (!vis[j] &amp;&amp; dis[j] &lt; Min) &#123; Min = dis[j]; index = j; &#125; &#125; if (index == -1) break; vis[index] = true; for (int j = 0; j &lt; n; j++) &#123; if (!vis[j] &amp;&amp; _map[index][j] != inf) &#123; if (dis[index] + _map[index][j] &lt; dis[j]) &#123; dis[j] = dis[index] + _map[index][j]; paths[j] = paths[index]; Maxvalue[j] = Maxvalue[index] + people[j]; &#125; else if (dis[index] + _map[index][j] == dis[j]) &#123; paths[j] += paths[index]; Maxvalue[j] = max(Maxvalue[j],Maxvalue[index] + people[j]); &#125; &#125; &#125; &#125;&#125;int main()&#123; std::ios::sync_with_stdio(false); cin &gt;&gt; n &gt;&gt; m &gt;&gt; _beg &gt;&gt; _end; for (int i = 0 ; i &lt; n; i++) &#123; cin &gt;&gt; people[i]; &#125; int x,y,val; memset(_map,inf,sizeof _map); for (int i = 0; i &lt; m; i++) &#123; cin &gt;&gt; x &gt;&gt; y &gt;&gt; val; _map[x][y] = val; _map[y][x] = val; &#125; Dijkstra(_beg); cout &lt;&lt; paths[_end] &lt;&lt; " " &lt;&lt; Maxvalue[_end] &lt;&lt; endl; return 0;&#125; 这里明显就是关于Dijkstra的裸题，变化的地方就是加了一两个内置数组，作为状态的变化，类似于动态规划，到后面就可以解题解出来了。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>PAT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数论总结]]></title>
    <url>%2F2019%2F05%2F06%2F%E6%95%B0%E8%AE%BA%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[数论总结来自西北工业大学的讲义以及题目的总结 素数运算实验范例这里将的就是与素数相关的筛法，这里介绍两种筛法。 素数的线性筛法埃式筛法12345678910111213141516//最普通的埃式筛法memset(check, 0, sizeof(check));int tot = 0;for (int i = 2; i &lt;= n; ++i)&#123; if (!check[i]) &#123; prime[tot++] = i; &#125; // 下面其实用乘法和用加法都是一样的，而这里就是乘法的原因就在于，减少了循环次数 // 唯一没有被优化的地方就在于 每一个数字被重复标记了很多次，而后面的欧拉筛就会限制标记次数为一次 for (int j = i * i; j &lt;= n; j *= i) &#123; check[j] = 1; &#125;&#125; 欧拉筛法 12345678910111213141516171819202122232425262728293031//进阶版的线性筛法//质数数组int prime[MAXN];//判断每一个数 数组int check[MAXL];int tot = 0;memset(check, 0, sizeof(check));for (int i = 2; i &lt; MAXL; ++i)&#123; if (!check[i]) &#123; prime[tot++] = i; &#125; for (int j = 0; j &lt; tot; ++j) &#123; //大致意思就在于 将每一个数的与质数数组里面的数进行相乘，最后得到的结果存在check中去 //需要注意的就是 一旦当前的数能被整除的时候 就立马退出，这样代表每一个数字都会被自己的最小质因数给整除出来。 if (i * prime[j] &gt; MAXL) &#123; break; &#125; check[i * prime[j]] = 1; if (i % prime[j] == 0) &#123; break; &#125; &#125;&#125; 然后下面就由上面两种线性筛法引申出来下面两个结论 每一个大于4的偶数可以写成两个奇素数的和。(poj 2262) 每一个大于8的数字可以分为4个素数的和。(uva 10168) 大素数的实验范例一般这里还存在一些超过给出的素数表的范围，或者是打表到那个地方一定会反超之类的题目，这里都使用一种类似于区间筛法的办法去解决问题。 比如 uva 10871: 打出 2 到 根号n范围的表，然后超过这个范围的数，对于这个数里面的数全部去除以前面打表产生的素数表，看能不能除尽，来判断这个大整数是否是素数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/* 这道题 其实利用了素数表之后，就是一个一次遍历的过程了 不过我没有想到的是， 这道题其实已经提前将每一个sum给记录下来了，就相当于一个打表的方式。 另外这道题第二个爆点就在于 当超出了表范围内的大数怎么办，这里就可以用分两种，第一种是在这种情况的直接看表， 另外一种就是用 这个数去mod 表内的每一个质数，这样可以加快时间。*/#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;using namespace std;const int maxn = 10011;bool u[maxn];int su[maxn];int num = 0;void prepare()&#123; int i, j; memset(u, true, sizeof(u)); for (i = 2; i &lt; maxn; ++i) &#123; if (u[i]) &#123; su[++num] = i; &#125; for (j = 1; j &lt;= num; ++j) &#123; if (i * su[j] &gt; maxn) &#123; break; &#125; u[i * su[j]] = false; if (i % su[j] == 0) &#123; break; &#125; &#125; &#125;&#125;bool pri(int x)&#123; if (x &lt;= 10010) &#123; return u[x]; &#125; int i; for (i = 1; i &lt;= num; ++i) &#123; if (x % su[i] == 0) &#123; return false; break; &#125; &#125; return true;&#125;int main()&#123; prepare(); int t; scanf("%d", &amp;t); while (t--) &#123; int n; scanf("%d", &amp;n); int i, j; int s[n + 1]; s[0] = 0; for (i = 1; i &lt;= n; ++i) &#123; scanf("%d", &amp;s[i]); s[i] += s[i - 1]; &#125; bool ok = false; for (i = 2; i &lt;= n; ++i) &#123; for (j = 1; j + i - 1 &lt;= n; ++j) &#123; int k = s[i + j - 1] - s[j - 1]; if (pri(k)) &#123; ok = true; printf("Shortest primed subsequence is length %d:", i); for (k = 1; k &lt;= i; ++k) &#123; printf(" %d", s[j + k - 1] - s[j + k - 2]); &#125; printf("\n"); break; &#125; &#125; if (ok) &#123; break; &#125; &#125; if (!ok) &#123; printf("This sequence is anti-primed.\n"); &#125; &#125; return 0;&#125; 求解不定方程和同余的实验范例这一个章节的东西基本上可以说是奠定了数论的基础，所以这部分的东西请务必掌握。 首先这里先贴出 gcd 和 exgcd的代码 欧几里得算法1234int gcd(int a,int b) &#123; if (b == 0) retuan a; return gcd(b,a % b);&#125; exgcd 扩展欧几里得算法12345678910111213int exgcd (int a,int b, int &amp;x,int &amp;y) &#123; if (b == 0) &#123; x = 1; y = 0; return a; &#125; int t = exgcd(b,a % b,x,y); int d = x; x = y; y = d - (a / b) * y; return t;&#125; 欧几里得算法是用来求解最大公约数的由欧几里得公式推出 如果 a与b 互素，那么b * t + a 与 b 也一定互素。 这里贴出一道题 就是对于上面gcd公式的周期性的利用 happy poj 2773 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* 这道题目就是在于对于gcd的周期性的使用。 这道题就利用了与m互素的数对m去膜具有周期性*/#include &lt;stdio.h&gt;#include &lt;iostream&gt;using namespace std;int s[1000005];int gcd(int a, int b)&#123; if (b == 0) &#123; return a; &#125; else &#123; return gcd(b, a % b); &#125;&#125;int main()&#123; int m, k; while (scanf("%d%d", &amp;m, &amp;k) != EOF) &#123; int i; int num = 0; for (i = 1; i &lt;= m; i++) &#123; if (gcd(m, i) == 1) &#123; s[num++] = i; &#125; &#125; //这里其实进行了两种情况：一种刚好除尽的情况， //和另外一种没有刚好除尽的情况。 if (k % num == 0) &#123; //这里减一的目的是刚刚好除尽，减去一个后面好加上一个ai; printf("%d\n", (k / num - 1) * m + s[num - 1]); &#125; else &#123; //后面的则就体现在了余数这个地方。，之所以减去1是因为num不可能算上的最后一个 printf("%d\n", k / num * m + s[k % num - 1]); &#125; &#125; return 0;&#125; 扩展欧几里得算法是用来求最大公约数和不定方程的通解 这里同样也贴出一道模板样题作为示范 The Balance poj 2142 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/* 这道题就在于其很厉害的是 解释了ecgcd的真正的用途。 这道题说难也不是很难，只是教会了一些数论题目全部的代码该如何去写。 典型的求 不定方程的做法 ax + by = d; 求解 一个 x，y 的满足条件的特解。 这里写一下求解步骤 ： 第一步 首先先得出这个方程，然后对方程两边同时除以gcd(a,b); 在步入第二步的过程中有一个判断 就是看d 对于 gcd(a,b)的比较情况，决定这个不定方程是否有解； 第二步 就是直接用未初始化的 x,y 带入exgcd求解 可以得到一个 x,y的其中一个特解 第三步 将得到的特解乘以相应的扩大的d_倍，最后按照题目规定的条件进行整改最终得出结果 其中需要注意的是 上面得到的特解，只有在ax + by 正好等于gcd(a,b)的时候 才会同时满足。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;using namespace std;int gcd(int a,int b) &#123; if (b == 0) return a; return gcd(b,a % b);&#125;int exgcd(int a,int b,int &amp;x,int &amp;y) &#123; if (b == 0) &#123; x = 1; y = 0; return a; &#125; int t = exgcd(b,a % b,x,y); int _x = x; int _y = y; x = _y; y = _x - (a/b) * _y; return t;&#125;int a,b,d;int a_,b_,d_;int x,y;//通解int q;int x1,x2,y1,y2;int main()&#123; while (scanf("%d %d %d",&amp;a,&amp;b,&amp;d) &amp;&amp; a &amp;&amp; b &amp;&amp; d) &#123; q = gcd(a,b); a_ = a / q; b_ = b / q; d_ = d / q; int k = exgcd(a_,b_,x,y); x1 = x * d_; x1 = (x1 % b_ + b_) % b_; y1 = (d - x1 * a) / b; if (y1 &lt; 0) y1 = -y1; y2 = y * d_; y2 = (y2 % a_ + a_) % a_; x2 = (d - y2 * b) / a; if (x2 &lt; 0) x2 = -x2; if (x1 + y1 &lt; x2 + y2) printf("%d %d\n",x1,y1); else printf("%d %d\n",x2,y2); &#125; return 0;&#125; 这里还是讲求解不定方程的步骤再详细的过一遍 得到不定方程ax + by = m，先判断 m 是否是gcd(a,b)的倍数，如果是说明方程有解，如果不是方程则没有解 有解之后，方程两边同时除以gcd(a,b)，然后将重新得到的a,b值带入到扩展欧几里得的方程式中得到两个通解x,y， 需要将得到的x 或者 y 值 扩大 经除后的m值，因为扩展欧几里得求的不定方程默认就是等于1的。对于这道题而言，想要求最小的正整数的通解，于是就 (x % b + b) % b, 这里就是防止C++取余带来的负数影响。 下面还有一道题 也是求出不定方程的解，但是有一点点不同。 One Person Game zoj3593 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/* 这里的与上面一道题不一样的地方就在于 后面限制条件不太相同。 前面一道题上面求出的一个特解，但是 取mod之后得到的结果， 所以用改变后的变量值，来求另外一个。 而这道题不一样的是是通过求解答案 然后 根据特解来算结构来算。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;using namespace std;long long _beg,_end,a,b;const long long inf = 0x3f3f3f3f;long exgcd(long long a,long long b,long long &amp;x,long long &amp;y) &#123; if (b == 0) &#123; x = 1; y = 0; return a; &#125; long long t = exgcd(b,a % b,x,y); int x_ = x; int y_ = y; x = y_; y = x_ - (a / b) * y_; return t;&#125;int main()&#123; int T; cin &gt;&gt; T; while (T--) &#123; cin &gt;&gt; _beg &gt;&gt; _end &gt;&gt; a &gt;&gt; b; long long res = _end - _beg; long long d,x,y; d = exgcd(a,b,x,y); if (res % d != 0) &#123; cout &lt;&lt; -1 &lt;&lt; endl; continue; &#125; x *= res / d; y *= res / d; a = a / d; b = b / d; long long ans = inf * inf,tmp; long long mid = (y - x) / (a + b); for (int i = mid - 1; i &lt;= mid + 1; i++) &#123; long long x1 = x + i * b; long long y1 = y - i * a; if (x1 * y1 &gt;= 0) tmp = max(abs(x1),abs(y1)); else tmp = abs(x1 - y1); ans = min(ans,tmp); &#125; cout &lt;&lt; ans &lt;&lt; endl; &#125; return 0;&#125; 这道题不一样的是 他不是像前面求出通解之后求一个最小或者最大，我的理解就是 因为 其算出来的通解为 x = xo + k b,y = yo - k a ,其实将这里两个特解 直接当成0来算，因为题目要求最小，并且 a , b 的差距还不能太大，就直接求出 k的范围 然后 对其进行加1 减1的操作得出最后结果。 计算同余方程与同余方程组关于同余理论，自己的其他相关博客已经存在讲解这里就不在过多介绍了， 这里有一道经典的题，以后有时间插一下代码。 这里再次总结一下一元线性同余方程的解法。 首先首先 线性同余方程可以表示为 ax =- b(mod m) 就这样可以表示为一个不定方程式 ax = b + ym; 先求出 b % gcd(a,m) 判断其是否为0，如果不为0，那么以上的同余方程式或者不定方程式无解。如果 得到的结果为j，那么说明该方程有 j个 mod m 不同余的解 d = gcd(a,m); 当用欧几里得算法求出以上的解之后 得到其实是 ax=- d(mod m) 这一同余方程中 x 的解。所以说人话就是 当求出了那个特解之后 再去乘以之前 的 B 值 最后mod m得到最终同余方程的解。2 关于计算同余方程，其实与求解扩展欧几里得通解的效果是一样的， C_Loop poj2115 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/* 这道题其实再一次涉及到 exgcd的另外一个用法 这个用法仍然是从其中求解不定方程的作用中延伸过来的。 这道题就是一个简单的一维的线性求余过程， 对于这道题就显示一下 线性同余的过程 首先 线性同余方程可以表示为 ax =- b(mod m) 就这样可以表示为一个不定方程式 ax = b + ym; 所以第一步 先求出 b % gcd(a,m) 判断其是否为0，如果不为0，那么以上的同余方程式或者不定方程式无解。 如果 得到的结果为j，那么说明该方程有 j个 mod m 不同余的解 d = gcd(a,m); 当用欧几里得算法求出以上的解之后 得到其实是 ax` =- d(mod m) 这一同余方程中 x`的解。 所以根据判断d是否等于0 可以求出第一个解释x0 = x` * (b / d) mod m; 而其余d - 1的解就是 xi = (x0 + i *(m / d)) mod m; 所以说人话就是 当求出了那个特解之后 再去乘以之前 的 B 值 最后mod m得到最终同余方程的解。*/#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;cstdio&gt;#include&lt;queue&gt;#include&lt;map&gt;using namespace std;long long exgcd(long long a,long long b,long long &amp;x,long long &amp;y) &#123; if (b == 0) &#123; x = 1; y = 0; return a; &#125; long long t = exgcd(b,a % b,x,y); long long d = x; x = y; y = d - (a / b) * y; return t;&#125;long long gcd (long long a,long long b) &#123; if (b == 0) return a; return gcd(b,a % b);&#125;long long a,b,c,k;long long x,y;int main()&#123; while (scanf("%lld %lld %lld %lld",&amp;a,&amp;b,&amp;c,&amp;k)) &#123; if (a == 0 &amp;&amp; b == 0 &amp; c == 0 &amp;&amp; k ==0) break; long long gap = b - a; k = ((long long)1 &lt;&lt; k); gap = (gap % k + k) % k; if (gap == 0) &#123; printf("0\n"); continue; &#125; long long q = exgcd(c,k,x,y); if (gap % q) &#123; printf("FOREVER\n"); continue; &#125; //前面属于判断过程，后面就是正常的ecgcd的 不定方程求解了 //所以需要做的事情就是 方程两边同时除以gcd c = c / q; gap = gap / q; k = k / q; long long xx = exgcd(c,k,x,y); x *= gap; x = (x % k + k) % k; printf("%lld\n",x); &#125; return 0;&#125; 接下来就是一道求解逆元的问题了。 定理 同余方程 ax =- 1(mod m)有解 当且仅仅当 gcd(a,m) = 时候成立，且其的所有解都同余 Modular Inverse zoj 3609 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;using namespace std;int exgcd(int a,int b,int &amp;x,int &amp;y) &#123; if (b == 0) &#123; x = 1; y = 0; return a; &#125; int t = exgcd(b,a % b,x,y); int d = x; x = y; y = d - (a / b) * y; return t; &#125;int a,b,q,x,y;int main()&#123; int T; while (cin &gt;&gt; T) &#123; while (T--) &#123; cin &gt;&gt; a &gt;&gt; b; q = exgcd(a,b,x,y); //就是这里多了判断其是否为0的条件。 if (q != 1) &#123; printf("Not Exist\n"); continue; &#125; //这里就是处理0的情况 x = (x % b + b) % b; if (x == 0) cout &lt;&lt; b &lt;&lt; endl; else cout &lt;&lt; x &lt;&lt; endl; &#125; &#125; return 0;&#125; 同余方程组 （中国剩余定理）这里贴出 求解同余方程组的阶梯步骤 将题目中给出的所有同余方程组列出来，形如 a =- ai (mod ni),并且将每一个ni相乘起来 得到一个 n 。（或者是求其全部的最小公倍数） 然后通过公式 计算出 mi = n / ni，然后再通过mi 计算出mi模 n 的逆 就是通过 扩展欧几里得公式去求解每一个同余方程 mi * x =- 1 (mod ni); 然后再计算每一个 ci = mi * mi的逆。 最后通过公式 a = ((全部相加)ai * ci ) mod n… Biorhythms poj 1006 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/* 这道题目其实是严格按照中国剩余定理来计算的，最后求解的结果实际上是计算出来的三个同余的结果，同时满足多个同余方程的一个共同的结果 不过下面的步骤需要弄清楚，第一步是先求出每一个同余的 m值，然后再通过求m逆，然后将其相乘得到ci 最后乘以每一项的ci 最后求解的结果去mod上一个最终的mod n就行了*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;#include &lt;cmath&gt;using namespace std;int p,e,i,d;int exgcd (int a,int b, int &amp;x,int &amp;y) &#123; if (b == 0) &#123; x = 1; y = 0; return a; &#125; int t = exgcd(b,a % b,x,y); int d = x; x = y; y = d - (a / b) * y; return t;&#125;int m1,m2,m3;int n1,n2,n3;int n = 21252;int x,x2,x3;int y,y2,y3;//处理C++ 中 % 出负数的情况int _mod(int x,int b) &#123; return (x % b + b) % b;&#125;int main()&#123; int Case = 1; while (scanf("%d %d %d %d",&amp;p,&amp;e,&amp;i,&amp;d)) &#123; if (p == -1 &amp;&amp; e == -1 &amp;&amp; i == -1 &amp;&amp; d== -1) break; m1 = n / 23; m2 = n / 28; m3 = n / 33; int q1 = exgcd(m1,23,x,y); int q2 = exgcd(m2,28,x2,y2); int q3 = exgcd(m3,33,x3,y3); x = _mod(x,23) * m1; x2 = _mod(x2,28) * m2; x3 = _mod(x3,33) * m3; int res = x * p + x2 * e + x3 * i - d; res = res % n; if (res &lt;= 0) res += n; cout &lt;&lt; "Case "&lt;&lt; Case++ &lt;&lt;": the next triple peak occurs in "&lt;&lt;res &lt;&lt;" days." &lt;&lt; endl; &#125; return 0;&#125; 特殊的同余式威尔逊定理如果 p 是素数，(p - 1)! =- -1 (mod p)成立 意思就是 如果 p是素数的情况，(p - 1)! + 1 mod p 正好可以等于0. YAPTCHA uva 4382 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;sstream&gt;#include &lt;cstring&gt;#include &lt;map&gt;#include &lt;set&gt;#include &lt;vector&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;#define MOD 2018#define LL long long#define ULL unsigned long long#define Pair pair&lt;int, int&gt;#define mem(a, b) memset(a, b, sizeof(a))#define _ ios_base::sync_with_stdio(0), cin.tie(0)using namespace std;const int maxn = 3e6 + 10, INF = 0x7fffffff;int vis[maxn], ans[maxn];//这里是一种简单的筛法,相当于一个简单的埃式筛法。void init()&#123; mem(vis, 0); for (int i = 2; i &lt;= sqrt(maxn + 0.5); i++) if (!vis[i]) for (int j = i * i; j &lt; maxn; j += i) vis[j] = 1;&#125;void f()&#123; mem(ans, 0); for (int i = 1; i &lt;= 1e6; i++) &#123; int temp = 3 * i + 7; ans[i] = ans[i - 1] + (1 - vis[temp]); &#125;&#125;int main()&#123; init(); f(); int T, n; cin &gt;&gt; T; while (T--) &#123; cin &gt;&gt; n; cout &lt;&lt; ans[n] &lt;&lt; endl; &#125; return 0;&#125; 费马小定理 如果p是素数，a是正整数，gcd(a,p) = 1,则 a的p - 1 次幂 同余 1 mod p. what day is that day zoj 37851234567891011121314151617181920212223242526272829303132/* 这道题讲述的就是费马小定理，这道题目关键点就是在，前面对于周期mod的求取，应用了费马小定理，最后得出的结论。*/#include &lt;cstdio&gt;#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;using namespace std;int num[1000];char day[10][10] = &#123;"Saturday", "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday"&#125;;int pow(int x)&#123; int ans = 1; for (int i = 1; i &lt;= x; i++) ans = (ans * x) % 7; return ans;&#125;int main()&#123; for (int i = 1; i &lt;= 300; i++) num[i] = (pow(i) + num[i - 1]) % 7; int T; scanf("%d", &amp;T); while (T--) &#123; int n; scanf("%d", &amp;n); printf("%s\n", day[num[n % 294]]); &#125; return 0;&#125; 伪素数其产生的原因就在于费马小定理的逆不成立，如果a是一个正整数，如果n是一个正合数，并且a的n次幂 同余 a (mod n) 则称n为以a为基的伪素数。 Pseudoprime numbers poj 3641 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* 这道题不断的出现runtime error 用java 的时候 这个时候我就不太清楚是为什么了。 后面还需要弄清楚一件事情就是 究竟什么时候才能够用欧拉赛的时间去打表，这里就不太清楚 有的时候用欧拉筛打表反而出现错误的答案。 */#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;#include &lt;cmath&gt;using namespace std;long long _mod(long long x,long long y,long long mod) &#123; long long ans = 1; while (y) &#123; if (y &amp; 1) ans = ans * x % mod; y &gt;&gt;= 1; x = x * x % mod; &#125; return ans;&#125;bool is_prime(long long x) &#123; for (int i = 2; i &lt;= sqrt(x) + 0.5; i++) &#123; if (x % i == 0) return false; &#125; return true;&#125;long long q,a;int main()&#123; while (scanf("%lld %lld",&amp;q,&amp;a) &amp;&amp; q &amp;&amp; a) &#123; if (is_prime(q)) &#123; printf("no\n"); continue; &#125; long long ans = _mod(a,q,q); if (ans == a) printf("yes\n"); else printf("no\n"); &#125; return 0;&#125; 接下来还有一道题，可以根据java的一个函数直接得出结果，但是同样也可以通过C++ 的大素数的检测方法从而得出结果。 123456789101112131415161718192021import java.util.Scanner;import java.math.BigInteger;public class Main &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); int n; BigInteger a; while (in.hasNext()) &#123; n = in.nextInt(); int cnt = 0; for (int i = 0; i &lt; n; i++) &#123; a = in.nextBigInteger(); if (a.isProbablePrime(3)) cnt++; &#125; System.out.println(cnt); &#125; in.close(); return; &#125;&#125; C++ 前面有讲的超出区间的测定方法。 123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt;#include &lt;math.h&gt;int is_prime(int x)&#123; int tp = (int)sqrt(x * 1.0); for (int i = 2; i &lt;= tp; ++i) &#123; if (x % i == 0) &#123; return 0; &#125; &#125; return 1;&#125;int main()&#123; int n; while (~scanf("%d", &amp;n)) &#123; int ans = 0, tp; for (int i = 0; i &lt; n; ++i) &#123; scanf("%d", &amp;tp); if (tp == 2) &#123; ++ans; &#125; else if (tp &amp; 1) &#123; ans += is_prime(tp); &#125; &#125; printf("%d\n", ans); &#125; return 0;&#125; 欧拉定理欧拉函数表示的是到n之前与n互素的且不超过n的正整数的个数。 如果 n和a是互素的正整数，则 a的 欧拉函数n 同余1 mod n]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>acm</tag>
        <tag>数论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[背包初级及相应题目总结]]></title>
    <url>%2F2019%2F05%2F01%2F%E8%83%8C%E5%8C%85%E5%88%9D%E7%BA%A7%E5%8F%8A%E7%9B%B8%E5%BA%94%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[背包初级讲解这里对于动态规划里面一个简单基础的问题进行总结，包括 01背包，完全背包，多重背包，混合背包… 01背包题目 有N件物品和一个容量为V 的背包。放入第i件物品耗费的费用是Ci1，得到 的价值是Wi 。求解将哪些物品装入背包可使价值总和最大。 基本思路 用子问题定义状态:即F [i, v]表示前i件物品恰放入一个容量为v的背包可 以获得的最大价值。则其状态转移方程便是:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657**对于二维dp数组的伪代码如下**F[0,0..V] ←0 fori ←1toNforv ←Ci toVF[i,v] ← max&#123;F[i − 1,v],F[i − 1,v − Ci] + Wi&#125;**优化空间的复杂度**使用滚动数组，以及进行压缩空间。伪代码如下：F [0..V ] ←0 fori ←1toNforv ←V toCiF[v] ←max&#123;F[v],F[v−Ci]+Wi&#125;**初始化的细节**&gt;我们看到的求最优解的背包问题题目中，事实上有两种不太相同的问法。 有的题目要求“恰好装满背包”时的最优解，有的题目则并没有要求必须把背 包装满。一种区别这两种问法的实现方法是在初始化的时候有所不同。&gt;如果是第一种问法，要求恰好装满背包，那么在初始化时除了F [0]为0，其 它F [1..V ]均设为−∞，这样就可以保证最终得到的F [V ]是一种恰好装满背包的 最优解。&gt;如果并没有要求必须把背包装满，而是只希望价格尽量大，初始化时应该 将F [0..V ]全部设为0。#### 题目总结 ##### 1.Charm Bracelet (poj3624)```C++/* 第一道题属于一个简单的01背包模板题目，这里不多说 可以直接套模板。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int n,m;int dp[13000];int w[3500],v[3500];int main()&#123; while (cin &gt;&gt; n &gt;&gt; m) &#123; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; w[i] &gt;&gt; v[i]; &#125; memset(dp,0,sizeof dp); for (int i = 1; i &lt;= n; i++) &#123; for (int j = m; j &gt;= w[i]; j--) &#123; dp[j] = max(dp[j],dp[j - w[i]] + v[i]); &#125; &#125; cout &lt;&lt; dp[m] &lt;&lt; endl; &#125; return 0;&#125; 2.Bone_Collector(hdu 2602)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* 一段简单的模板题目，不过需要弄清楚的 一维数组与二维数组在这里相应的区别，往往这里会产生很大的区别， 比如第二个循环的开始条件，因为这里是由子问题的堆积，然后一点一点向上升最终得到的问题，所以这李最好控制背包的放与不放的问题、 就比如我在这道题目的第二个问题中出现的错误，就是将j=0这个条件直接掠过去了，其实这里是不对的。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;const int maxn = 1010;long long weight[maxn],value[maxn],dp[maxn][maxn];long v,w;int main()&#123; int T; cin &gt;&gt; T; while(T--) &#123; cin &gt;&gt; w &gt;&gt; v; value[0] = 0; weight[0] = 0; for (int i = 1; i &lt;= w; i++) &#123; cin &gt;&gt; value[i]; &#125; for (int i = 1; i &lt;= w; i++) &#123; cin &gt;&gt; weight[i]; &#125; memset(dp, 0, sizeof dp); for (int i = 1; i &lt;= w; i++) &#123; for (int j = 0; j &lt;= v; j++) &#123; if (j &gt;= weight[i]) &#123; dp[i][j] = max(dp[i - 1][j],dp[i - 1][j - weight[i]] + value[i]); &#125; else dp[i][j] = dp[i - 1][j]; &#125; &#125; cout &lt;&lt; dp[w][v] &lt;&lt; endl; &#125; return 0;&#125; 3.饭卡123456789101112131415161718192021222324252627282930313233343536373839404142/* 这道题神奇的地方就在于 其的重量限制于价值重合在了一起，所以对于这道题而言就是只能重合的去写状态转移方程了 另外需要注意的是最后输出结果的办法，是将最后一个物品交给剩下的最大的钱去购买，这样能彻底用光最后的钱财*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int n,m;const int maxn = 1010;int num[maxn],dp[maxn][maxn];int main()&#123; while (cin &gt;&gt; n &amp;&amp; n) &#123; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; num[i]; &#125; cin &gt;&gt; m; sort(num + 1, num + 1 + n); if (m &lt; 5) &#123; cout &lt;&lt; m &lt;&lt; endl; continue; &#125; memset(dp,0,sizeof dp); for (int i = 1; i &lt;= n; i++) &#123; for (int j = 0; j &lt;= m - 5; j++) &#123; if (j &gt;= num[i]) &#123; dp[i][j] = max(dp[i - 1][j],dp[i - 1][j - num[i]] + num[i]); &#125; else dp[i][j] = dp[i - 1][j]; &#125; &#125; cout &lt;&lt; m - dp[n - 1][m - 5] - num[n] &lt;&lt; endl; &#125; return 0;&#125; 完全背包完全背包这里与01背包相类似，但是区别就在于每一个种类的背包可以取无数个 1234567一般都是将其转化为01背包的方法求解，用一个滚动数组来进行表示，不过需要注意的是，其与01背包的第二个循环不同地方完全背包的伪代码：```pydef CompletePack(F, C, W ) forv ←CtoVF[v] ←max&#123;F[v],f[v−C]+W&#125; 题目下面贴出关于完全背包的题目 1.减肥1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* 这道题使用二维数组就一直就会超时 具体的我也不太清楚，但是 没有办法 只能使用一维滚动数组，进行了相应的空间优化 不过这里需要补充几个知识点 第一 关于二维数组的完全背包状态转移方程 dp[i][j] = max (dp[i - 1][j],dp[i - 1][j - k * c[i]] + k * v[i]); 由上面这个式子就可以得出，状态转移方程 于是 一种空间优化的写法 是直接写成 max(dp[i - 1][j]，dp[i][j - w[i]] + v[i]) 第二 如果换成滚动数组的话 记住 第二个循环的两个顺序，如果是倒叙的话 则就是要保证每一个物品只会取一次，但是如果是正序的话，那么就不需要保证上面所说的顺序了。 而这里官方的解释 就在这里 ： 让 v 递减是为了保证第i次循环中的状态F[i;v]是由状态F[i-1;v-Ci]递推而来。 换句话说，这正是为了保证每件物品只选一次，保证在考虑“选入第 i 件物品”这件策 略时，依据的是一个绝无已经选入第 i 件物品的子结果F[i-1;v-Ci]。而现在完全背 包的特点恰是每种物品可选无限件，所以在考虑“加选一件第 i 种物品”这种策略时， 却正需要一个可能已选入第 i 种物品的子结果F[i;v-Ci]，所以就可以并且必须采用v 递增的顺序循环。这就是这个简单的程序为何成立的道理。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include&lt;cstdio&gt;using namespace std;int n, a, b, m;const int maxn = 110;int happiness[maxn], kaluli[maxn];int dp[110000];int main()&#123; while (~scanf("%d",&amp;n)) &#123; for (int i = 1; i &lt;= n; i++) &#123; scanf("%d %d",&amp;happiness[i],&amp;kaluli[i]); &#125; scanf("%d",&amp;m); memset(dp,0,sizeof dp); for (int i = 1; i &lt;= n; i++) &#123; for (int j = kaluli[i]; j &lt;= m; j++) &#123; dp[j] = max(dp[j],dp[j - kaluli[i]] + happiness[i]); &#125; &#125; printf("%d\n",dp[m]); &#125; return 0;&#125; 2.Dollar Dayz12345678910111213141516171819202122232425import java.util.Scanner;import java.math.BigInteger;public class Main &#123; public static void main(String[] args) &#123; int n,k; Scanner in = new Scanner(System.in); while (in.hasNext()) &#123; BigInteger[] dp = new BigInteger[1005]; n = in.nextInt(); k = in.nextInt(); dp[0] = new BigInteger("1"); for (int i = 1; i &lt;= n; i++) &#123; dp[i] = new BigInteger("0"); &#125; for (int i = 1; i &lt;= k; i++) &#123; for (int j = i; j &lt;= n; j++) &#123; dp[j] = dp[j].add(dp[j - i]); &#125; &#125; System.out.println(dp[n]); &#125; &#125;&#125; 3.Piggy-Bank1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* 这道题是一个完全背包的裸题，对于这道题而言更加神奇的地方就在于其实求最小值而不是求最大值 所以在最先开始初始化的时候不应该去初始化为0，而应该初始化为无穷大 而千万不要忘记了再初始化的时候一定要对第一个状态进行一个单独赋值是等于0，还是等于无穷大，这个等到时候再看。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt; using namespace std;int _beg,_end;const int maxn = 505;int v[maxn],w[maxn];int dp[10010];int main()&#123; int T; cin &gt;&gt; T; while (T--) &#123; scanf("%d %d",&amp;_beg,&amp;_end); int bottle = _end - _beg; int n; scanf("%d",&amp;n); for (int i = 1; i &lt;= n; i++)&#123; scanf("%d %d",&amp;v[i],&amp;w[i]); &#125; memset(dp,0x3f3f3f3f,sizeof dp); dp[0] = 0; for (int i = 1; i &lt;= n;i ++) &#123; for (int j = w[i]; j &lt;= bottle; j++) &#123; dp[j] = min(dp[j],dp[j - w[i]] + v[i]); &#125; &#125; if (dp[bottle] != 0x3f3f3f3f) cout &lt;&lt; "The minimum amount of money in the piggy-bank is " &lt;&lt; dp[bottle] &lt;&lt; "." &lt;&lt; endl; else cout &lt;&lt; "This is impossible." &lt;&lt; endl; &#125; return 0;&#125; 多重背包多重背包与完全背包最大的不同就是在于，完全背包其的每一个背包取值可以取无数个（相对于背包容量而言）而多重背包的意思就是相对于背包容量而言 取不满，在取不满的同时还能够再加入其的背包，故，这里就为多重背包 模板代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;const int maxn = 100005;//三个属性值 一个重量 数量 以及价值int weight[maxn],number[maxn],value[maxn];//状态存储int dp[maxn &lt;&lt; 4];//背包的容量int bag; int n;//01背包 void zeroonepack(int weight,int value) &#123; for (int j = bag; j &gt;= weight; j--) &#123; dp[j] = max(dp[j],dp[j - weight] + value); &#125;&#125;//完全背包void completepack(int weight,int value) &#123; for (int j = weight; j &lt;= bag; j++) &#123; dp[j] = max(dp[j],dp[j - weight] + value); &#125;&#125;//多重背包void multilpack(int weight,int number,int value) &#123; //第一种情况就是 如果这件物品所有的重量是小于背包的重量的话 //那么对于背包而言 这个物品是可以取无限大。 if (bag &lt;= number * weight) &#123; completepack(weight,value); return; &#125; //而超过的这个范围的就只能使用01背包 然后使用二进制的方法 //将每一类型的背包进行一个分组 //后面再依次分别使用多重背包。 int k = 1; while (k &lt;= number) &#123; zeroonepack(k * weight,k * value); number = number - k; k = k * 2; &#125; zeroonepack(number * weight, number * value);&#125;int main()&#123; cin &gt;&gt; bag &gt;&gt; n; for (int i = 1; i &lt;= n ;i ++) &#123; cin &gt;&gt; weight[i] &gt;&gt; number[i] &gt;&gt; value[i]; &#125; for (int i = 1; i &lt;= n ;i ++) &#123; multilpack(weight[i],number[i],value[i]); &#125; cout &lt;&lt; dp[bag] &lt;&lt; endl; return 0;&#125; 相应题目总结1. Space Elevator1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* 一道多重背包的裸题目，这道题虽然并没有去套用多重背包的裸模板，但是这道题神奇的地方就在于其对于 背包的数量进行了再一次的循环，然后再来看看有没有符合的特点。 然后其的状态转移方程也是特别的有意思： dp[k] |= dp[k - node[i].h] 不过这个 |= 到后面去官网查询一下最后的结果的意思.*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;struct Node &#123; int h,a,c; bool operator &lt; (const Node &amp;n) const &#123; return a &lt; n.a; &#125;&#125;node[450];int dp[40050];int main()&#123; int K; while (cin &gt;&gt; K) &#123; for (int i = 1; i &lt;= K; i++) &#123; cin &gt;&gt; node[i].h &gt;&gt; node[i].a &gt;&gt; node[i].c; &#125; memset(dp,0,sizeof dp); dp[0] = 1; sort(node + 1, node + 1 + K); for (int i = 1; i &lt;= K ;i ++) &#123; for (int j = 1; j &lt;= node[i].c; j++) &#123; for (int k = node[i].a; k &gt;= node[i].h; k-- )&#123; dp[k] |= dp[k - node[i].h]; &#125; &#125; &#125; int cnt = 0; for (int i = node[K].a; i &gt;= 0; i--) &#123; if (dp[i]) &#123; cnt = i; break; &#125; &#125; cout &lt;&lt; cnt &lt;&lt; endl; &#125; return 0;&#125; 2. Coins123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* 这道题神奇的地方就是将多重背包的裸题进行了改变， 主要就是每一次增加的价值会发生改变，这才是最关键的地方。 这里的价值就不再是个数，而是进行一个打表，通过这个打表来判断这个重量是否能够达到。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int n;int bag;bool dp[100040];int value[105],number[105];int cnt = 0;void zeroonepack(int weight, int value)&#123; for (int j = bag; j &gt;= weight; j--) &#123; if (!dp[j] &amp;&amp; dp[j - weight])&#123; dp[j] = true; cnt ++; &#125; &#125;&#125;//完全背包void completepack(int weight, int value)&#123; for (int j = weight; j &lt;= bag; j++) &#123; if (!dp[j] &amp;&amp; dp[j - weight]) &#123; dp[j] = true; cnt ++; &#125; &#125;&#125;//多重背包void multilpack(int weight, int number, int value)&#123; //第一种情况就是 如果这件物品所有的重量是小于背包的重量的话 //那么对于背包而言 这个物品是可以取无限大。 if (bag &lt;= number * weight) &#123; completepack(weight, value); return; &#125; //而超过的这个范围的就只能使用01背包 然后使用二进制的方法 //将每一类型的背包进行一个分组 //后面再依次分别使用多重背包。 int k = 1; while (k &lt; number) &#123; zeroonepack(k * weight, k * value); number = number - k; k = k * 2; &#125; zeroonepack(number * weight, number * value);&#125;int main()&#123; while (cin &gt;&gt; n &gt;&gt; bag &amp;&amp; n &amp;&amp; bag) &#123; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; value[i]; &#125; for (int i = 1; i &lt;= n;i ++) &#123; cin &gt;&gt; number[i]; &#125; cnt = 0; memset(dp,0,sizeof dp); dp[0] = 1; for (int i = 1; i &lt;= n ;i ++) &#123; multilpack(value[i],number[i],value[i]); &#125; cout &lt;&lt; cnt &lt;&lt; endl; &#125; return 0;&#125; 混合背包将01背包 完全背包 多重背包的三种背包 进行一个混合最简单的解决方法就是将其分开进行来算 举个例子 就是 一道题可能有多个背包，通过这多个背包来进行判断题目中所要求解的值。 题目1.Fewest coins1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/* 这道题目神奇的地方 是两个背包的问题 的总和，其实也算作是一个简单的题目，但是 这道题唯一复杂的地方就在于对于背包问题的理解 意思就是如何将一个看上去不是背包的问题转换成一个背包问题 首先的思路就是来判断是一个什么类型的背包 映射到这道题上面可以发现 前面付钱的过程是一个多重背包 后面付钱的过程是一个完全背包 不过深入理解了塞入 状态方程 第一次在价值那个地方出现了错误。 最终的价值不应该是相比总是的钱数，而应该是最小能够达到的背包数。*/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;map&gt;using namespace std;const int maxn = 30005;int dp[maxn],back[maxn];int value[105],number[105];int bag;int n,k;void zeroonepack(int weight,int value)&#123; for (int j = bag ; j &gt;= weight; j--) &#123; dp[j] = min(dp[j],dp[j - weight] + value); &#125;&#125;void completepack(int weight,int value) &#123; for (int j = weight; j &lt;= bag; j++) &#123; dp[j] = min(dp[j],dp[j - weight] + value); &#125;&#125;void mutipack(int weight,int value,int number) &#123; if (number * weight &gt;= bag) &#123; completepack(weight,value); return; &#125; int k = 1; while (k &lt; number) &#123; zeroonepack(k * weight,k * value); number = number - k; k *= 2; &#125; zeroonepack(number * weight , number * value);&#125;int main()&#123; while (cin &gt;&gt; n &gt;&gt; k) &#123; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; value[i] ; &#125; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; number[i]; &#125; memset(dp,0x3f3f3f3f,sizeof dp); memset(back,0x3f3f3f3f,sizeof back); dp[0] = 0; back[0] = 0; bag = k + 20000; for (int i = 1; i &lt;= n; i++) &#123; for (int j = value[i]; j &lt;= bag; j++) &#123; back[j] = min(back[j],back[j - value[i]] + 1); &#125; &#125; for (int i = 1; i &lt;= n; i++) &#123; mutipack(value[i],1,number[i]); &#125; int ans = 0x3f3f3f3f; for (int i = k; i &lt;= bag; i++) &#123; ans = min(ans,back[i - k] + dp[i]); &#125; if (ans == 0x3f3f3f3f) cout &lt;&lt; -1 &lt;&lt; endl; else cout &lt;&lt; ans &lt;&lt; endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>acm</tag>
        <tag>背包九讲</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective java item 6]]></title>
    <url>%2F2019%2F03%2F28%2Feffective-java-item-6%2F</url>
    <content type="text"><![CDATA[Item 6: Avoid creating unnecessary objects It is often appropriate to reuse a single object instead of creating a new function- ally equivalent object each time it is needed. Reuse can be both faster and more stylish. An object can always be reused if it is immutable 去反复的使用一个单一的对象，而不是再次创建一个新对象再需要的时候这样的做法是非常合适的。重复使用可以同时很快有符合现代规则。然后一个对象可以被总是反复使用如果其是不变的话。 下面有一个基本简单的例子 12String s = new String("bikini"); // DON'T DO THIS!String s = "bikini"; 前者是不可以采取的，因为其新建了两个对象，并且第二个新建的对象直接赋值给第一个新建的对象，而后者可取的地方就在于其直接赋值给了第一个对象，不存在创建一个新的对象。 You can often avoid creating unnecessary objects by using static factory meth- ods (Item 1) in preference to constructors on immutable classes that provide both. 你可以经常通过用静态的工厂方法禁止创建一个不必要的对象而不是使用不会改变的类或者是一个构造器。 For example, the factory method Boolean.valueOf(String) is preferable to the constructor Boolean(String), which was deprecated in Java 9. The constructor must create a new object each time it’s called, while the factory method is never required to do so and won’t in practice. 这里举个例子，工厂方法就像上面提供的相比于其的构造函数而言，不需要再每次调用的时候构建一个新的对象，而且如果反复利用的是一个不变的对象的话，你可以保证的是，找个对象永远都不会改变。 Unfortunately, it’s not always obvious when you’re creating such an object. Suppose you want to write a method to determine whether a string is a valid Roman numeral. Here’s the easiest way to do this using a regular expression 不幸的是，当你创建一个这样的对象的时候不总是那么的明显，假设你想要写一个方法去判断一个字符串是否是罗马数字，下面有一个简单的办法来进行判断：1234// Performance can be greatly improved! static boolean isRomanNumeral(String s) &#123; return s.matches("^(?=.)M*(C[MD]|D?C&#123;0,3&#125;)" + "(X[CL]|L?X&#123;0,3&#125;)(I[XV]|V?I&#123;0,3&#125;)$"); &#125; While String.matches is the easiest way to check if a string matches a regular expression, it’s not suitable for repeated use in performance-critical situations. 这通常是一个最简单的方法去判断是否一个字符串去包含常规的语法操作，然而其并不适合多次使用即多次调用的场景下面。 The problem is that it internally creates a Pattern instance for the regular expression and uses it only once, after which it becomes eligible for garbage collection. Creating a Pattern instance is expensive because it requires compiling the regular expression into a finite state machine. 而这个的问题就在于其创建了一个Pattern的实例给相应的正则表达式，而且仅仅只是使用了一次，然后就直接被java垃圾回收器给回收了，而创建一个Pattern的实例的代价是非常昂贵的，因为其需要compiling这个正则表达式到相应的机器里面去。 1234567// Reusing expensive object for improved performance public class RomanNumerals &#123; private static final Pattern ROMAN = Pattern.compile( "^(?=.)M*(C[MD]|D?C&#123;0,3&#125;)" + "(X[CL]|L?X&#123;0,3&#125;)(I[XV]|V?I&#123;0,3&#125;)$"); static boolean isRomanNumeral(String s) &#123; return ROMAN.matcher(s).matches(); &#125; &#125; If the class containing the improved version of the isRomanNumeral method is initialized but the method is never invoked, the field ROMAN will be initialized needlessly. It would be possible to eliminate the initialization by lazily initializing the field (Item 83) the first time the isRomanNumeral method is invoked, but this is not recommended. As is often the case with lazy initialization, it would compli- cate the implementation with no measurable performance improvement (Item 67). 还有一种优化的方案就在于，如果上面这个类永远都没有被调用的话，那么上面直接设置成静态的成员变量就会出现构造对象的浪费，意思就是如果没有被调用就会有浪费，于是有一种方法就是按照之前的单实例化类那样，在构造函数里面加上，如果被调用了，那么就会创建一个final的对象。 Another way to create unnecessary objects is autoboxing, which allows the programmer to mix primitive and boxed primitive types, boxing and unboxing automatically as needed. Autoboxing blurs but does not erase the distinction between primitive and boxed primitive types. 还存在一种方式去创建一些不必要的对象，就是自动打包行为，就是将原生的类型，自动打包成了封装类型，这样也会造成许多不需要的对象，有些对象仅仅只是使用了一次。就像下面这个例子：1234567// Hideously slow! Can you spot the object creation? private static long sum() &#123; Long sum = 0L; for (long i = 0; i &lt;= Integer.MAX_VALUE; i++) sum += i; return sum; &#125; 上面的这个例子就是在加法的时候使long的类型自动包装成一个Long类型，这样则造成了很多不必要的开销。 The present item says, “Don’t create a new object when you should reuse an existing one,”while Item 50 says, “Don’t reuse an existing object when you should create a new one.” Note that the penalty for reusing an object when defensive copying is called for is far greater than the penalty for needlessly creating a duplicate object. Failing to make defensive copies where required can lead to insidious bugs and security holes; creating objects unnecessarily merely affects style and performance. 总而言之，当你可以并且应该重复利用一个已经存在的一个对象的时候，不要重复创建一个新的对象，而第五十条提醒的是 当你需要一个新的对象的时候不要去重复引用一个存在的旧对象。记住一些保护性质copy实际上是并不可取的，这个在后面会涉及到，其实这里与C++里面的知识有点吻合，关于左值引用与右值引用的知识。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>effective_java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective java item 5]]></title>
    <url>%2F2019%2F03%2F26%2Feffective-java-item-5%2F</url>
    <content type="text"><![CDATA[Item 5: Prefer dependency injection to hardwiring resources Many classes depend on one or more underlying resources. For example, a spell checker depends on a dictionary. It is not uncommon to see such classes imple- mented as static utility classes (Item 4): 有一些类依赖一些潜在的资源，就像一个字符串检查器 依靠字典，所以也就不是很特殊见到一些类被翻译成静态的工具类。 Similarly, it’s not uncommon to see them implemented as singletons (Item 3): 就像一些类直接被翻译成单一实例类。 12345678// Inappropriate use of singleton - inflexible &amp; untestable! public class SpellChecker &#123; private final Lexicon dictionary = ...; private SpellChecker(...) &#123;&#125; public static INSTANCE = new SpellChecker(...); public boolean isValid(String word) &#123; ... &#125; public List&lt;String&gt; suggestions(String typo) &#123; ... &#125; &#125; Static utility classes and singletons are inappropriate for classes whose behavior is parameterized by an underlying resource. 静态的工具类和单一实体类，会在存在多种参数替换给基础资源，（就像上面的检查器有多种版本的字典资源一样），那么这些类就会变得特别不合适。 A simple pattern that satisfies this requirement is to pass the resource into the constructor when creating a new instance. This is one form of dependency injection: the dictionary is a dependency of the spell checker and is injected into the spell checker when it is created. 只有一种办法就是在构建的时候 构建函数里面直接给予相应的构造器，这样既维护了单实例化，又解决了上面多版本的问题。 123456789// Dependency injection provides flexibility and testability public class SpellChecker &#123; private final Lexicon dictionary; public SpellChecker(Lexicon dictionary) &#123; this.dictionary = Objects.requireNonNull(dictionary); &#125; public boolean isValid(String word) &#123; ... &#125; public List&lt;String&gt; suggestions(String typo) &#123; ... &#125; &#125; In summary, do not use a singleton or static utility class to implement a class that depends on one or more underlying resources whose behavior affects that of the class, and do not have the class create these resources directly. Instead, pass the resources, or factories to create them, into the constructor (or static factory or builder). This practice, known as dependency injection, will greatly enhance the flexibility, reusability, and testability of a class. 总而言之，不要在实现一个静态工具类或者一个单实例类的时候的同时去实现一个多个资源替换的类，这样会影响其他的类，并且违背了这个类最先开始的本意，好的解决办法就是在类的构造函数里面加上该资源或者带上该工厂方法。 另外对于上面一个函数进行讲解Objects.requireNonNull;其的代码形式如下： 12345public static &lt;T&gt; T requireNonNull(T obj) &#123; if (obj == null) throw new NullPointerException(); return obj;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>effective_java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective java item 4]]></title>
    <url>%2F2019%2F03%2F16%2Feffective-java-item-4%2F</url>
    <content type="text"><![CDATA[Item 4: Enforce noninstantiability with a private constructor强迫不能实例化的类，拥有一个私有的构造函数。 Occasionally you’ll want to write a class that is just a grouping of static methods and static fields. Such classes have acquired a bad reputation because some people abuse them to avoid thinking in terms of objects, but they do have valid uses. 也许有的时候，你需要写一个类，拥有一些静态的变量与函数，而当有人给这些类实例化的时候，这些类往往就具有一些不太好的口碑。因为这些类并不是当成对象，仅仅只是当成一个工具。 (As of Java 8, you can also put such methods in the interface, assuming it’s yours to modify.) Lastly, such classes can be used to group methods on a final class, since you can’t put them in a subclass 在java8的时候你可以把一些函数直接放在接口里面，而最近一些类可以帮用做是一系列的函数群，不过你不能将他们放到可以继承的子类里面去。 Such utility classes were not designed to be instantiated: an instance would be nonsensical. In the absence of explicit constructors, however, the compiler pro- vides a public, parameterless default constructor. To a user, this constructor is indistinguishable from any other. 而一些功能类型的类不是被设计成可实例化的，是因为实例化往往没有意思，而这个时候编译器会自动的提供公开且没有参数的构造函数，对于客户及其使用者而言，必须使这类构造函数隐藏起来。 Attempting to enforce noninstantiability by making a class abstract does not work. The class can be subclassed and the subclass instantiated. 然后仅仅只是强迫这些类变成抽象类是完全达不到效果的，因为这些类还会被继承，而继承其的子类往往还会被实例化。 A default construc- tor is generated only if a class contains no explicit constructors, so a class can be made noninstantiable by including a private constructor: 然后最后的结果就是只能给类安置一个私有的构造函数才能避免以上问题。 就像如下代码：12345678// Noninstantiable utility class public class UtilityClass &#123; // Suppress default constructor for noninstantiability private UtilityClass() &#123; throw new AssertionError(); &#125; ...// Remainder omitted &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>effective_java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective java item 3]]></title>
    <url>%2F2019%2F03%2F15%2Feffective-java-item-3%2F</url>
    <content type="text"><![CDATA[Item 3: Enforce the singleton property with a private constructor or an enum type A singleton is simply a class that is instantiated exactly once [Gamma95]. Single- tons typically represent either a stateless object such as a function (Item 24) or a system component that is intrinsically unique. 首先先解释一下 singleton 这个是表示一个类只会被实例化一次的类，一般用于一些函数类型的功能，以及某些一同的独一无二的重要组成成分。 There are two common ways to implement singletons. Both are based on keeping the constructor private and exporting a public static member to provide access to the sole instance. In one approach, the member is a final field 现在有两种办法去实现这种单实例的情况，基于保证其的构造函数私有化，和输出公开静态成员来保护唯一的实例，一般这个实例都是final的变量。 123456// Singleton with public final field public class Elvis &#123; public static final Elvis INSTANCE = new Elvis(); private Elvis() &#123; ... &#125; public void leaveTheBuilding() &#123; ... &#125; &#125; 以上的例子就是在静态加载的过程中就直接调用这个实例类的函数，外部无法直接去构造这个类，所以也就直接造成这个类只能够被访问一次。 In the second approach to implementing singletons, the public member is a static factory method 第二种方法获得这种单实例化的类，直接使用一个get类型的函数，也可以使用一种你那个懒惰标记的方法，直到调用的时候才开始实例化这个类。 One advantage of the static factory approach is that it gives you the flexibility to change your mind about whether the class is a singleton without changing its API. The factory method returns the sole instance, but it could be modified to return, say, a separate instance for each thread that invokes it. 第一个函数就是给你灵活性去改变这个类是否是单实例化，其的静态工厂方法是返回这个类的唯一实例，但是其很容易被修改，比如说为每一次调用该方法的线程返回一个唯一的实例。 A second advantage is that you can write a generic singleton factory if your application requires it (Item 30). A final advantage of using a static factory is that a method reference can be used as a supplier, for example Elvis::instance is a Supplier. Unless one of these advantages is relevant, the public field approach is preferable 第二个好事就是你可以写一个泛型类型的单实例化类，如果你的应用就此要求的话。就此的方法可以把这个单实例化当成一种提供者。 To make a singleton class that uses either of these approaches serializable (Chapter 12), it is not sufficient merely to add implements Serializable to its declaration. To maintain the singleton guarantee, declare all instance fields transient and provide a readResolve method (Item 89). Otherwise, each time a serialized instance is deserialized, a new instance will be created, leading, in the case of our example, to spurious Elvis sightings. 为了保证每一次访问到类里面的，去获得一个”只读函数“，这样就防止每一次访问到这个类的时候不会再生成一个新的类，确确实实的保证了类的单一性。 A third way to implement a singleton is to declare a single-element enum: 第三种方法实现单实例化是生成一个单个元素的枚举类 This approach is similar to the public field approach, but it is more concise, provides the serialization machinery for free, and provides an ironclad guarantee against multiple instantiation, even in the face of sophisticated serialization or reflection attacks. This approach may feel a bit unnatural, but a single-element enum type is often the best way to implement a singleton. 这种类型的方法就是类似于类的变量方法，但是这个更精细，提供的机器内存消耗几乎就是免费的，并且提供（这里后面的一句话 英文没怎么看懂 自动标红）。 这种方法可能有点不自然，但是这种方法往往是实现这种单实例化最好的方法。 Note that you can’t use this approach if your singleton must extend a superclass other than Enum (though you can declare an enum to implement interfaces). 记住如果你需要用单实例化类去继承一个类的话，那么就不能使用这种单枚举的方法了。其的样例代码如下：1234567// Enum singleton - the preferred approach public enum Elvis &#123; INSTANCE; public void leaveTheBuilding() &#123; ... &#125; &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>effective_java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective java item 2]]></title>
    <url>%2F2019%2F03%2F14%2Feffective-java-item-2%2F</url>
    <content type="text"><![CDATA[Item 2: Consider a builder when faced with many constructor parameters条款二 当面临许多构造参数的时候，建议考虑一下一个构造器(builder) What sort of constructors or static factories should you write for such a class? Traditionally, programmers have used the telescoping constructor pattern, in which you provide a constructor with only the required parameters, another with a single optional parameter, a third with two optional parameters, and so on, culmi- nating in a constructor with all the optional parameters. 经常会遇到构造函数中有多个参数，而这些参数，如果按照标准的方法来写的话，会特别的麻烦，于是就采用C++中的委托构造函数，利用其中一个构造函数，为其他所有的构造函数构造，相当于起到了一个构造器的作用(builder) Typically this constructor invocation will require many parameters that you don’t want to set, but you’re forced to pass a value for them anyway. In this case, we passed a value of 0 for fat. 很多时候你不想设置那么多的参数，最简单的一个办法是给这个成员直接设置0。 In short, the telescoping constructor pattern works, but it is hard to write client code when there are many parameters, and harder still to read it. The reader is left wondering what all those values mean and must carefully count parameters to find out. Long sequences of identically typed parameters can cause subtle bugs. If the client accidentally reverses two such parameters, the compiler won’t complain, but the program will misbehave at runtime (Item 51). 简而言之，这种委托构造函数虽然可行，但是客户在写代码的时候很容易写错，就算写对了，也很难读出来，并且也会出现一种情况就是当参数够多的时候，写错了参数的顺序，这样造成的错误，编译器是不会轻易报错的。所以这里就很难被找出来。 A second alternative when you’re faced with many optional parameters in a constructor is the JavaBeans pattern, in which you call a parameterless construc- tor to create the object and then call setter methods to set each required parameter and each optional parameter of interest 还有第二种办法就是 给每一个私有成员设置一个set函数，一个外围的函数直接可以作用到内部私有成员，并且直接设置其的值。 Unfortunately, the JavaBeans pattern has serious disadvantages of its own.Because construction is split across multiple calls, a JavaBean may be in an inconsistent state partway through its construction. The class does not have the option of enforcing consistency merely by checking the validity of the constructor parameters. Attempting to use an object when it’s in an inconsistent state may cause failures that are far removed from the code containing the bug and hence difficult to debug. 不幸的是，这种模式的代码写法，将构造过程与赋值过程分开，也就意味着，当构造对象并没有赋值的时候会造成错误，另外，其还会在写一个immutable类的时候花费额外的工作保证线程安全。 Luckily, there is a third alternative that combines the safety of the telescoping constructor pattern with the readability of the JavaBeans pattern. It is a form of the Builder pattern [Gamma95]. Instead of making the desired object directly, the client calls a constructor (or static factory) with all of the required parameters and gets a builder object. Then the client calls setter-like methods on the builder object to set each optional parameter of interest. Finally, the client calls a parameterless build method to generate the object, which is typically immutable. 幸运的是 这里存在第三种构造方式，结合上述两种方法的优点，并且保证了线程安全，也不会有过多的参数的麻烦。按照下述的例子，直接在内的内部构造一个静态的builder的类，用一个其他的类来构造这个类，第一解决了immutable的问题，其次也解决了参数不能特意的问题。 This client code is easy to write and, more importantly, easy to read. The Builder pattern simulates named optional parameters as found in Python and Scala. NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8) .calories(100).sodium(35).carbohydrate(27).build();Check invariants involving multiple parameters in the constructor invoked by the build method. To ensure these invariants against attack, do the checks on object fields after copying parameters from the builder (Item 50). If a check fails, throw an IllegalArgumentException (Item 72) whose detail message indicates which parameters are invalid (Item 75). 这样的做法会造成代码清晰可读，并且最重要的是，可以在构造器这个类型里面进行一个check函数进行异常检查。 The Builder pattern is well suited to class hierarchies. Use a parallel hier- archy of builders, each nested in the corresponding class. Abstract classes have abstract builders; concrete classes have concrete builders. 这种构造模式，其实特别有利于类型继承，利用相应的类内的构造器帮助进行构造。一般利用像如下形式的构造方法即可：记住这个地方时直接用过build 来返回外部的那个类。 NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8) .calories(100).sodium(35).carbohydrate(27).build(); Here are two concrete subclasses of Pizza, one of which represents a standard New-York-style pizza, the other a calzone. 后面的两种模式属于继承过程中出现的构造，注意构造的这个构造器 一定要满足如下形式。最重要的是下面继承处的处理，调用基类的构造器 super(builder);12345678910111213141516171819202122232425262728293031323334353637public class NyPizza extends Pizza &#123; public enum Size &#123; SMALL, MEDIUM, LARGE &#125; private final Size size; public static class Builder extends Pizza.Builder&lt;Builder&gt; &#123; private final Size size; public Builder(Size size) &#123; this.size = Objects.requireNonNull(size); &#125; @Override public NyPizza build() &#123; return new NyPizza(this); &#125; @Override protected Builder self() &#123; return this; &#125; &#125; private NyPizza(Builder builder) &#123; super(builder); size = builder.size; &#125; &#125; public class Calzone extends Pizza &#123; private final boolean sauceInside; public static class Builder extends Pizza.Builder&lt;Builder&gt; &#123; private boolean sauceInside = false; // Default public Builder sauceInside() &#123; sauceInside = true; return this; &#125; @Override public Calzone build() &#123; return new Calzone(this); &#125; @Override protected Builder self() &#123; return this; &#125; &#125; private Calzone(Builder builder) &#123; super(builder); sauceInside = builder.sauceInside; &#125; &#125; This technique, wherein a subclass method is declared to return a subtype of the return type declared in the super- class, is known as covariant return typing. It allows clients to use these builders without the need for casting. 这项技术返回的类都是隶属于该类的，这样做的好处可以允许客户使用这些类而不需要使用转型。 A single builder can be used repeatedly to build multiple objects. The parameters of the builder can be tweaked between invocations of the build method to vary the objects that are created. A builder can fill in some fields automatically upon object creation, such as a serial number that increases each time an object is created. 由于是静态的类，所以只需要被构造一次，却可以造成多次使用，这里就是其的好处，，而这个构造器可以在这个对象被创建之后自动赋值。，比较方便。 The Builder pattern has disadvantages as well. In order to create an object, you must first create its builder. While the cost of creating this builder is unlikely to be noticeable in practice, it could be a problem in performance-critical situations. Also, the Builder pattern is more verbose than the telescoping constructor pattern 其存在的坏处就在于，其写出来的代码非常的复杂和冗杂，对于只有一点参数的构造器而言，完全没有这样写的必要，但是对于先开始只有一点参数，但是后面则变成很多参数的工程来说第一次使用这种构造器方便以后来写。 In summary, the Builder pattern is a good choice when designing classes whose constructors or static factories would have more than a handful of parameters 总而言之，使用这种办法的方便在于大工程，且一个类的构造参数过多的情况，即解决了参数冗杂的问题，又再次解决了类不能final的问题。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>effective_java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[effective java item 1]]></title>
    <url>%2F2019%2F03%2F13%2Feffective-java-item-1%2F</url>
    <content type="text"><![CDATA[Item 1: Consider static factory methods instead of constructors前面几个条款的内容是关于创建和销毁对象。 The traditional way for a class to allow a client to obtain an instance is to provide a public constructor. There is another technique that should be a part of every programmer’s toolkit. A class can provide a public static factory method, which is simply a static method that returns an instance of the class. Here’s a simple example from Boolean (the boxed primitive class for boolean). This method translates a boolean primitive value into a Boolean object reference: 考虑直接用一个静态的方法来完成构造函数的功能，比如接受一个对象，然后通过这个对象来构造一个新的对象。 A class can provide its clients with static factory methods instead of, or in addition to, public constructors. Providing a static factory method instead of a public constructor has both advantages and disadvantages. 提供一个静态方法作为构造函数的有额外相对于提供公开构造函数的好处以及坏处。 One advantage of static factory methods is that, unlike constructors, they have names. If the parameters to a constructor do not, in and of themselves, describe the object being returned, a static factory with a well-chosen name is easier to use and the resulting client code easier to read. 第一个好处是静态的函数有独特的名字而构造函数没有名字，通过名字将构造函数的参数进行一个分类显示的更加耐用。 the constructor BigInteger(int, int, Random), which returns a BigInteger that is probably prime, would have been better expressed as a static factory method named BigInteger.probablePrime. 就像大整数类在里面就有一个构造一个趋近于自己值的质数的大整数类，然后这里直接用名字命名显得更加方便。 Because they have names, static factory methods don’t share the restriction discussed in the previous paragraph. In cases where a class seems to require multiple constructors with the same signature, replace the constructors with static factory methods and carefully chosen names to highlight their differences. 有的时候一些公开构造函数的参数类型，以及参数的顺序，代表着不同的构造函数，这样会容易弄混淆，于是这也是体现名字第二个好的地方。 A second advantage of static factory methods is that, unlike constructors, they are not required to create a new object each time they’re invoked. 第二个好处就是相比于构造函数每次在被call的时候，会构造一个新的对象，而静态方法有的时候则会节省下这一笔开销。就像之前举了一个例子，Boolean.valueOf 从来没有构造一个新的对象。 . Instance control allows a class to guarantee that it is a singleton (Item 3) or noninstantiable (Item 4). Also, it allows an immutable value class (Item 17) to make the guarantee that no two equal instances exist: a.equals(b) if and only if a == b. This is the basis of the Flyweight pattern . Enum types (Item 34) provide this guarantee. 这种实例化重复使用一个对象，得到的两个好处，第一个好处就是保证其是一个singleton,另一个好处，就是保证在调用equal函数的时候只能允许相等的条件只会有一个，那么就可以直接使用==号进行操作，从而进行性能上面的提升。 A third advantage of static factory methods is that, unlike constructors, they can return an object of any subtype of their return type. This gives you great flexibility in choosing the class of the returned object. 而其的第三点好处就体现在其的返回值可以为任意该类型的子类型对象，这样在类型的返回的时候会提供很大的灵活性。 One application of this flexibility is that an API can return objects without making their classes public. Hiding implementation classes in this fashion leads to a very compact API. 而其中的第一点应用就在于返回API接口的时候可以不需要将这个类弄成公开的，隐藏其的实现。 For example, the Java Collections Framework has forty-five utility implementations of its interfaces, providing unmodifiable collections, synchronized collections, and the like. Nearly all of these implemen- tations are exported via static factory methods in one noninstantiable class (java.util.Collections). The classes of the returned objects are all nonpublic. java在实现其的接口的时候，在接口里面采用静态的方法，导出的类往往都是没有公有化的，这样实现了 类的实现过程的隐藏。 one for each convenience implemen- tation. It is not just the bulk of the API that is reduced but the conceptual weight: the number and difficulty of the concepts that programmers must master in order to use the API. The programmer knows that the returned object has precisely the API specified by its interface, so there is no need to read additional class docu- mentation for the implementation class. Furthermore, using such a static factory method requires the client to refer to the returned object by interface rather than implementation class, which is generally good practice (Item 64). 开发者在接口的使用过程中，通过其的返回类型可以逐渐了解到其API的真实用途，这样来就不需要阅读额外的开发者文档。 As of Java 8, the restriction that interfaces cannot contain static methods was eliminated, so there is typically little reason to provide a noninstantiable compan- ion class for an interface. Many public static members that would have been at home in such a class should instead be put in the interface itself. Note, however, that it may still be necessary to put the bulk of the implementation code behind these static methods in a separate package-private class. This is because Java 8 requires all static members of an interface to be public. Java 9 allows private static methods, but static fields and static member classes are still required to be public. java8的时候就同样将 接口里面不能放静态类型的函数规定给消除了，所以这个时候就没有理由去提供一个不可实例化的类给一个接口了，而许多静态成员应该被放在这样一个接口本身里，记住，现在还是最重要的是将实现的代码放在这些静态实现方法之后。这是因为java8 所有的静态成员都必须公开，而java9 则允许私有的静态函数，其他则是公开的。 A fourth advantage of static factories is that the class of the returned object can vary from call to call as a function of the input parameters. Any sub- type of the declared return type is permissible. The class of the returned object can also vary from release to release. 第四个好处就在于返回的子类型中可以根据参数的形式来进行改变 一一对应的关系，这里举出了一个enumset的例子 （我看的不是很懂 所以这里标红，以后有时间再次来了解一下。） A fifth advantage of static factories is that the class of the returned object need not exist when the class containing the method is written. Such flexible static factory methods form the basis of service provider frameworks, like the Java Database Connectivity API (JDBC). A service provider framework is a system in which providers implement a service, and the system makes the implementations available to clients, decoupling the clients from the implementations. 第五个好处就是当类中包含的函数已经被写了，然后这返回对象不需要存在，（这一点也没有看懂，等以后拜读了中文版再来解释，手动标红） The main limitation of providing only static factory methods is that classes without public or protected constructors cannot be subclassed. For example, it is impossible to subclass any of the convenience implementation classes in the Collections Framework. Arguably this can be a blessing in disguise because it encourages programmers to use composition instead of inheritance (Item 18), and is required for immutable types (Item 17). 其实这个地方最大的一个局限的地方就在于，如果一个类没有公开或者保护的构造函数的话 那么这个类是不允许被继承的，意思就是对于被静态函数得来的类，因为不具有公开的构造函数 所以不能够被子类化。 A second shortcoming of static factory methods is that they are hard for programmers to find. They do not stand out in API documentation in the way that constructors do, so it can be difficult to figure out how to instantiate a class that provides static factory methods instead of constructors. 第二个缺点就在于可能开发者会很不容易找到这些静态方法，而且他们不会像平常构造函数一样，所以很难理解实例化一个类提供的静态函数而不是此构造函数。 不过有一些静态函数的样例 类似的模板 可以自己在书中去查找。 In summary, static factory methods and public constructors both have their uses, and it pays to understand their relative merits. Often static factories are preferable, so avoid the reflex to provide public constructors without first consid- ering static factories. 总之 两种构造函数都有相应的好处与坏处，具体样例具体分析。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>effective_java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数专题的java方法总结]]></title>
    <url>%2F2019%2F03%2F13%2F%E5%A4%A7%E6%95%B0%E4%B8%93%E9%A2%98%E7%9A%84java%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[其实这里题目类型都差不多仅仅只贴出几道题的代码，并且对这些题目所用到的函数进行一个总结。123456789101112131415161718192021222324import java.math.BigDecimal;import java.util.Scanner;import java.io.BufferedInputStream;public class E &#123; public static void main(String[] args) &#123; Scanner in = new Scanner(System.in); while (in.hasNext()) &#123; BigDecimal r; int n; r = in.nextBigDecimal(); n = in.nextInt(); BigDecimal ans; ans = r.pow(n); ans = ans.stripTrailingZeros(); String res = ans.toPlainString(); while (res.startsWith("0")) &#123;res =res.substring(1);&#125; System.out.println(res); &#125; in.close(); &#125;&#125; stripTrailingZeros() 这个函数的意思是去除多余的0。toPlainString() 这个函数的意思是将某些科学计数法，给全部展开。startsWith(&quot;0&quot;) 这个函数的意思就是 判断字符串到底以什么函数为前提。substring(1) 这个函数的意思就是字符串进行一个有效的替换。 另外 java 里面大数的大数幂次方必须要规定一个mod对象 实现函数则为modpow() 最后再累积点 C++ 知识：12345678910A*B % C = (A%C * B%C)%C(A+B)%C = (A%C + B%C)%C如 532 mod 7 =（500%7+30%7+2%7)%7;当然还有a*b mod c=(a mod c+b mod c)mod c;如35 mod 3=((5%3)*(7%3))%3 还有一道题目 具体看代码这道题展现了 java在求余数方面的缺陷。 重要的就是这一步 v = (v * 10 + s[i] - ‘0’) % mod123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.util.Scanner;import java.math.BigInteger;public class H &#123; public static void main(String[] args) &#123; Scanner cin = new Scanner(System.in); BigInteger a; String b,c; int Case = 1; while (cin.hasNext()) &#123; a = cin.nextBigInteger(); b = a.mod(new BigInteger("137")).toString(); c = a.mod(new BigInteger("73")).toString(); if (b.equals("0") &amp;&amp; c.equals("0") ) System.out.println("Case #" + Case++ + ": YES"); else System.out.println("Case #" + Case++ + ": NO"); &#125; &#125;&#125;/*关于这道题，不知道为什么用java 提交就是没有办法过，全部都是爆内存，我个人觉得可能在大数，求余数这方面，可能存在缺陷。下面提供几个 AC的 C++代码#include&lt;cstdio&gt;#include&lt;cstring&gt;#include&lt;algorithm&gt;using namespace std;const int maxn = 10000000 + 1;const int mod = 10001;char s[maxn];int main()&#123; int kase = 0; while(scanf("%s",s) == 1)&#123; int len = strlen(s); int v = 0; for (int i = 0; i &lt; len; ++i)&#123; v = (v*10 + s[i]-48) % mod; &#125; if (v == 0)printf("Case #%d: YES\n",++kase); else printf("Case #%d: NO\n",++kase); &#125; return 0;&#125;*/]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>题解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四道关于BFS的情况变换题目]]></title>
    <url>%2F2019%2F03%2F13%2F%E5%9B%9B%E9%81%93%E5%85%B3%E4%BA%8EBFS%E7%9A%84%E6%83%85%E5%86%B5%E5%8F%98%E6%8D%A2%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[这个专题 同样还是总结一些BFS的题目，但是这些BFS的题目都存在一个特定的特点，也就是你真的没有办法猜到，原来这道题目最后是通过BFS的方法做的。 第一题 FliptileFliptile 这道题 个人是觉得很有必要来做一遍，这道题不太属于一个严格的bfs，但是这道题的递归解题思路很有意思。 题目大意就是两种颜色的格子，给定一个初始图，翻动最小的步数，使得全部为白色，并且最后给出翻动与不翻动的图片 这道题最好玩的是 我们需要明白一个前提，第i行的格子在竖排上只能被上面的颜色改变，意思是 最后一排的只能根据倒数第二排的位置来确定。那我们通过递归确定第一排便利下去的每一种方法，然后判断是否会进行改变，最后保证最后一排全部为白色，也就达到了全部为白色的效果。 需要注意的是，里面有一个&amp; 1的操作，这个意思就是对2求余，最终导致的结果就是可以判断该位置的格子该不该重复翻转过来。 代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;using namespace std;const int maxn = 17;int cpy[maxn][maxn];int map[maxn][maxn];int res[maxn][maxn];int n,m;int Min;bool judge() &#123; for (int i = 1; i &lt;= m; i ++) &#123; int tmp = cpy[n][i] + cpy[n][i - 1] + cpy[n][i + 1] + cpy[n - 1][i]; if ((map[n][i] + tmp) &amp; 1) return false; &#125; return true;&#125;void dfs(int a,int num) &#123; if (num &gt; Min) return; if (a &gt; n) &#123; if (judge() &amp;&amp; Min &gt; num) &#123; Min = num; memcpy(res,cpy,sizeof (cpy)); return ; &#125; return; &#125; int _time = 0; for (int i = 1 ; i &lt;= m; i ++) &#123; int tmp = map[a - 1][i] + cpy[a - 1][i] + cpy[a - 2][i] + cpy[a - 1][i - 1] + cpy[a - 1][i + 1]; if (tmp &amp; 1) &#123; cpy[a][i] = 1; _time ++; &#125; else cpy[a][i] = 0; &#125; dfs(a + 1, num + _time);&#125;void solve(int a,int num) &#123; if (a &gt; m) &#123; dfs(2,num); return ; &#125; cpy[1][a] = 0; solve(a + 1,num); cpy[1][a] = 1; solve(a + 1,num + 1);&#125;void get()&#123; while( cin &gt;&gt; n &gt;&gt; m) &#123; for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= m; j++) &#123; cin &gt;&gt; map[i][j]; &#125; &#125; Min = 0x3f3f3f3f; memset(cpy,0,sizeof(cpy)); solve(1,0); if (Min == 0x3f3f3f3f) cout &lt;&lt; "IMPOSSIBLE" &lt;&lt; endl; else &#123; for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= m; j++) &#123; cout &lt;&lt; res[i][j] &lt;&lt; " "; &#125; cout &lt;&lt; endl; &#125; &#125; &#125;&#125;int main()&#123; get(); return 0;&#125; 第二题 potspots 这道题刚开始看的第一眼完全想象不到这竟然是一个BFS的题目，因为相互之间倒水，当时是完全没有一点思路的，不过后来根据BFS层序查找的性质，可以逐渐发现，原来这个地方的一共有六种情况，然后将已经遍历过的和不符合条件的全部去除，然后将返回到原来的位置的情况直接失败，很容易就可以用BFS给弄出来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;queue&gt;#include&lt;cstring&gt;#include&lt;iterator&gt;using namespace std;int A,B,C;const int maxn = 1005;bool vis[maxn][maxn];const string s[6] = &#123;"FILL(1)", "FILL(2)", "DROP(1)", "DROP(2)", "POUR(1,2)", "POUR(2,1)"&#125;;struct Node&#123; int v_a,v_b; int step; vector&lt;string&gt; vs; Node() &#123;&#125;; Node (int a,int b,int c) : v_a(a), v_b(b), step(c) &#123; &#125;&#125;;bool bfs() &#123; queue&lt;Node&gt; q; Node now(0,0,0),next; vis[0][0] = true; q.push(now); vector&lt;string&gt; * tmp; while(!q.empty()) &#123; Node now = q.front(); q.pop(); if (now.v_a == C || now.v_b == C) &#123; cout &lt;&lt; now.step &lt;&lt; endl; for (int it = 0; it != now.vs.size(); it++) &#123; cout &lt;&lt; now.vs[it] &lt;&lt; endl; &#125; return true; &#125; if (now.v_a != A) &#123; next.v_a = A; next.v_b = now.v_b; next.step = now.step + 1; if (!vis[next.v_a][next.v_b])&#123; vis[next.v_a][next.v_b] = true; next.vs = now.vs; next.vs.push_back(s[0]); q.push(next); &#125; &#125; if (now.v_b != B) &#123; next.v_b = B; next.v_a = now.v_a; next.step = now.step + 1; if (!vis[next.v_a][next.v_b]) &#123; vis[next.v_a][next.v_b] = true; next.vs = now.vs; next.vs.push_back(s[1]); q.push(next); &#125; &#125; if (now.v_a != 0)&#123; next.v_a = 0; next.v_b = now.v_b; next.step = now.step + 1; if (!vis[next.v_a][next.v_b]) &#123; vis[next.v_a][next.v_b] = true; next.vs = now.vs; next.vs.push_back(s[2]); q.push(next); &#125; &#125; if (now.v_b != 0)&#123; next.v_b = 0; next.v_a = now.v_a; next.step = now.step + 1; if (!vis[next.v_a][next.v_b]) &#123; vis[next.v_a][next.v_b] = true; next.vs = now.vs; next.vs.push_back(s[3]); q.push(next); &#125; &#125; if (now.v_a != 0 &amp;&amp; now.v_b != B) &#123; next.v_a = now.v_a - (B - now.v_b); next.v_b = now.v_a + now.v_b; if (next.v_b &gt; B) next.v_b = B; if (next.v_a &lt; 0) next.v_a = 0; next.step = now.step + 1; if (!vis[next.v_a][next.v_b]) &#123; vis[next.v_a][next.v_b] = true; next.vs = now.vs; next.vs.push_back(s[4]); q.push(next); &#125; &#125; if (now.v_a != A &amp;&amp; now.v_b != 0)&#123; next.v_b = now.v_b - (A - now.v_a); next.v_a = now.v_a + now.v_b; if (next.v_a &gt; A) next.v_a = A; if (next.v_b &lt; 0) next.v_b = 0; next.step = now.step + 1; if (!vis[next.v_a][next.v_b]) &#123; vis[next.v_a][next.v_b] = true; next.vs = now.vs; next.vs.push_back(s[5]); q.push(next); &#125; &#125; &#125; return false;&#125;int main()&#123; while(cin &gt;&gt; A &gt;&gt; B &gt;&gt; C) &#123; memset(vis,false,sizeof vis); if (!bfs()) cout &lt;&lt; "impossible" &lt;&lt; endl; &#125; return 0;&#125; 第三题 非常可乐非常可乐 这一道题，其实与上面一道题很类似的地方就在于，也是将诸多情况进行一个总结与分布，符合条件的入队列，不符合条件的直接出队列。关键就是这道题的条件设置方面与上面一题有些不同。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160import java.util.*;public class L_非常可乐 &#123; static Scanner in = new Scanner(System.in); static final int maxn = 105; // 标志数组来标记路径，三个杯子三维数组即可 static int[][][] visited = new int[maxn][maxn][maxn]; static void init() &#123; for (int i = 0; i &lt; maxn; ++i) for (int j = 0; j &lt; maxn; ++j) for (int k = 0; k &lt; maxn; ++k) visited[i][j][k] = 0; &#125; // a b c为三个容器的最大容量 static void bfs(int a, int b, int c) &#123; if (a % 2 == 1) &#123; System.out.println("NO"); return; &#125; //记住这里可以直接写queue的接口 来声明类型 并且在后面 new 的时候 以LinkedList来实现 其的接口 Queue&lt;Node&gt; que = new LinkedList&lt;Node&gt;(); // 初始 que.add(new Node(a, 0, 0, 0)); while (!que.isEmpty()) &#123; // 取队头并弹出 Node t = que.poll(); visited[t.a][t.b][t.c] = 1; // 判断是否符合条件 if (t.a == t.b &amp;&amp; t.c == 0 || t.a == t.c &amp;&amp; t.b == 0 || t.b == t.c &amp;&amp; t.a == 0) &#123; System.out.println(t.step); return; &#125; // 倒水过程，注意倒水的前提是杯子里面有水 // b -&gt; a if (t.b != 0) &#123; // 因为没有刻度， 所以每次倒水都有两种情况 // 第一种情况是把自己倒完 if (t.a + t.b &lt;= a) &#123; if (visited[t.a + t.b][0][t.c] == 0) &#123; que.add(new Node(t.a + t.b, 0, t.c, t.step + 1)); visited[t.a + t.b][0][t.c] = 1; &#125; &#125; // 第二种情况是把对方倒满 else if (t.a != a) &#123; if (visited[a][t.b - (a - t.a)][t.c] == 0) &#123; que.add(new Node(a, t.b - (a - t.a), t.c, t.step + 1)); visited[a][t.b - (a - t.a)][t.c] = 1; &#125; &#125; &#125; // c -&gt; a if (t.c != 0) &#123; if (t.a + t.c &lt;= a) &#123; if (visited[t.a + t.c][t.b][0] == 0) &#123; que.add(new Node(t.a + t.c, t.b, 0, t.step + 1)); visited[t.a + t.c][t.b][0] = 1; &#125; &#125; else if (t.a != a) &#123; if (visited[a][t.b][t.c - (a - t.a)] == 0) &#123; que.add(new Node(a, t.b, t.c - (a - t.a), t.step + 1)); visited[a][t.b][t.c - (a - t.a)] = 1; &#125; &#125; &#125; // b -&gt; c if (t.b != 0) &#123; if (t.b + t.c &lt;= c) &#123; if (visited[t.a][0][t.b + t.c] == 0) &#123; que.add(new Node(t.a, 0, t.b + t.c, t.step + 1)); visited[t.a][0][t.b + t.c] = 1; &#125; &#125; else if (t.c != c) &#123; if (visited[t.a][t.b - (c - t.c)][c] == 0) &#123; que.add(new Node(t.a, t.b - (c - t.c), c, t.step + 1)); visited[t.a][t.b - (c - t.c)][c] = 1; &#125; &#125; &#125; // c -&gt; b if (t.c != 0) &#123; if (t.c + t.b &lt;= b) &#123; if (visited[t.a][t.c + t.b][0] == 0) &#123; que.add(new Node(t.a, t.c + t.b, 0, t.step + 1)); visited[t.a][t.c + t.b][0] = 1; &#125; &#125; else if (t.b != b) &#123; if (visited[t.a][b][t.c - (b - t.b)] == 0) &#123; que.add(new Node(t.a, b, t.c - (b - t.b), t.step + 1)); visited[t.a][b][t.c - (b - t.b)] = 1; &#125; &#125; &#125; // a -&gt; b if (t.a != 0) &#123; if (t.a + t.b &lt;= b) &#123; if (visited[0][t.a + t.b][t.c] == 0) &#123; que.add(new Node(0, t.a + t.b, t.c, t.step + 1)); visited[0][t.a + t.b][t.c] = 1; &#125; &#125; else if (t.b != b) &#123; if (visited[t.a - (b - t.b)][b][t.c] == 0) &#123; que.add(new Node(t.a - (b - t.b), b, t.c, t.step + 1)); visited[t.a - (b - t.b)][b][t.c] = 1; &#125; &#125; &#125; // a -&gt; c if (t.a != 0) &#123; if (t.a + t.c &lt;= c) &#123; if (visited[0][t.b][t.a + t.c] == 0) &#123; que.add(new Node(0, t.b, t.a + t.c, t.step + 1)); visited[0][t.b][t.a + t.c] = 1; &#125; &#125; else if (t.c != c) &#123; if (visited[t.a - (c - t.c)][t.b][c] == 0) &#123; que.add(new Node(t.a - (c - t.c), t.b, c, t.step + 1)); visited[t.a - (c - t.c)][t.b][c] = 1; &#125; &#125; &#125; &#125; System.out.println("NO"); &#125; public static void main(String[] args) &#123; while (in.hasNext()) &#123; int a = in.nextInt(), b = in.nextInt(), c = in.nextInt(); if (a == 0 &amp;&amp; b == 0 &amp;&amp; c == 0) break; init(); bfs(a, b, c); &#125; &#125;&#125;class Node &#123; // a b c 代表实际拥有水的体积 int a, b, c, step; Node(int a, int b, int c, int step) &#123; this.a = a; this.b = b; this.c = c; this.step = step; &#125;&#125; 第四题 prime pathprime path 这道题 同样看题目这的没有办法观察到这是一个BFS的题目，只有看到后面才逐渐发现这道题目 其实是通过搜寻每个部位的变化，最终导致输出结果不过这里会借助到一些筛选质数的办法 比如欧拉筛 比如埃式筛 只不过后面是直接用暴力枚举这部分 我是真的没有想到，暴力枚举了四十种情况。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;queue&gt;#include&lt;cstring&gt;#include&lt;vector&gt;using namespace std;int T;int a,b;const int maxn = 10000;int prime[maxn];bool check[maxn];bool vis[maxn];int tot = 0;struct Node &#123; int x,step; Node()&#123;&#125;; Node(int a,int c):x(a),step(c)&#123;&#125;&#125;;void get_prime() &#123; memset(check,false,sizeof(check)); for (int i = 2; i &lt; maxn ; i++) &#123; if (!check[i]) prime[tot++] = i; for (int j = 0; j &lt; tot; j++) &#123; if (i * prime[j] &gt; maxn) break; check[i * prime[j]] = true; if (i % prime[j] == 0) break; &#125; &#125;&#125;int bfs(int a,int b) &#123; memset(vis,false,sizeof vis); queue&lt;Node&gt; q; Node o1(a,0),o2,o3; q.push(o1); vis[a] = false; while(!q.empty()) &#123; o2 = q.front(); q.pop(); if (o2.x == b) return o2.step; int num[4]; num[0] = o2.x / 1000; num[1] = o2.x / 100 % 10; num[2] = o2.x / 10 % 10; num[3] = o2.x % 10; for (int i = 0; i &lt; 4; i++) &#123; int tmp = num[i]; for (int j = 0; j &lt; 10; j++) &#123; num[i] = j; int yy = num[0] * 1000 + num[1] * 100 + num[2] *10 + num[3]; if (!vis[yy] &amp;&amp; !check[yy] &amp;&amp; yy &gt; 1000 &amp;&amp; yy &lt; 9999) &#123; vis[yy] = true; o3.x = yy; o3.step = o2.step + 1; q.push(o3); &#125; &#125; num[i] = tmp; &#125; &#125; return -1;&#125;int main()&#123; get_prime(); cin &gt;&gt; T; int ans = -1; while(T--) &#123; cin &gt;&gt; a &gt;&gt; b; ans = bfs(a,b); if (ans == -1) cout &lt;&lt; "Impossible" &lt;&lt; endl; else cout &lt;&lt; ans &lt;&lt; endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>BFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两道与fire有关的基础BFS]]></title>
    <url>%2F2019%2F03%2F13%2F%E4%B8%A4%E9%81%93%E4%B8%8Efire%E6%9C%89%E5%85%B3%E7%9A%84%E5%9F%BA%E7%A1%80BFS%2F</url>
    <content type="text"><![CDATA[第一道题fire game 这道题目其实就是一个简单的bfs，但是令我特别困惑的是，我不知道怎么去取每一个火苗向四周扩散的时间，然后最后才知道，原来是直接计算那个最长的路线就行了，这道题目的意思就是根据每一个点的遍历，去寻找最长的那一个点，将每个点放进去，然后找距离这个点最长的距离就是其扩散的最终时间，然后到最后依次枚举两个点，按照各自两个点之间的最快的时间来决定最终的时间。 其实这道题不难，一道bfs的模拟题目，只不过就是后面决策的那个地方不太好下。 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;queue&gt;#include&lt;cstring&gt;using namespace std;#define inf 0x3f3f3f3fint n,m;const int maxn = 15;char map[maxn][maxn];int vis[maxn][maxn];struct point&#123; int x,y,pos; point ()&#123;&#125; point (int a,int b,int c) : x(a),y(b),pos(c) &#123;&#125; point move(int i) &#123; point tmp(x,y,pos); switch (i)&#123; case 0:&#123; tmp.x = x + 1; break; &#125; case 1: &#123; tmp.x = x - 1; break; &#125; case 2: &#123; tmp.y = y + 1; break; &#125; case 3: &#123; tmp.y = y - 1; break; &#125; &#125; tmp.pos++; return tmp; &#125;&#125;;int bfs(point a,point b) &#123; queue&lt;point&gt; q; point now,next; q.push(a); q.push(b); memset(vis,inf,sizeof vis); vis[a.x][a.y] = 0; vis[b.x][b.y] = 0; while (!q.empty()) &#123; now = q.front(); q.pop(); for (int i = 0; i &lt; 4; i++) &#123; next = now.move(i); if (next.x &gt;= 0 &amp;&amp; next.x &lt; n &amp;&amp; next.y &gt;= 0 &amp;&amp; next.y &lt; m &amp;&amp; map[next.x][next.y] == '#' &amp;&amp; vis[next.x][next.y] == inf) &#123; vis[next.x][next.y] = next.pos; q.push(next); &#125; &#125; &#125; int res = 0; for (int i = 0 ;i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; if (map[i][j] == '#') //这里就是找在层序遍历中距离res最大的每一个点，即最后的时间。 res = max(res,vis[i][j]); &#125; &#125; return res;&#125;int main()&#123; int T; cin &gt;&gt; T; int Case = 1; while (T--) &#123; cin &gt;&gt; n &gt;&gt; m; int cnt = 0; getchar(); for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j ++) &#123; cin &gt;&gt; map[i][j]; if (map[i][j] == '#') &#123; cnt ++; &#125; &#125; getchar(); &#125; if (cnt &lt;= 2) &#123; cout &lt;&lt; "Case " &lt;&lt; Case++ &lt;&lt; ": " &lt;&lt; 0 &lt;&lt; endl; continue; &#125; int res = inf; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; if (map[i][j] == '#') &#123; for (int l = 0; l &lt; n; l++) &#123; for (int k = 0; k &lt; m; k++) &#123; if (l &lt;= i &amp;&amp; k &lt;= j) continue; if (map[l][k] == '#')&#123; point p1(i,j,0); point p2(l,k,0); //这里就是找每一个距离最远的点中最小的那个值。 int ans = bfs(p1,p2); res = min(ans,res); &#125; &#125; &#125; &#125; &#125; &#125; if (cnt == inf) cout &lt;&lt; "Case " &lt;&lt; Case++ &lt;&lt; ": " &lt;&lt; -1 &lt;&lt; endl; else cout &lt;&lt; "Case " &lt;&lt; Case++ &lt;&lt; ": " &lt;&lt; cnt &lt;&lt; endl; &#125;&#125; 第二道题Fire! 其实吧，这道题刚出来的时候，我在想，因为两个BFS嘛，会不会用到并发编程,(原谅我的天真烂漫)，后面是直接用两个BFS分开放，用一个二维数组来记录火蔓延的时间，然后再用一个BFS来记录其的走向位置，。 本质上，还是属于一个bfs的模板题目。 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;queue&gt;#include&lt;cstring&gt;using namespace std;#define inf 0x3f3f3f3fstruct point &#123; int x,y,step; point() &#123;&#125; point (int a,int b,int c) : x(a),y(b), step(c) &#123;&#125; point move(int i) &#123; point tmp(x, y, step); switch (i) &#123; case 0: &#123; tmp.x = x + 1; break; &#125; case 1: &#123; tmp.x = x - 1; break; &#125; case 2: &#123; tmp.y = y + 1; break; &#125; case 3: &#123; tmp.y = y - 1; break; &#125; &#125; tmp.step++; return tmp; &#125;&#125;;const int maxn = 1010;int m,n;char map[maxn][maxn];bool vis[maxn][maxn];int _time[maxn][maxn];queue&lt;point&gt; q_fire;queue&lt;point&gt; q_joe;void bfs_fire() &#123; point now, next; while (!q_fire.empty()) &#123; now = q_fire.front(); q_fire.pop(); for (int i = 0; i &lt; 4 ; i++) &#123; next = now.move(i); if (next.x &gt;= 0 &amp;&amp; next.y &gt;= 0 &amp;&amp; next.x &lt; m &amp;&amp; next.y &lt; n &amp;&amp; _time[next.x][next.y] &gt; next.step &amp;&amp; (map[next.x][next.y] == '.' || map[next.x][next.y] == 'J')) &#123; q_fire.push(next); _time[next.x][next.y] = next.step; &#125; &#125; &#125;&#125;bool is_ok(int x,int y) &#123; return (x == 0 || y == 0 || x == m - 1 || y == n - 1);&#125;int bfs_joe() &#123; point now,next; while (!q_joe.empty()) &#123; now = q_joe.front(); q_joe.pop(); if (is_ok(now.x,now.y)) return now.step + 1; for (int i = 0; i &lt; 4; i ++) &#123; next = now.move(i); if (next.x &gt;= 0 &amp;&amp; next.y &gt;= 0 &amp;&amp; next.x &lt; m &amp;&amp; next.y &lt; n &amp;&amp; !vis[next.x][next.y] &amp;&amp; map[next.x][next.y] == '.' &amp;&amp; next.step &lt; _time[next.x][next.y])&#123; q_joe.push(next); vis[next.x][next.y] = true; &#125; &#125; &#125; return 0;&#125;void clear()&#123; memset(vis, false, sizeof(vis)); while (!q_fire.empty()) q_fire.pop(); while (!q_joe.empty()) q_joe.pop();&#125;int main()&#123; int T; cin &gt;&gt; T; while (T--) &#123; clear(); cin &gt;&gt; m &gt;&gt; n; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; cin &gt;&gt; map[i][j]; _time[i][j] = inf; if (map[i][j] == 'J') &#123; q_joe.push(point (i,j,0)); vis[i][j] = true; &#125; else if (map[i][j] == 'F') &#123; q_fire.push(point(i,j,0)); &#125; &#125; getchar(); &#125; bfs_fire(); int t = bfs_joe(); if (t) cout &lt;&lt; t &lt;&lt; endl; else cout &lt;&lt; "IMPOSSIBLE" &lt;&lt; endl; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[质数筛选问题]]></title>
    <url>%2F2019%2F03%2F05%2F%E8%B4%A8%E6%95%B0%E7%AD%9B%E9%80%89%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[关于质数的筛选问题，就像最先开始学习C语言一样，最先开始都是从1遍历到本身。 后来的优化版本就体现在遍历到本身的 根号下的倍数关系。但是 后来则发现有太多的重复循环次数，这里反而显得不是特别好，所以就出来一种新的筛选方法。 12345678910111213141516//最普通的埃式筛法memset(check, 0, sizeof(check));int tot = 0;for (int i = 2; i &lt;= n; ++i)&#123; if (!check[i]) &#123; prime[tot++] = i; &#125; // 下面其实用乘法和用加法都是一样的，而这里就是乘法的原因就在于，减少了循环次数 // 唯一没有被优化的地方就在于 每一个数字被重复标记了很多次，而后面的欧拉筛就会限制标记次数为一次 for (int j = i * i; j &lt;= n; j *= i) &#123; check[j] = 1; &#125;&#125; 鉴于上面所说的在进行一次优化，则优化体现在了减少重复次数 123456789101112131415161718192021222324252627282930//进阶版的线性筛法//质数数组int prime[MAXN];//判断每一个数 数组int check[MAXL];int tot = 0;memset(check, 0, sizeof(check));for (int i = 2; i &lt; MAXL; ++i)&#123; if (!check[i]) &#123; prime[tot++] = i; &#125; for (int j = 0; j &lt; tot; ++j) &#123; //大致意思就在于 将每一个数的与质数数组里面的数进行相乘，最后得到的结果存在check中去 //需要注意的就是 一旦当前的数能被整除的时候 就立马退出，这样代表每一个数字都会被自己的最小质因数给整除出来。 if (i * prime[j] &gt; MAXL) &#123; break; &#125; check[i * prime[j]] = 1; if (i % prime[j] == 0) &#123; break; &#125; &#125;&#125; 接下来就是区间筛]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>质数筛选</tag>
        <tag>欧拉筛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享几道简单搜索题目]]></title>
    <url>%2F2019%2F03%2F05%2F%E5%88%86%E4%BA%AB%E5%87%A0%E9%81%93%E7%AE%80%E5%8D%95%E6%90%9C%E7%B4%A2%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[不多做分析，其基本上都是一些 dfs 与 bfs上面的简单题目 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/************************************************************************* &gt; File Name: 棋盘问题.cpp &gt; Author: wangshuxiao &gt; Mail: wsx1128@outlook.com &gt; Created Time: Sun 3 Mar 15:05:54 2019 ************************************************************************/#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;string&gt;using namespace std;int n,k;char board [10][10];int total;bool booked[10];int cnt;void dfs(int cur) &#123; if (cnt == k) &#123; total ++; return; &#125; if (cur &gt;= n) return ; for (int j = 0; j &lt; n; j ++) &#123; if (booked[j] == false &amp;&amp; board[cur][j] == '#') &#123; booked[j] = true; cnt ++; dfs(cur + 1); booked[j] = false; cnt --; &#125; &#125; //这种情况是防范 没有在首置位 有满足符合条件的数据 dfs(cur + 1);&#125;int main()&#123; while (cin &gt;&gt; n &gt;&gt; k) &#123; if (n == -1 &amp;&amp; k == -1) break; for (int i = 0; i &lt; n; i ++) &#123; booked[i] = false; for (int j = 0; j &lt; n; j ++) &#123; cin &gt;&gt; board[i][j]; &#125; &#125; total = 0,cnt = 0; dfs(0); cout &lt;&lt; total &lt;&lt; endl; &#125; return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/************************************************************************* &gt; File Name: DungeonMaster.cpp &gt; Author: wangshuxiao &gt; Mail: wsx1128@outlook.com &gt; Created Time: Sun 3 Mar 16:10:18 2019 ************************************************************************/#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;string&gt;#include&lt;queue&gt;using namespace std;const int maxn = 35;int L,C,R;char map[maxn][maxn][maxn];int dis[maxn][maxn][maxn];struct position &#123; int x,y,z; int pos; position () = default; position(int x,int y,int z,int pos) : this.x(x), this.y(y),this.z(z),this.pos(pos) &#123;&#125;; position move (int i);&#125;;position position::move(int i)&#123; position tmp = *this; switch (i) &#123; case 1: tmp.x = x + 1; break; case 2: tmp.x = x - 1; break; case 3: tmp.y = y + 1; break; case 4: tmp.y = y - 1; break; case 5: tmp.z = z + 1; break; case 6: tmp.z = z - 1; break; &#125; return tmp;&#125;void bfs (int i,int j,int k) &#123; position beg (i,j,k,0); queue&lt;position&gt; q; q.push(beg); while (!q.empty()) &#123; position now = q.front(); q.pop(); dis[now.x][now.y][now.z] = now.pos; for (int i = 0; i &lt; 7; i++) &#123; position next = now.move(i); if (next.x &gt;= 0 &amp;&amp; next.x &lt; L &amp;&amp; next.y &gt;= 0 &amp;&amp; next.y &lt; R &amp;&amp; next.z &gt;= 0 &amp;&amp; next.z &lt; C &amp;&amp; dis[next.x][next.y][next.z] == -1 &amp;&amp; map[next.x][next.y][next.z] != '#') &#123; position empt (next.x,next.y,next.z,now.pos + 1); q.push(empt); &#125; &#125; &#125;&#125;int main()&#123; while (cin &gt;&gt; L &gt;&gt; R &gt;&gt; C) &#123; if (L == 0 &amp;&amp; R == 0 &amp;&amp; C == 0) &#123; break; int x1,y1,z1; int x2,y2,z2; for (int i = 0; i != L; i++) &#123; for (int j = 0; j != R; j++) &#123; for (int k = 0; k != C; k++) &#123; cin &gt;&gt; map[i][j][k]; dis[i][j][k] = -1; if (map[i][j][k] == 'S') &#123; x1 = i; y1 = j; z1 = k; &#125; if (map[i][j][k] == 'E') &#123; x2 = i; y2 = j; z2 = k; &#125; &#125; &#125; &#125; bfs(x1, y1, z1); if (dis[x2][y2][z2] == -1) cout &lt;&lt; "Trapped!" &lt;&lt; endl; else &#123; cout &lt;&lt; "Escaped in " &lt;&lt; dis[x2][y2][z2] &lt;&lt; " minute(s)." &lt;&lt; endl; &#125; return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;string&gt;using namespace std;int m,n;const int maxn = 105;char map [maxn][maxn];int cnt;void dfs(int i,int j) &#123; if (i &lt; 0 &amp;&amp; i &gt;= m) return; if (j &lt; 0 &amp;&amp; j &gt;= n) return; if (map[i][j] == '@') &#123; map[i][j] = '.'; dfs(i-1,j); dfs(i+1,j); dfs(i,j-1); dfs(i,j+1); dfs(i-1,j-1); dfs(i-1,j+1); dfs(i+1,j-1); dfs(i+1,j+1); &#125;&#125;int main() &#123; while (cin &gt;&gt; m &amp;&amp; m != 0 &amp;&amp; cin &gt;&gt; n) &#123; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) cin &gt;&gt; map[i][j]; &#125; for (int i = 0; i &lt; m; i ++) &#123; for (int j = 0; j &lt; n ; j++) &#123; if (map[i][j] == '@')&#123; dfs(i,j); cnt++; &#125; &#125; &#125; cout &lt;&lt; cnt &lt;&lt; endl; cnt = 0; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117#include &lt;vector&gt;#include &lt;queue&gt;#include &lt;stdio.h&gt;#include &lt;cstring&gt;using namespace std;int n, m;char map[201][201];int dis_Y[201][201];int dis_M[201][201];struct point&#123; int x, y, pos; point()&#123;&#125;; point(int a, int b, int c) : x(a), y(b), pos(c) &#123;&#125;&#125;;int _move[4][2] = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;;void bfs(queue&lt;point&gt; *q, int x, int y, bool flag)&#123; point beg(x, y, 0); q-&gt;push(beg); point now, next; while (!q-&gt;empty()) &#123; now = q-&gt;front(); q-&gt;pop(); for (int i = 0; i &lt; 4; i++) &#123; next.x = now.x + _move[i][0]; next.y = now.y + _move[i][1]; if ( next.x &lt; n &amp;&amp; next.x &gt;= 0 &amp;&amp; next.y &lt; m &amp;&amp; next.y &gt;= 0 &amp;&amp; map[next.x][next.y] != '#') &#123; if (flag) &#123; if (dis_Y[next.x][next.y] == -1) &#123; next.pos = now.pos + 1; q -&gt; push(next); dis_Y[now.x][now.y] = now.pos + 1; &#125; &#125; else &#123; if (dis_M[next.x][next.y] == -1) &#123; next.pos = now.pos + 1; q -&gt; push(next); dis_M[now.x][now.y] = now.pos + 1; &#125; &#125; &#125; &#125; &#125;&#125;int main()&#123; int yi_x, yi_y; int m_x, m_y; while (~scanf("%d %d", &amp;n, &amp;m)) &#123; pair&lt;int,int&gt; p; getchar(); vector&lt;pair&lt;int,int&gt; &gt;v; queue&lt;point&gt; qm; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; scanf("%c", &amp;map[i][j]); dis_M[i][j] = -1; dis_Y[i][j] = -1; if (map[i][j] == 'Y') &#123; yi_x = i; yi_y = j; &#125; else if (map[i][j] == 'M') &#123; m_x = i; m_y = j; &#125; else if (map[i][j] == '@') &#123; v.push_back(make_pair(i,j)); &#125; &#125; getchar(); &#125; dis_Y[yi_x][yi_y] = 0; dis_M[m_x][m_y] = 0; bfs(&amp;qm, yi_x, yi_y, true); bfs(&amp;qm, m_x, m_y, false); int Min = 9999999; int tmp = 0; for (auto it = v.begin(); it != v.end(); it++) &#123; tmp = dis_M[it-&gt;first][it-&gt;second] + dis_Y[it-&gt;first][it-&gt;second]; if (Min &gt; tmp) Min = tmp; &#125; printf("%d\n", Min * 11); &#125; return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;string&gt;#include&lt;queue&gt;#include &lt;stack&gt;#include&lt;utility&gt;using namespace std;const int maxn = 6;int map [maxn][maxn];struct point&#123; int x , y , pos; pair&lt;int ,int &gt; p; point()&#123;&#125;; point(int a,int b,int c) : x(a),y(b),pos(c) &#123;&#125; point move(int i) &#123; point tmp = *this; switch (i) &#123; case 0: &#123; tmp.x += 1; break; &#125; case 1: &#123; tmp.x -= 1; break; &#125; case 2: &#123; tmp.y += 1; break; &#125; case 3: &#123; tmp.y -= 1; break; &#125; &#125; return tmp; &#125;&#125;;int main()&#123; point m[maxn][maxn]; for (int i = 0; i &lt; 5; i++) &#123; for (int j = 0 ; j &lt; 5; j++) &#123; cin &gt;&gt; map[i][j]; m[i][j].x = i; m[i][j].y = j; m[i][j].pos = -1; &#125; &#125; queue&lt;point&gt;q; point beg(0,0,0); q.push(beg); while (!q.empty()) &#123; point now = q.front(); q.pop(); //m[now.x][now.y].pos = now.pos; for (int i = 0; i &lt; 4; i++) &#123; point next = now.move(i); if (next.x &lt; 5 &amp;&amp; next.x &gt;= 0 &amp;&amp; next.y &lt; 5 &amp;&amp; next.y &gt;= 0 &amp;&amp; map[next.x][next.y] != 1 &amp;&amp; m[next.x][next.y].pos == -1) &#123; m[next.x][next.y].pos = now.pos+1; m[next.x][next.y].p = make_pair(now.x,now.y); q.push(m[next.x][next.y]); &#125; &#125; &#125; stack&lt;pair&lt;int ,int&gt; &gt; s; s.push(make_pair(4,4)); pair&lt;int,int&gt;x = m[4][4].p; int y = m[4][4].pos; while (y --) &#123; s.push(x); x = m[x.first][x.second].p; &#125; while (!s.empty()) &#123; x = s.top(); s.pop(); cout &lt;&lt; "(" &lt;&lt; x.first &lt;&lt; ", " &lt;&lt; x.second &lt;&lt; ")" &lt;&lt; endl; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>bfs</tag>
        <tag>dfs</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8_pazzle]]></title>
    <url>%2F2019%2F02%2F26%2F8-pazzle%2F</url>
    <content type="text"><![CDATA[此为第四周普林斯顿算法课大作业，基本思路是基于优先队列的A*算法。所谓A*算法，就是启发式算法，人工智能基础，就是将每一步周围的一步之类的情况全部存储起来，然后放进优先队列里面进行比较，然后依次出队，算出最终的结果相当于一个小博弈。 首先，先看题目。 直接贴出代码 Board.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148package Programming_Assignment_4;import edu.princeton.cs.algs4.StdRandom;import java.util.ArrayList;public class Board &#123; private int [][] blocks; private final int dimension; public Board(int[][] blocks) &#123; if (blocks == null) throw new NullPointerException("Null blocks"); dimension = blocks.length; this.blocks = new int[dimension][dimension]; for (int i = 0; i &lt; dimension; i++) &#123; this.blocks[i] = blocks[i].clone(); &#125; &#125; public int dimension() &#123; return dimension; &#125; public int hamming() &#123; int cnt = 0; for (int i = 0; i &lt; dimension; i++) &#123; for (int j = 0; j &lt; dimension; j++) &#123; if (blocks[i][j] == 0) continue; if (blocks[i][j] != i * dimension + j + 1) cnt ++; &#125; &#125; return cnt; &#125; public int manhattan() &#123; int cnt = 0; for (int i = 0; i &lt; dimension; i++) &#123; for (int j = 0; j &lt; dimension; j++) &#123; if (blocks[i][j] == 0) continue; if (blocks[i][j] != i * dimension + j + 1) &#123; int val = blocks[i][j]; int row = (val - 1) / dimension; int col = (val - 1) % dimension; int dif = Math.abs(row - i) + Math.abs(col - j); cnt += dif; &#125; &#125; &#125; return cnt; &#125; public boolean isGoal() &#123; return hamming() == 0; &#125; private void swap (int i1,int r1,int i2,int r2) &#123; int tmp = blocks[i1][r1]; blocks[i1][r1] = blocks[i2][r2]; blocks[i2][r2] = tmp; &#125; public Board twin() &#123; Board twinBoard = new Board(blocks); int row = 0,col = 0; if (blocks[row][col] == 0) col++; for (int i = 0; i &lt; dimension; i++) &#123; for (int j = 0; j &lt; dimension; j++) &#123; if (blocks[i][j] != 0 &amp;&amp; blocks[i][j] != blocks[row][col]) &#123; twinBoard.swap(i,j,row,col); return twinBoard; &#125; &#125; &#125; return twinBoard; &#125; public boolean equals(Object y) &#123; if (y == null) return false; if (y.getClass().isInstance(this)) &#123; Board tmp = (Board) y; if (tmp.dimension != this.dimension) return false; for (int i = 0; i &lt; dimension; i++) &#123; for (int j = 0; j &lt; dimension; j++) &#123; if (tmp.blocks[i][j] != this.blocks[i][j]) return false; &#125; &#125; return true; &#125; return false; &#125; public Iterable&lt;Board&gt; neighbors() &#123; ArrayList&lt;Board&gt; neighbors = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; dimension; i++) &#123; for (int j = 0; j &lt; dimension; j++) &#123; if (blocks[i][j] == 0) &#123; if (i &gt; 0) &#123; Board tmpUp = new Board(blocks); tmpUp.swap(i,j,i - 1,j); neighbors.add(tmpUp); &#125; if (i &lt; dimension - 1) &#123; Board tmpDown = new Board(blocks); tmpDown.swap(i,j,i + 1,j); neighbors.add(tmpDown); &#125; if (j &gt; 0) &#123; Board tmpLeft = new Board(blocks); tmpLeft.swap(i,j,i,j - 1); neighbors.add(tmpLeft); &#125; if (j &lt; dimension - 1) &#123; Board tmpRight = new Board(blocks); tmpRight.swap(i,j,i,j + 1); neighbors.add(tmpRight); &#125; break; &#125; &#125; &#125; return neighbors; &#125; public String toString() &#123; StringBuilder sb = new StringBuilder(); sb.append(dimension + "\n"); for (int row = 0; row &lt; dimension; row++) &#123; for (int col = 0; col &lt; dimension; col++) &#123; sb.append(String.format("%2d ", blocks[row][col])); &#125; sb.append("\n"); &#125; return sb.toString(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package Programming_Assignment_4;import edu.princeton.cs.algs4.In;import edu.princeton.cs.algs4.MinPQ;import edu.princeton.cs.algs4.Stack;import edu.princeton.cs.algs4.StdOut;public class Solver &#123; private BoardNode current; private BoardNode twinCurrent; private class BoardNode implements Comparable&lt;BoardNode&gt; &#123; private Board item; private int priority; private int move; private BoardNode preBoard; public BoardNode (Board item,BoardNode preBoard) &#123; this.item = item; this.preBoard = preBoard; if (preBoard == null) this.move = 0; else this.move = preBoard.move + 1; this.priority = this.move + item.manhattan(); &#125; public int compareTo(BoardNode b) &#123; return Integer.compare(this.priority,b.priority); &#125; &#125; private void putNeighbors (BoardNode current,MinPQ&lt;BoardNode&gt;pq) &#123; Iterable&lt;Board&gt; neighbors = current.item.neighbors(); for (Board it : neighbors) &#123; if (current.preBoard == null || !it.equals(current.preBoard.item)) &#123; pq.insert(new BoardNode(it,current)); &#125; &#125; &#125; public Solver(Board initial) &#123; if (initial == null) &#123; throw new IllegalArgumentException("Constructor argument Board is null!"); &#125; current = new BoardNode(initial,null); twinCurrent = new BoardNode(initial.twin(),null); MinPQ&lt;BoardNode&gt; pq = new MinPQ&lt;BoardNode&gt;(); MinPQ&lt;BoardNode&gt; twinpq = new MinPQ&lt;BoardNode&gt;(); pq.insert(current); twinpq.insert(twinCurrent); while (true) &#123; current = pq.delMin(); if (current.item.isGoal()) break; putNeighbors(current,pq); twinCurrent = twinpq.delMin(); if (twinCurrent.item.isGoal()) break; putNeighbors(twinCurrent,twinpq); &#125; &#125; public boolean isSolvable() &#123; return current.item.isGoal(); &#125; public int moves() &#123; if (current.item.isGoal()) return current.move; return -1; &#125; public Iterable&lt;Board&gt; solution() &#123; if (isSolvable()) &#123; Stack&lt;Board&gt; stack = new Stack&lt;&gt;(); BoardNode node = current; while (node != null) &#123; stack.push(node.item); node = node.preBoard; &#125; return stack; &#125; return null; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
        <tag>A*算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于java的碰撞物理引擎]]></title>
    <url>%2F2019%2F02%2F26%2F%E5%9F%BA%E4%BA%8Ejava%E7%9A%84%E7%A2%B0%E6%92%9E%E7%89%A9%E7%90%86%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[首先，贴出效果图，基于java的物理引擎。 完成这个效果需要考虑几件事情。 第一步显示定义出每一个颗粒，具体的形状，颜色，位置，速度…具体API如下： 其实这里最关键的是上面的预测碰撞时间的算法，应用了大学物理的相关知识。将三种碰撞的预测时间算出来，另外并依次赋予三种碰撞的效果。然后将其放入一个可比较的事件中，通过遍历每一个球与其他球预测碰撞情况，放入优先队列中再依次处理。 第一种 两球相撞1234567891011121314151617181920212223242526272829303132333435363738//时间//注意下面几个地方的剪枝public double timeToHitBall (Ball that) &#123; if (this == that) return INFINITY; double dx = that.pos_x - this.pos_x; double dy = that.pos_y - this.pos_y; double dvx = that.vec_x - this.vec_x; double dvy = that.vec_y - this.vec_y; double dvdr = dx * dvx + dy * dvy; if (dvdr &gt; 0) return INFINITY; double dvdv = dvx * dvx + dvy * dvy; if (dvdv == 0) return INFINITY; double drdr = dx * dx + dy * dy; double sigma = this.radius + that.radius; double d = (dvdr * dvdr) - dvdv * (drdr - sigma * sigma); if (d &lt; 0) return INFINITY; return -(dvdr + Math.sqrt(d)) / dvdv; &#125;//碰撞后的效果public void bounceOff (Ball that) &#123; double dx = that.pos_x - this.pos_x; double dy = that.pos_y - this.pos_y; double dvx = that.vec_x - this.vec_x; double dvy = that.vec_y - this.vec_y; double dvdr = dx * dvx + dy * dvy; double dist = this.radius + that.radius; double J = 2 * this.mass * that.mass * dvdr / ((this.mass + that.mass) * dist); double Jx = J * dx / dist; double Jy = J * dy / dist; this.vec_x += Jx / this.mass; this.vec_y += Jy / this.mass; that.vec_x -= Jx / that.mass; that.vec_y -= Jy / that.mass; this.cnt ++; that.cnt ++; &#125; 第二种与墙体发生碰撞12345678910111213141516171819202122232425//碰撞垂直墙的时间public double timeToHitVerticalWall() &#123; if (vec_x &gt; 0) return (border - pos_x - radius) / vec_x; else if (vec_x &lt; 0) return (radius - pos_x) / vec_x; else return INFINITY;&#125;//碰撞水平墙的时间public double timeToHitHorizontalWall() &#123; if (vec_y &gt; 0) return (border - pos_y - radius) / vec_y; else if (vec_y &lt; 0) return (radius - pos_y) / vec_y; return INFINITY;&#125;//碰撞效果public void bounceOffVerticalWall () &#123; this.cnt ++; this.vec_x = - this.vec_x;&#125;public void bounceoffHorizontalWall () &#123; this.cnt ++; this.vec_y = - this.vec_y;&#125; 以下便是第一个球体类型的完整代码Ball.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121import edu.princeton.cs.algs4.StdDraw;import edu.princeton.cs.algs4.StdRandom;import java.awt.*;public class Ball &#123; //球的横纵坐标 private double pos_x; private double pos_y; //球的横纵方向上面的速度 private double vec_x; private double vec_y; //球的半径 private final double radius; //球的质量 private final double mass; //边界长度 private final double border; //球的颜色 private final Color color; //碰撞次数 private int cnt = 0; //限定一个最大值 private static final double INFINITY = Double.POSITIVE_INFINITY; public Ball () &#123; pos_x = StdRandom.uniform(0.0, 1.0); pos_y = StdRandom.uniform(0.0, 1.0); vec_x = StdRandom.uniform(-0.005, 0.005); vec_y = StdRandom.uniform(-0.005, 0.005); radius = 0.01; mass = 0.5; border = 1; color = Color.BLACK; &#125; public Ball (double px,double py,double vx,double vy,double radius,double mass,double border,Color color) &#123; this.pos_x = px; this.pos_y = py; this.vec_x = vx; this.vec_y = vy; this.radius = radius; this.mass = mass; this.border = border; this.color = color; &#125; public void draw() &#123; StdDraw.filledCircle(pos_x,pos_y,radius); StdDraw.setPenColor(color); &#125; public void move (double dt) &#123; pos_x = pos_x + vec_x * dt; pos_y = pos_y + vec_y * dt; &#125; public double timeToHitBall (Ball that) &#123; if (this == that) return INFINITY; double dx = that.pos_x - this.pos_x; double dy = that.pos_y - this.pos_y; double dvx = that.vec_x - this.vec_x; double dvy = that.vec_y - this.vec_y; double dvdr = dx * dvx + dy * dvy; if (dvdr &gt; 0) return INFINITY; double dvdv = dvx * dvx + dvy * dvy; if (dvdv == 0) return INFINITY; double drdr = dx * dx + dy * dy; double sigma = this.radius + that.radius; double d = (dvdr * dvdr) - dvdv * (drdr - sigma * sigma); if (d &lt; 0) return INFINITY; return -(dvdr + Math.sqrt(d)) / dvdv; &#125; public double timeToHitVerticalWall() &#123; if (vec_x &gt; 0) return (border - pos_x - radius) / vec_x; else if (vec_x &lt; 0) return (radius - pos_x) / vec_x; else return INFINITY; &#125; public double timeToHitHorizontalWall() &#123; if (vec_y &gt; 0) return (border - pos_y - radius) / vec_y; else if (vec_y &lt; 0) return (radius - pos_y) / vec_y; return INFINITY; &#125; public void bounceOff (Ball that) &#123; double dx = that.pos_x - this.pos_x; double dy = that.pos_y - this.pos_y; double dvx = that.vec_x - this.vec_x; double dvy = that.vec_y - this.vec_y; double dvdr = dx * dvx + dy * dvy; double dist = this.radius + that.radius; double J = 2 * this.mass * that.mass * dvdr / ((this.mass + that.mass) * dist); double Jx = J * dx / dist; double Jy = J * dy / dist; this.vec_x += Jx / this.mass; this.vec_y += Jy / this.mass; that.vec_x -= Jx / that.mass; that.vec_y -= Jy / that.mass; this.cnt ++; that.cnt ++; &#125; public int count() &#123; return cnt; &#125; public void bounceOffVerticalWall () &#123; this.cnt ++; this.vec_x = - this.vec_x; &#125; public void bounceoffHorizontalWall () &#123; this.cnt ++; this.vec_y = - this.vec_y; &#125;&#125; 其次，我们需要对以上球体类进行一个包装，将其赋予可比较的特性。因为从宏观上来看，我们需要比较的是每一个球体的碰撞情况，所以，用一个事件包含其诸多特性 12345678910111213141516171819202122232425262728private static class Collison_Event implements Comparable&lt;Collison_Event&gt;&#123; private final Ball a,b; private final double time; private final int countA,countB; public Collison_Event (Ball a,Ball b,double time) &#123; this.time = time; this.a = a; this.b = b; if (a != null) countA = a.count(); else countA = -1; if (b != null) countB = b.count(); else countB = -1; &#125; public int compareTo(Collison_Event that) &#123; return Double.compare(this.time,that.time); &#125; public boolean isValid () &#123; if (this.time == Double.POSITIVE_INFINITY) return false; else &#123; if (a != null &amp;&amp; a.count() != countA) return false; if (b != null &amp;&amp; b.count() != countB) return false; return true; &#125; &#125; &#125; 最后就是整个包含类，就称为一个系统思路就是预测碰撞的时间，放入优先队列中，另外，需要注意的核心的一点就是，其采用了时间限制，大于某个时间的球体碰撞即不放进队列中，避免开销。还有，不要忘记重绘的条件，在这里加入一个HZ变量控制帧数。 以下是第二个类的全部代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121import edu.princeton.cs.algs4.MinPQ;import edu.princeton.cs.algs4.StdDraw;import java.awt.Color;public class CollisionSystem &#123; protected MinPQ&lt;Collison_Event&gt; pq; //相当于一个总控时间的一个参数，后面所有关于时间的参数都需要加上一个这个 protected double t = 0.0; protected Ball[] balls; //这里就相当于一个控制每一帧数的频率控制 private static final double HZ = 0.5; public CollisionSystem(Ball[] balls) &#123; this.balls = balls.clone(); &#125; //这里新加上的一个参数 limit 是控制一些完全没必要的事件 //意思就是剔除那些需要太长时间才会相撞的球体 protected void pridict (Ball b,double limit) &#123; if (b == null) return; for (int i = 0;i &lt; balls.length;i++)&#123; double dt = b.timeToHitBall(balls[i]); if (t + dt &lt;= limit) pq.insert(new Collison_Event(b,balls[i],dt + t)); &#125; double dxt = b.timeToHitHorizontalWall() + t; double dyt = b.timeToHitVerticalWall() + t; if (dxt &lt;= limit) pq.insert(new Collison_Event(b,null,dxt)); if (dyt &lt;= limit) pq.insert(new Collison_Event(null,b,dyt)); &#125; protected void redrew(double limit) &#123; StdDraw.clear(); for (int i = 0;i &lt; balls.length;i++) &#123; balls[i].draw(); &#125; StdDraw.show(); StdDraw.pause(20); if (t &lt; limit) &#123; pq.insert(new Collison_Event(null,null,t + 1.0 / HZ)); &#125; &#125; protected void simulate (double limit) &#123; pq = new MinPQ&lt;Collison_Event&gt;(); for (int i = 0; i &lt; balls.length; i++) &#123; pridict(balls[i],limit); &#125; pq.insert(new Collison_Event(null,null,0)); while (!pq.isEmpty()) &#123; Collison_Event event = pq.delMin(); if (!event.isValid()) continue; //将其他的点全部移动 for (int i = 0; i &lt; balls.length; i++) &#123; balls[i].move(event.time - t); &#125; t = event.time; if (event.a != null &amp;&amp; event.b != null) event.a.bounceOff(event.b); else if (event.a == null &amp;&amp; event.b != null) event.b.bounceOffVerticalWall(); else if (event.a != null &amp;&amp; event.b == null) event.a.bounceoffHorizontalWall(); else if (event.a == null &amp;&amp; event.b == null) redrew(limit); pridict(event.a,limit); pridict(event.b,limit); &#125; &#125; private static class Collison_Event implements Comparable&lt;Collison_Event&gt;&#123; private final Ball a,b; private final double time; private final int countA,countB; public Collison_Event (Ball a,Ball b,double time) &#123; this.time = time; this.a = a; this.b = b; if (a != null) countA = a.count(); else countA = -1; if (b != null) countB = b.count(); else countB = -1; &#125; public int compareTo(Collison_Event that) &#123; return Double.compare(this.time,that.time); &#125; public boolean isValid () &#123; if (this.time == Double.POSITIVE_INFINITY) return false; else &#123; if (a != null &amp;&amp; a.count() != countA) return false; if (b != null &amp;&amp; b.count() != countB) return false; return true; &#125; &#125; &#125; public static void main(String [] args)&#123; StdDraw.setCanvasSize(600,600); //这个是清楚缓冲 帮助改善运动的 StdDraw.enableDoubleBuffering(); Ball[] balls = new Ball[100]; for (int i = 0;i &lt; 100; i++) &#123; balls[i] = new Ball(); &#125; CollisionSystem system = new CollisionSystem(balls); system.simulate(100000); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>物理引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[普林斯顿算法课第四周小作业]]></title>
    <url>%2F2019%2F02%2F24%2F%E6%99%AE%E6%9E%97%E6%96%AF%E9%A1%BF%E7%AE%97%E6%B3%95%E8%AF%BE%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%B0%8F%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[第四周的小作业主要围绕优先队列以及基于优先队列的Taxicabnumber。先贴出关于优先队列的代码MaxPQ.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149package Interview_Question_Week4.PQ;import edu.princeton.cs.algs4.StdIn;import edu.princeton.cs.algs4.StdOut;import java.util.Comparator;import java.util.Iterator;import java.util.NoSuchElementException;public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; implements Iterable&lt;Key&gt; &#123; protected Key[] key; protected int len; private Comparator&lt;Key&gt; comparator; public MaxPQ(int init)&#123; key = (Key[]) new Object[1 + init]; len = 0 + init; &#125; public MaxPQ (int init , Comparator&lt;Key&gt; rule)&#123; comparator = rule; key = (Key[]) new Object[1 + init]; len = 0 + init; &#125; private boolean less(int i,int j)&#123; if (comparator == null)&#123; return key[i].compareTo(key[j]) &lt; 0; &#125; return comparator.compare(key[i],key[j]) &lt; 0; &#125; protected void change(int i,int j) &#123; Key temp = key[i]; key[i] = key[j]; key[j] = temp; &#125; protected void sink(int k)&#123; while (k * 2 &lt;= len) &#123; int j = k * 2; if (j &lt; len &amp;&amp; less(j,j+1)) j++; if (!less(k,j)) break; change(k,j); k = j; &#125; &#125; protected void up(int k)&#123; while (k &gt; 1 &amp;&amp; less(k / 2,k)) &#123; change(k, k / 2); k = k / 2; &#125; &#125; private void resize(int n) &#123; Key[] temp = (Key[]) new Object[n]; for (int i = 1; i &lt;= len;i++) &#123; temp[i] = key[i]; &#125; key = temp; &#125; public boolean isEmpty()&#123; return len == 0; &#125; public Key get(int n) &#123; return key[n]; &#125; public int size() &#123; return len; &#125; public void insert(Key item) &#123; if (item == null) throw new IllegalArgumentException("wrong"); if (len + 1 == key.length) resize(2 * key.length); key[++len] = item; up(len); assert isMaxHeap(1); &#125; // 这里是帮助后面完成一个assert判断而存在的 private boolean isMaxHeap(int k) &#123; if (k &gt; len) return true; int left = 2*k; int right = 2*k + 1; if (left &lt;= len &amp;&amp; less(k, left)) return false; if (right &lt;= len &amp;&amp; less(k, right)) return false; return isMaxHeap(left) &amp;&amp; isMaxHeap(right); &#125; public Key delMax() &#123; if (isEmpty()) throw new NoSuchElementException(); Key item = key[1]; key[1] = null; change(1,len--); sink(1); if (len + 1 &lt;= key.length / 4 &amp;&amp; len &gt; 0 ) resize(key.length / 2); assert isMaxHeap(1); return item; &#125; public Iterator&lt;Key&gt; iterator ()&#123; return new heapIterator(); &#125; private class heapIterator implements Iterator&lt;Key&gt;&#123; private MaxPQ&lt;Key&gt; copy; public heapIterator() &#123; if (comparator == null) &#123; copy = new MaxPQ&lt;Key&gt;(len); &#125; else copy = new MaxPQ&lt;Key&gt;(len,comparator); for (int i = 0;i &lt; len;i++)&#123; copy.insert(key[i]); &#125; &#125; public boolean hasNext() &#123; if (!isEmpty()) return true; return false; &#125; public Key next() &#123; if (!hasNext()) throw new NoSuchElementException(); return copy.delMax(); &#125; @Override public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; public static void main(String[] args) &#123; edu.princeton.cs.algs4.MaxPQ&lt;String&gt; pq = new edu.princeton.cs.algs4.MaxPQ&lt;String&gt;(); while (!StdIn.isEmpty()) &#123; String item = StdIn.readString(); if (!item.equals("-")) pq.insert(item); else if (!pq.isEmpty()) StdOut.print(pq.delMax() + " "); &#125; StdOut.println("(" + pq.size() + " left on pq)"); &#125;&#125; 随机优先队列 RandomPQ.java 12345678910111213141516171819202122232425262728package Interview_Question_Week4;import Interview_Question_Week4.PQ.MaxPQ;import edu.princeton.cs.algs4.StdRandom;public class RandomPQ&lt;Key extends Comparable&lt;Key&gt;&gt; extends MaxPQ &#123; private int len; public RandomPQ (int n) &#123; super(n); this.len = super.len; &#125; public Comparable&lt;Key&gt; sample() &#123; int n = StdRandom.uniform(len + 1); return super.get(n); &#125; public Comparable&lt;Key&gt; randomRemove () &#123; int n = StdRandom.uniform(len + 1); Comparable&lt;Key&gt; item = key[n]; change(n,len--); key[len + 1] = null; sink(n); return item; &#125;&#125; 优先队列的一些应用PriorityQueue.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class PriorityQueue &#123; private MaxPQ&lt;Integer&gt; left; private MinPQ&lt;Integer&gt; right; public PriorityQueue() &#123; left = new MaxPQ&lt;Integer&gt;(); right = new MinPQ&lt;Integer&gt;(); &#125; public double findMedian() &#123; int L = left.size(); int R = right.size(); if (L == R) return (left.max() + right.min()) / 2; else if (L &gt; R) return left.max(); else return right.min(); &#125; public void insert(int key) &#123; double median = findMedian(); int L = left.size(); int R = right.size(); if (key &lt;= median) &#123; left.insert(key); if (L - R &gt; 1) &#123; right.insert(left.delMax()); &#125; &#125; else &#123; right.insert(key); if (R - L &gt; 1) &#123; left.insert(right.delMin()); &#125; &#125; &#125; public void removeMedian() &#123; int L = left.size(); int R = right.size(); if (L &gt; R) &#123; left.delMax(); &#125; else &#123; right.delMin(); &#125; &#125;&#125; 有四个数 a,b,c,d 满足 a^3 + b^3 = c^3 +d^3，然后再给一个数 n，求出 n之内所有满足上述等式的四个数 思路此处就是运用优先队列，将没两个数的立方和加起来，然后再以立方和的大小来进行排序，作为最后排序的标准，最后进行比较，可做优化。 代码如下： Taxicab 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package Interview_Question_Week4;import edu.princeton.cs.algs4.MinPQ;import edu.princeton.cs.algs4.StdOut;public class Taxicab implements Comparable&lt;Taxicab&gt; &#123; private final int a; private final int b; private final int cube; public Taxicab(int x,int y) &#123; this.a = x; this.b = y; this.cube = x * x * x + y * y * y; &#125; @Override public int compareTo(Taxicab a) &#123; if (this.cube &lt; a.cube) return -1; if (this.cube &gt; a.cube) return 1; if (this.a &lt; a.a) return -1; if (this.a &gt; a.a) return 1; return 0; &#125; @Override public String toString() &#123; return "number: " + cube + " (" + a + ", " + b + ")"; &#125; public void findTaxicabNumber(int N) &#123; MinPQ&lt;Taxicab&gt; candidate = new MinPQ&lt;Taxicab&gt;(); for (int i = 1;i &lt;= N;i++) &#123; candidate.insert(new Taxicab(i,i)); &#125; int cnt = 1; Taxicab pre = new Taxicab(0,0); while (!candidate.isEmpty()) &#123; Taxicab curr = candidate.delMin(); if (curr == pre) &#123; cnt ++; if (cnt == 2) &#123; StdOut.print(pre.cube + "=" + pre); &#125; StdOut.print(" = " + curr); &#125; else &#123; if (cnt &gt; 1) StdOut.println(); cnt = 1; &#125; pre = curr; if (curr.a &lt; N) candidate.insert(new Taxicab(curr.a,curr.b + 1)); &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CollinearPoint]]></title>
    <url>%2F2019%2F02%2F24%2FCollinearPoint%2F</url>
    <content type="text"><![CDATA[CollinearPoint——-普林斯顿第三周大作业第三周的大作业 有点意思，基于排序的一次简单优化，先看题目。 一步一步来，根据题目首先写出一个点的类，这个类要包含比较，并且，要包含求出两个类之间斜率的方法。Point.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package Programming_Assignment_3;import edu.princeton.cs.algs4.StdDraw;import edu.princeton.cs.algs4.StdRandom;import java.util.Arrays;import java.util.Comparator;public class Point implements Comparable&lt;Point&gt; &#123; private final int x; private final int y; public Point(int x, int y) &#123; this.x = x; this.y = y; &#125; public void draw() &#123; StdDraw.point(x,y); &#125; public void drawTo(Point that) &#123; StdDraw.line(x,y,that.x,that.y); &#125; public String toString() &#123; return "(" + x + ", " + y + ")"; &#125; public int compareTo(Point that) &#123; if (y &gt; that.y) return 1; else if (y &lt; that.y) return -1; else if (x &gt; that.x) return 1; else if (x &lt; that.x) return -1; else return 0; &#125; public double slopeTo(Point that) &#123; if (x == that.x) &#123; if (y == that.y) return Double.NEGATIVE_INFINITY; else return Double.POSITIVE_INFINITY; &#125; if (y == that.y) return 0 / 1.0; return (y - that.y) * 1.0 / (x - that.x); &#125; private class SlopeOrder implements Comparator&lt;Point&gt;&#123; public int compare(Point p, Point q) &#123; if (slopeTo(p) &lt; slopeTo(q)) return -1; if (slopeTo(p) &gt; slopeTo(q)) return +1; return 0; &#125; &#125; public Comparator&lt;Point&gt; slopeOrder() &#123; return new SlopeOrder(); &#125; public static void main(String[] args) &#123; int x0 = Integer.parseInt(args[0]); int y0 = Integer.parseInt(args[1]); int n = Integer.parseInt(args[2]); StdDraw.setCanvasSize(800, 800); StdDraw.setXscale(0, 50); StdDraw.setYscale(0, 50); StdDraw.setPenRadius(0.005); StdDraw.enableDoubleBuffering(); Point[] points = new Point[n]; for (int i = 0; i &lt; n; i++) &#123; int x = StdRandom.uniform(50); int y = StdRandom.uniform(50); points[i] = new Point(x, y); points[i].draw(); &#125; // draw p = (x0, x1) in red Point p = new Point(x0, y0); StdDraw.setPenColor(StdDraw.RED); StdDraw.setPenRadius(0.02); p.draw(); // draw line segments from p to each point, one at a time, in polar order StdDraw.setPenRadius(); StdDraw.setPenColor(StdDraw.BLUE); Arrays.sort(points, p.slopeOrder()); for (int i = 0; i &lt; n; i++) &#123; p.drawTo(points[i]); StdDraw.show(); StdDraw.pause(100); &#125; &#125;&#125; 接下来就是直线的类，这两个类都比较简单，这里就直接贴出代码LineSegment.java123456789101112131415161718192021222324package Programming_Assignment_3;public class LineSegment &#123; private final Point a; private final Point b; public LineSegment(Point p, Point q) &#123; if (p == null || q == null) throw new java.lang.IllegalArgumentException(); a = p; b = q; &#125; public void draw() &#123; a.drawTo(b); &#125; public String toString() &#123; return a + " -&gt; " + b; &#125; public int hasCode() &#123; throw new UnsupportedOperationException(); &#125;&#125; 最后就是问题的求解方法。问题 需要知道平面上的点，有哪些点是在一条直线上的，第一种方法，暴力法，直接用四种循环写出答案。 BruteCollinearPoints.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package Programming_Assignment_3;import java.util.ArrayList;import java.util.Arrays;public class BruteCollinearPoints &#123; private Point[] copies; private ArrayList&lt;LineSegment&gt; lineSegments = new ArrayList&lt;LineSegment&gt;(); // finds all line segments containing 4 points public BruteCollinearPoints(final Point[] points) &#123; if (points == null) throw new java.lang.IllegalArgumentException(); copies = new Point[points.length]; for (int i = 0; i &lt; points.length; i++) &#123; copies[i] = points[i]; &#125; // sort by y-coordinate // the endpoints are the first and last points Arrays.sort(copies); // after sort then can check if duplicate for (int i = 0; i &lt; copies.length - 1; i++) if (copies[i].compareTo(copies[i+1]) == 0) throw new java.lang.IllegalArgumentException(); for (int ip = 0; ip &lt; copies.length-3; ip++) &#123; for (int iq = ip + 1; iq &lt; copies.length-2; iq++) &#123; double slopeP2Q = copies[ip].slopeTo(copies[iq]); for (int ir = iq + 1; ir &lt; copies.length-1; ir++) &#123; double slopeQ2R = copies[iq].slopeTo(copies[ir]); if (slopeP2Q != slopeQ2R) continue; for (int is = ir + 1; is &lt; copies.length; is++) &#123; double slopeR2S = copies[ir].slopeTo(copies[is]); // if 3 of 4's slopes are equal then 4 points are colllinear if (slopeP2Q == slopeR2S) lineSegments.add(new LineSegment(copies[ip], copies[is])); &#125; &#125; &#125; &#125; &#125; // the number of line segments public int numberOfSegments() &#123; return lineSegments.size(); &#125; // the line segments public LineSegment[] segments() &#123; LineSegment[] result = new LineSegment[lineSegments.size()]; for (int i = 0; i &lt; lineSegments.size(); i++) &#123; result[i] = lineSegments.get(i); &#125; return result; &#125; 优化的方法就是基于排序，将每一个点都与已经排好序的点集进行比较，按照一定的顺序进行比较可以省略很多。FastCollinearPoints.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package Programming_Assignment_3;import java.util.ArrayList;import java.util.Arrays;public class FastCollinearPoints &#123; private Point[] copies; private ArrayList&lt;LineSegment&gt; lineSegments = new ArrayList&lt;LineSegment&gt;(); // finds all line segments containing 4 or more points public FastCollinearPoints(Point[] points) &#123; if (points == null) throw new java.lang.IllegalArgumentException(); copies = new Point[points.length]; for (int i = 0; i &lt; points.length; i++) &#123; copies[i] = points[i]; &#125; // sort by y-coordinate // the endpoints are the first and last points Arrays.sort(copies); // after sort then can check if duplicate for (int i = 0; i &lt; copies.length - 1; i++) if (copies[i].compareTo(copies[i+1]) == 0) throw new java.lang.IllegalArgumentException(); for (int i = 0; i &lt; copies.length - 1; i++) &#123; Point origin = copies[i]; // Think of p as the origin. double[] slopes = new double[copies.length - 1 - i]; Point[] others = new Point[copies.length - 1 - i]; for (int j = 0; j &lt; copies.length - 1 - i; j++) others[j] = copies[j + 1 + i]; // For each other point q, determine the slope it makes with p for (int j = 0; j &lt; others.length; j++) slopes[j] = origin.slopeTo(others[j]); // Sort the points according to the slopes they makes with p Arrays.sort(others, origin.slopeOrder()); Arrays.sort(slopes); // Check if any 3 (or more) adjacent points in the // sorted order have equal slopes with respect to p // If so, these points, together with p, are collinear for (int cnt_same = 0, j = 0; j &lt; slopes.length - 1; j++) &#123; if (slopes[j] == slopes[j+1]) &#123; cnt_same++; &#125; if (cnt_same &gt;= 2) &#123; lineSegments.add(new LineSegment(origin, others[j + 1])); break; &#125; &#125; &#125; &#125; // the number of line segments public int numberOfSegments() &#123; return lineSegments.size(); &#125; // the line segments public LineSegment[] segments() &#123; LineSegment[] result = new LineSegment[lineSegments.size()]; for (int i = 0; i &lt; lineSegments.size(); i++) &#123; result[i] = lineSegments.get(i); &#125; return result; &#125;&#125; 总结由于暴力做法运算了很多原本不需要的循环，相当于是做了很多重复功，所以不招收待见，而基于优化的版本进行了优化，所以在实际应用中是可取的。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[普林斯顿算法课第三周小作业]]></title>
    <url>%2F2019%2F02%2F24%2F%E6%99%AE%E6%9E%97%E6%96%AF%E9%A1%BF%E7%AE%97%E6%B3%95%E8%AF%BE%E7%AC%AC%E4%B8%89%E5%91%A8%E5%B0%8F%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[第三周主要讲的是归并排序和快速排序，这里在C++里面已经总结过，直接贴出代码。CountInversions 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package Interview_Question_Week3;import java.util.Arrays;public class CountInversions &#123; private Comparable[] aux; private int inversion = 0; private boolean less (Comparable a,Comparable b)&#123; return a.compareTo(b) &lt; 0; &#125; public int get_num(Comparable[] a) &#123; aux = new Comparable[a.length]; sort(a,0,a.length - 1); return inversion; &#125; public void sort(Comparable[] a,int lo,int high)&#123; if (lo &gt;= high) return; int mid = (lo + high) / 2; sort(a,lo,mid); sort(a,mid+1,high); merge(a,lo,mid,high); &#125; public void merge(Comparable[] a,int lo,int mid,int high)&#123; int i = lo; int j = mid + 1; for (int k = lo; k &lt;= high;k++)&#123; aux[k] = a[k]; &#125; for (int k = lo;k &lt;= high;k++)&#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; high) a[k] = aux[i++]; else if (less (aux[i],aux[j]))&#123; // 这一步的目的就在于逆序对的个数，前面有多少个大于自己个数，就有多少个逆序对 inversion += mid + 1 - i; a[k] = aux[i++]; &#125; else a[k] = aux[j++]; &#125; &#125; public static void main(String [] args)&#123; Integer []a = &#123;1,5,3,7,2,8,6,4&#125;; System.out.println(new CountInversions().get_num(a)); System.out.println(Arrays.toString(a)); &#125;&#125; LinkedMergedArrays123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package Interview_Question_Week3;import java.util.Arrays;import java.util.Iterator;import java.util.ListIterator;public class LinkedMergedArrays &lt;T extends Comparable&lt;T&gt;&gt; implements Iterable&lt;T&gt;&#123; private Node first = null; private Node last = null; private int n = 0; private class Node &#123; Node next; T item; &#125; private boolean less (Comparable a,Comparable b) &#123; return a.compareTo(b) &lt; 0; &#125; public Iterator&lt;T&gt; iterator() &#123; return new ListIterator(); &#125; private class ListIterator implements Iterator&lt;T&gt;&#123; private Node current = first; public boolean hasNext() &#123; return current != null; &#125; public T next() &#123; // TODO Auto-generated method stub T t = current.item; current = current.next; return t; &#125; &#125; public void add(T t)&#123; Node node = new Node(); node.item = t; node.next = null; if(first == null &amp;&amp; last == null)&#123; first = node; last = node; &#125;else if(first != null &amp;&amp; first == last)&#123; first.next = node; last = node; &#125;else&#123; last.next = node; last = node; &#125; n++; &#125; public String toString()&#123; Iterator&lt;T&gt; iter = iterator(); String ret = iter.next().toString(); while(iter.hasNext())&#123; ret += ", "+ iter.next().toString() ; &#125; return ret; &#125; //以下代码是第一种方式的归并 还有第二种形式的归并 明天可以写一下。 public void mergeSort()&#123; first = sort(first); &#125; private Node sort(Node head)&#123; if(head == null || head.next == null) return head; Node slow = head; Node fast = head; //取中间节点 while(fast.next != null &amp;&amp; fast.next.next != null)&#123; slow = slow.next; fast = fast.next.next; &#125; Node left = head; Node right = slow.next; slow.next = null; //将左右链表分开 left = sort(left); right = sort(right); return merge(left,right); &#125; private Node merge(Node left, Node right)&#123; //System.out.println("left="+left.element+",right="+right.element); Node aux = new Node(); //需要耗费logn的额外空间 Node l= left; Node r = right; Node current = aux; while(l != null &amp;&amp; r!=null)&#123; if(less(r.item,l.item)) &#123; current.next = r; current = current.next; r = r.next; &#125; else &#123; current.next = l; current = current.next; l= l.next; &#125; &#125; if(l!=null) current.next = l; // 如果左侧没遍历完，将其连接至current后 else if(r != null) current.next = r; //如果右侧没遍历完，将其连接至current后 return aux.next; //返回归并好的链表 &#125;&#125; MergeSortedSubArray 12345678910111213141516171819202122232425262728package Interview_Question_Week3;import edu.princeton.cs.algs4.StdRandom;import java.util.Arrays;public class MergeSortedSubArray &#123; private static boolean less (Comparable a,Comparable b)&#123; return a.compareTo(b) &lt; 0; &#125; public static void merge(Comparable[] array)&#123; int n = array.length / 2; Comparable[] aux = new Comparable[n]; for (int i = 0;i &lt; n;i++)&#123; aux[i] = array[i]; &#125; System.out.println(Arrays.toString(aux)); int l = 0; int r = n; for(int k = 0; k&lt;2*n;k++)&#123; if(l &gt;= n) break;//辅助元素数组全部用完，array右侧不需要挪动位置了 else if(r&gt;=2*n) array[k]=aux[l++];//array原右侧元素全部放置合适位置，后面只需把辅助数组的元素挪到array右侧 else if(less(array[r],aux[l])) array[k] = array[r++]; else array[k] = aux[l++]; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[普林斯顿第二周小作业]]></title>
    <url>%2F2019%2F02%2F24%2F%E6%99%AE%E6%9E%97%E6%96%AF%E9%A1%BF%E7%AC%AC%E4%BA%8C%E5%91%A8%E5%B0%8F%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[第二周是关于队列与栈的相关实现，由于C++里面早就涉及到了，这里并不多说，直接贴代码Elementary_Sorts123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package Interview_Question_Week2.Elementary_Sorts;import edu.princeton.cs.algs4.StdRandom;enum Ball &#123; Red, Blue, White;&#125;public class Backets&#123; private Ball backets[]; private Ball color(int i)&#123; return backets[i]; &#125; private void swap (int i , int j)&#123; Ball tmp = backets[i]; backets[i] = backets[j]; backets[j] = tmp; &#125; public Backets(int n) &#123; backets = new Ball[n]; for (Ball i : backets)&#123; int x = StdRandom.uniform(3); switch (x)&#123; case 0: &#123;i = Ball.Blue;break;&#125; case 1: &#123; i = Ball.Red;break;&#125; case 2: &#123;i = Ball.White;break;&#125; &#125; &#125; &#125; public void sort() &#123; int low = 0; int cur = 0; int high = backets.length - 1; while (cur &lt;= high)&#123; switch (color(cur))&#123; case Red: &#123; if (cur != low) &#123; swap(cur, low); &#125; cur++; low++; break; &#125; case White: &#123; cur++; break; &#125; case Blue: &#123; swap (high,cur); high--; break; &#125; &#125; &#125; &#125; public static void main(String [] args)&#123; &#125;&#125;package Interview_Question_Week2.Elementary_Sorts;import java.awt.Point;import java.util.Arrays;import java.util.HashSet;import java.util.Random;import java.util.Set;public class Intersection_of_two_sets &#123; private Set&lt;Point&gt; same; private int sameTimes; public Intersection_of_two_sets(Point[]a , Point[]b,int times)&#123; same = new HashSet&lt;Point&gt;(); for (int i = 0;i &lt; times;i++)&#123; same.add(a[i]); same.add(b[i]); &#125; sameTimes = times * 2 - same.size(); &#125; public int get()&#123; return sameTimes; &#125; public static void main(String [] args)&#123; int n = 10; Random ra = new Random(); Point[] a = new Point[10]; Point[] b = new Point[10]; for (int i = 0;i &lt; n;i++)&#123; a[i] = new Point(); b[i] = new Point(); a[i].setLocation(ra.nextInt(10)+1,ra.nextInt(10)+1); b[i].setLocation(ra.nextInt(10)+1,ra.nextInt(10)+1); &#125; Intersection_of_two_sets i = new Intersection_of_two_sets(a,b,n); System.out.println(Arrays.toString(a)); System.out.println(Arrays.toString(b)); System.out.println(i.same); System.out.println(i.get()); &#125;&#125; MaxArrayStack1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package Interview_Question_Week2;import java.util.*;public class MaxArrayStack &#123; private int Max; private int sz; private int []a; public MaxArrayStack()&#123; Max = -999999999; a = new int [1]; sz = 0; &#125; public void resize(int capacity)&#123; int[] tmp = new int [capacity]; for (int i = 0;i != sz;i++)&#123; tmp[i] = a[i]; &#125; a = tmp; &#125; private void check()&#123; if (sz == a.length) resize(a.length * 2); &#125; public void push(int item)&#123; if (item &gt; Max) Max = item; check(); a[sz++] = item; &#125; public int pop()&#123; return a[--sz]; &#125; public int getMax()&#123; return Max; &#125; public String toString()&#123; return Arrays.toString(a); &#125; public static void main(String [] args)&#123; MaxArrayStack mStack = new MaxArrayStack(); mStack.push(4); mStack.push(5); mStack.push(6); mStack.push(2); mStack.push(1); mStack.push(10); mStack.push(7); mStack.push(7); System.out.println(mStack); System.out.println(mStack.getMax()); &#125;&#125; MaxLinkedStack123456789101112131415161718192021222324252627282930313233343536373839404142package Interview_Question_Week2;import java.util.*;class MaxLinkedStack &#123; private int N; private Node first; private Node max; private class Node &#123; private double item; private Node next; &#125; public MaxLinkedStack() &#123; N = 0; first = null; max = null; &#125; public double getMax() &#123; return max.item; &#125; public void push(double item) &#123; Node oldfirst = first; first = new Node(); first.item = item; first.next = oldfirst; N++; if (item &gt;= getMax()) &#123; Node oldmax = max; max = new Node(); max.next = oldmax; &#125; &#125; public double pop() &#123; double tmp = first.item; first = first.next; N--; if (tmp == getMax()) &#123; max = max.next; &#125; return tmp; &#125;&#125; StackQueue1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package Interview_Question_Week2;import java.util.*;public class StackQueue&lt;Item&gt; &#123; private Stack&lt;Item&gt; input = new Stack &lt;Item&gt;(); private Stack&lt;Item&gt; output = new Stack &lt;Item&gt;(); public int size ()&#123; return input.size() + output.size(); &#125; public StackQueue() &#123; &#125; public boolean isEmpty() &#123; return size() == 0; &#125; public void enqueue(Item item) &#123; if (item == null) throw new IllegalArgumentException("wrong enquene"); input.push(item); &#125; public Item dequeue() &#123; if (isEmpty())&#123; throw new IndexOutOfBoundsException("out of range"); &#125; if (output.isEmpty())&#123; while (!input.isEmpty())&#123; output.push(input.pop()); &#125; &#125; return output.pop(); &#125; public static void main(String [] args)&#123; StackQueue&lt;Integer&gt; squeue = new StackQueue&lt;Integer&gt;(); int i = 0; int N = 100; System.out.println("Size: " + squeue.size()); squeue.enqueue(i); while (i &lt;= N) &#123; if (i % 3 == 0) &#123; System.out.println("Dequeue: " + squeue.dequeue()); &#125; else &#123; squeue.enqueue(i); System.out.println("Enqueue: " + i); &#125; ++i; &#125; System.out.println("Size: " + squeue.size()); while (!squeue.isEmpty()) &#123; System.out.println("Dequeue: " + squeue.dequeue()); &#125; System.out.println("Size: " + squeue.size()); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Permutation]]></title>
    <url>%2F2019%2F02%2F24%2FPermutation%2F</url>
    <content type="text"><![CDATA[Permutation———普林斯顿算法大作业第二次总的来说第二次算法大作业比较简单，实现以下双端队列，以及随机出队的队列。鉴于这个难度系数，我这里直接写了两种，基于数组与基于链表两种方式，首先先看题目。 由于比较简单 这里不多说 直接开始贴代码。 Deque123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131package Programming_Assignment_2;import java.util.Iterator;import java.util.NoSuchElementException;public class Deque&lt;Item&gt; implements Iterable&lt;Item&gt; &#123; private Node first,last; private int size; private class Node &#123; Item item; Node next; Node previous; Node (Item i)&#123; item = i; next = null; previous = null; &#125; &#125; public Deque() &#123; first = last = null; size = 0; &#125; public boolean isEmpty() &#123; return size == 0; &#125; public int size() &#123; return size; &#125; public void addFirst(Item item) &#123; if (item == null)&#123; throw new IllegalArgumentException(); &#125; Node oldFirst = first; first = new Node(item); first.previous = null; if (isEmpty())&#123; last = first; first.next = null; &#125; else &#123; first.next = oldFirst; oldFirst.previous = first; &#125; size++; &#125; public void addLast(Item item) &#123; if (item == null)&#123; throw new IllegalArgumentException(); &#125; Node tmp = new Node(item); tmp.next = null; if (isEmpty())&#123; first = tmp; last = tmp; last.previous = null; &#125; else &#123; last.next = tmp; tmp.previous = last; last = tmp; &#125; size++; &#125; public Item removeFirst() &#123; if (isEmpty())&#123; throw new NoSuchElementException(); &#125; Item cnt = first.item; first = first.next; size--; if (isEmpty()) &#123; last = first =null; &#125; else &#123; first.previous = null; &#125; return cnt; &#125; public Item removeLast() &#123; if (isEmpty())&#123; throw new NoSuchElementException(); &#125; Item cnt = last.item; last = last.previous; size--; if (isEmpty())&#123; first = last = null; &#125; else &#123; last.next = null; &#125; return cnt; &#125; public Iterator&lt;Item&gt; iterator() &#123; return new DequeIterator(first); &#125; private class DequeIterator implements Iterator&lt;Item&gt;&#123; private Node current; public DequeIterator(Node first) &#123; current = first; &#125; public boolean hasNext()&#123; return current != null; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; public Item next()&#123; if (!hasNext())&#123; throw new NoSuchElementException(); &#125; Item cnt = current.item; current = current.next; return cnt; &#125; &#125;&#125; RandomizedQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package Programming_Assignment_2;import java.util.Iterator;import java.util.NoSuchElementException;import java.lang.UnsupportedOperationException;import edu.princeton.cs.algs4.StdRandom;//原本最初的打算是直接用链表进行实现的，//但是后来才发现性能要求迭代器的next的方法必须是常数时间，//而用链表实现不了，所以改用数组实现。public class RandomizedQueue&lt;Item&gt; implements Iterable&lt;Item&gt; &#123; private Item[] array; private int size; public RandomizedQueue()&#123; size = 0; array = (Item[]) new Object[1]; &#125; public boolean isEmpty() &#123; return size == 0; &#125; public int size() &#123; return size; &#125; private void check() &#123; if (size &gt;= array.length)&#123; resize(array.length * 2); &#125; else if (size &lt; array.length / 4)&#123; resize(array.length / 2); &#125; &#125; private void resize(int n) &#123; Item[] tmp = (Item[]) new Object[n]; for (int i = 0;i &lt; size;i++)&#123; tmp[i] = array[i]; &#125; array = tmp; &#125; public void enqueue(Item item) &#123; if (item == null) throw new IllegalArgumentException("wrong input"); check(); array[size++] = item; &#125; public Item dequeue() &#123; if (isEmpty()) throw new NoSuchElementException(); int random = StdRandom.uniform(size); Item cnt =array[random]; array[random] = array[size - 1]; array[--size] = null; check(); return cnt; &#125; public Item sample() &#123; if (isEmpty()) throw new NoSuchElementException(); return array[StdRandom.uniform(size)]; &#125; public Iterator&lt;Item&gt; iterator() &#123; return new RandomIterator(); &#125; private class RandomIterator implements Iterator&lt;Item&gt; &#123; private int rank; private Item[] iarray; public RandomIterator() &#123; rank = size; iarray = (Item[]) new Object[rank]; for (int i = 0;i &lt; rank;i++)&#123; iarray[i] = array[i]; &#125; &#125; public boolean hasNext() &#123; return rank &gt; 0; &#125; public void remove()&#123; throw new UnsupportedOperationException(); &#125; public Item next ()&#123; if (!hasNext()) throw new NoSuchElementException(); int random = StdRandom.uniform(rank); rank--; Item item = iarray[random]; iarray[random] = iarray[rank]; //这里需要注意的是 与上面直接在原数组上面操作的区别就在于不能直接令后面等于null //如 iarray[rank] = null 这样造成的后果是多用几次迭代器使用不了了。 iarray[rank] = null; return item; &#125; &#125;&#125; Permutation 123456789101112131415161718package Programming_Assignment_2;import edu.princeton.cs.algs4.StdIn;public class Permutation &#123; public static void main(String[] args) &#123; RandomizedQueue&lt;String&gt; rq = new RandomizedQueue&lt;String&gt;(); int k = Integer.parseInt(args[0]); while (!StdIn.isEmpty()) &#123; rq.enqueue(StdIn.readString()); // System.out.println(StdIn.readString()); &#125; while (k &gt; 0) &#123; System.out.println(rq.dequeue()); k--; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Percolation]]></title>
    <url>%2F2019%2F02%2F08%2FPercolation%2F</url>
    <content type="text"><![CDATA[Programming Assignment 1: Percolation第一次提交这样的全英文大作业，先开始完全看不懂题目，然后在网上看懂题目之后，于是写代码的时候也是混乱的，完全不知道该怎么用，看了别人提交的写了之后，自己也提交了几次，都是60分70分左右，到最后才发现数组的溢出，以及java输入输出的一些问题。 接下来看题目首先先看英文版的题目 看懂的大神可以不用看下面的中文版的题目了： 通过蒙特卡洛模拟方法来估计渗流阈值。 Percolation. 给一个有随机分布的绝缘和金属材料的组成的复合系统。例如我们想知道哪些部分必须是金属材料才能让这个复合系统是一个电导体。或者在一个多孔的地形，在表面有水或者油，在什么情况下水或者油能够从最表面渗透到最底层。科学家把这种过程的模型叫做Percolation。 The model. 在Assignment中，用一个NxN的格子表示percolation系统，每一个格子是打开或者关闭，打开是白色关闭是黑色。如果一个格子是full，首先他必须是打开额，然后表示从最顶上通过相连(4方向)的打开的格子可以渗透到这个位置。当一个系统是percolates，表示能从最顶层渗透到最底层，也就是说，最底层存在打开的格子是full。 The Problem. 研究人员对一下的问题感兴趣，如果每一个格子是独立的，并且被打开的概率为p，那么系统percolates的概率是多少？p=0，percolates概率为0，p=100，percolates的概率为100。下图是20x20和100x100格子的概率p的分布： 当N足够大时, 有一个阈值P, 使得当p &lt; p时候，任意的NN网格，几乎不能被渗透, 并且当p &gt; p, 基本能够被渗透。p没有准确的数值解。任务是写一个计算估计p的算法。 题目给出了两个样版分别作为题目开始写的两个类： 1234567public class Percolation &#123; public Percolation(int N) // create N-by-N grid, with all sites blocked public void open(int i, int j) // open site (row i, column j) if it is not already public boolean isOpen(int i, int j) // is site (row i, column j) open? public boolean isFull(int i, int j) // is site (row i, column j) full? public boolean percolates() // does the system percolate?&#125; 123456789public class PercolationStats &#123; public PercolationStats(int n, int trials) // perform trials independent experiments on an n-by-n grid public double mean() // sample mean of percolation threshold public double stddev() // sample standard deviation of percolation threshold public double confidenceLo() // low endpoint of 95% confidence interval public double confidenceHi() // high endpoint of 95% confidence interval public static void main(String[] args) // test client (described below)&#125; 第一部分建立起一个数学模型来模拟这个系统class Percolation123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import edu.princeton.cs.algs4.WeightedQuickUnionUF;public class Percolation &#123; //建立两个并查集 来控制 backwash 的虚拟节点所产生的问题 private WeightedQuickUnionUF uf; private WeightedQuickUnionUF backwash; //打开的数目 private int num; //这里用一维数组来表示整张图 private boolean[] percolation; //总数目 private int len; public Percolation(int n) &#123; if (n &lt; 1) throw new IllegalArgumentException("Illeagal Argument"); len = n; percolation = new boolean[n * n + 2]; uf = new WeightedQuickUnionUF(n * n + 2); backwash = new WeightedQuickUnionUF(n * n + 1); num = 0; for (int i = 1;i &lt; n * n + 1; i++)&#123; percolation[i] = false; &#125; percolation[0] = percolation[n * n + 1] = true; &#125; private void check(int i,int j)&#123; if (i &lt; 1 || i &gt; len || j &lt; 1 || j &gt; len) throw new IllegalArgumentException("out of the range"); &#125; private int get_position(int i,int j) &#123; return (i - 1) * len + j; &#125; public void open(int row, int col) &#123; check(row,col); if (isOpen(row,col)) return; int index = get_position(row,col); percolation[index] = true; num++; //处理虚拟节点与实际中的点的关系 //并且同时处理一下前后左右点之间的关系 if (row == 1)&#123; uf.union(0,index); backwash.union(0,index); &#125; else if (isOpen(index - len))&#123; uf.union(index,index - len); backwash.union(index,index - len); &#125; if (row == len) uf.union(len * len + 1,index); else if (isOpen(index + len))&#123; uf.union(index,index + len); backwash.union(index,index + len); &#125; if (col != 1 &amp;&amp; isOpen(index - 1))&#123; uf.union(index,index - 1); backwash.union(index,index - 1); &#125; if (col != len &amp;&amp; isOpen(index + 1))&#123; uf.union(index,index + 1); backwash.union(index,index + 1); &#125; &#125; private boolean isOpen(int x)&#123; return percolation[x]; &#125; public boolean isOpen(int row, int col)&#123; check(row,col); return isOpen(get_position(row,col)); &#125; public boolean isFull(int row, int col)&#123; check(row,col); int index = get_position(row,col); if (backwash.connected(index,0)) return true; return false; &#125; public int numberOfOpenSites()&#123; return num; &#125; public boolean percolates()&#123; return uf.connected(0,len * len + 1); &#125;&#125; 关于以上这个类 其实最初思考之处，完全就是借鉴并查集的思想，使用一个数组来存储当前的模块有没有被打开，然后根据这个模块进行改变，然后再使用并查集将第一个与当前位置相连接，前后左右都打开就相当于链接了，然后根据遍历就可以找出是否会遍历到最后一个位置去了。 上面所说的办法有些麻烦，有一种方法所产生的两个问题，也就是上面所使用的方法使用虚拟节点，相当于预设一个起点和一个终点，最后只需要判断起点与终点是否是并查集相连接的即可 并查集的使用方法，可以直接写一个类也可以使用自带好的类型。 会产生终点处的backwash问题，意思就是终点位置可能会与许多没有连接到起点的支点相连接，所以采用的解决办法就是使用两个并查集。 第二部分就是 解决数据的位置估计percolation的阈值，初始化时候格子都是关闭的，随机寻找一个关闭的位置打开，直到系统可以渗透为止，打开的格子比上总格子数就是阈值。 运用一下这些公式： 这个问题仅仅就是数学处理的问题，以及控制格式上面的输入输出。 class PercolationStats12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import edu.princeton.cs.algs4.StdIn;import edu.princeton.cs.algs4.StdOut;import edu.princeton.cs.algs4.StdRandom;import edu.princeton.cs.algs4.StdStats;import edu.princeton.cs.algs4.Stopwatch;public class PercolationStats &#123; private double[] results; // estimated threshold for each trial private double avg; private double std; public PercolationStats(int n, int trials)&#123; if(n &lt;= 0 || trials &lt;= 0) throw new IllegalArgumentException(); results = new double[trials]; for(int i = 0; i &lt; trials; i++)&#123; int step = 0; Percolation pr = new Percolation(n); while(!pr.percolates())&#123; int row = StdRandom.uniform(n) + 1; int col = StdRandom.uniform(n) + 1; if(!pr.isOpen(row, col))&#123; pr.open(row, col); step++; &#125; &#125; results[i] = (double)step / (n * n); &#125; this.avg = StdStats.mean(results); this.std = StdStats.stddev(results); &#125; public static void main(String[] args)&#123; StdOut.printf("%-25s\n", "Please input 2 integers"); int N = StdIn.readInt(); int T = StdIn.readInt(); Stopwatch wt = new Stopwatch(); PercolationStats ps = new PercolationStats(N, T); // elapsed CPU time in seconds double elapsed = wt.elapsedTime(); StdOut.printf("%-25s= %.15f\n", "elapsed CPU time", elapsed); StdOut.printf("%-25s= %.7f\n", "mean", ps.mean()); StdOut.printf("%-25s= %.17f\n", "stddev", ps.stddev()); StdOut.printf("%-25s= [%.15f, %.15f]\n", "%95 confidence interval", ps.confidenceLo(), ps.confidenceHi()); &#125; public double mean()&#123; return this.avg; &#125; public double stddev()&#123; return this.std; &#125; public double confidenceLo()&#123; return mean() - 1.96 * stddev() / Math.sqrt(results.length); &#125; public double confidenceHi()&#123; return mean() + 1.96 * stddev() / Math.sqrt(results.length); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>普林斯顿算法课</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[普林斯顿算法课之并查集]]></title>
    <url>%2F2019%2F02%2F08%2F%E6%99%AE%E6%9E%97%E6%96%AF%E9%A1%BF%E7%AE%97%E6%B3%95%E8%AF%BE%E4%B9%8B%E5%B9%B6%E6%9F%A5%E9%9B%86%2F</url>
    <content type="text"><![CDATA[普林斯顿算法之并查集个人理解 并查集就是运用在联通路径中，需要压缩路径，从而快速判断接下里的几个位置是否相连. 根据以上的需求可以写出简单类似于并查集的操作 建立数学模型，用一维甚至是多维数组来表示两个位置是否相连，相连则用相同数字来进行表示，然后经过遍历来筛查。 以上这种办法简单粗暴会花费很多无用功，所以这才产生了并查集的前身 简单来说就是根据叠加效应，如若两者相连，就将前者作为后者的值，然后依次累积，就会产生类似树形结构的根节点，也就是下面将会提到的root函数1234567private int root(int i)&#123; while (i != point[i]) &#123; i = point[i]; &#125; return i; &#125; 以上代码在二者没有相连接的时候，每一个人的根节点都是自己，当使用union操作的时候，就是将前者接到后者上面即后者就变成前者的节点，而这里就进行循环，知道找到根节点（根节点的祖先是自己） 接下来就是union操作1234567public void union(int a,int b)&#123; int roota = root(a); int rootb = root(b); if (roota == rootb) return ; point[rootb] = roota; cnt--; &#125; 找到两个所给点的祖先，并且把他们的祖先做一个连接行为，这样就完成了并查集的核心，而往往最多的变式就产生在这其中，一般涉及到祖先的赋值情况，后面优化的时候再说。 最后一个就是connected的函数，主要用来判断是否两个点是否连接，直接判断他们两个的祖先点是否相等即可。123public boolean connected(int a,int b)&#123; return root(a)==root(b); &#125; 优化优化主要分为两个方面路径压缩和路径树平衡。 路径压缩12345678private int root(int i)&#123; while (i != point[i]) &#123; point[i] = point[point[i]]; i = point[i]; &#125; return i; &#125; 此处与上面相比仅仅只是多了一行代码，但是却可以让代码提高速度5倍以上，这里就是将本来要一个一个叠加的节点，变成了多支叠加，这样树的深度少了很多，所带来的结果就是效率的提高。 路径树平衡1234567891011121314151617public void union(int a,int b)&#123; int roota = root(a); int rootb = root(b); if (roota == rootb) return ; if (sz[roota] &lt; sz[rootb])&#123; //下面的意思就是让 roota 接到 rootb 上面 point[roota] = rootb; sz[rootb] += sz[roota]; &#125; else &#123; point[rootb] = roota; //下面这个意思就是继续接头接上去 sz[roota] += sz[rootb]; if (Max[rootb] &gt; Max[roota]) Max[roota] = Max[rootb]; &#125; cnt--; &#125; 这里所带来的改变就是 使用了一个sz数组来记录每一个点在这个位置的深度，从而在每一次union操作的时候，都会有一个判断，就是树层次小的往树层次大的节点上面接，这样一来，同样减少了树的开销，加快效率。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>普林斯顿算法课</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中this和super的用法总结]]></title>
    <url>%2F2019%2F01%2F21%2FJava%E4%B8%ADthis%E5%92%8Csuper%E7%9A%84%E7%94%A8%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[thisthis是自身的一个对象，代表对象本身，可以理解为：指向对象本身的一个指针。 this的用法在java中大体可以分为3种： 1. 类似于C++里面对于自身普通的引用，这种情况就不在多讲了2. 形参与成员名字重名，用this来区分1234567891011121314151617class Person &#123; private int age = 10; public Person()&#123; System.out.println("初始化年龄："+age);&#125; public int GetAge(int age)&#123; this.age = age; return this.age; &#125;&#125; public class test1 &#123; public static void main(String[] args) &#123; Person Harry = new Person(); System.out.println("Harry's age is "+Harry.GetAge(12)); &#125;&#125; 运行结果：初始化年龄：10Harry’s age is 12 可以看到，这里age是GetAge成员方法的形参，this.age是Person类的成员变量。 3. 引用构造函数这个就放在下面与super一起讲。 supersuper可以理解为是指向自己超（父）类对象的一个指针，而这个超类指的是离自己最近的一个父类。 1. 类似于C++的普通对父类对象的引用。（这里也不在多说）2. 子类中的成员变量或方法与父类中的成员变量或方法同名（可以用该办法区分）123456789101112131415161718192021class Country &#123; String name; void value() &#123; name = "China"; &#125;&#125;class City extends Country &#123; String name; void value() &#123; name = "Shanghai"; super.value(); //调用父类的方法 System.out.println(name); System.out.println(super.name); &#125; public static void main(String[] args) &#123; City c=new City(); c.value(); &#125;&#125; 运行结果:ShanghaiChina 可以看到，这里既调用了父类的方法，也调用了父类的变量。若不调用父类方法value()，只调用父类变量name的话，则父类name值为默认值null。 3.引用构造函数super（参数）：调用父类中的某一个构造函数（应该为构造函数中的第一条语句）。this（参数）：调用本类中另一种形式的构造函数（应该为构造函数中的第一条语句）。 1234567891011121314151617181920212223242526272829303132333435363738class Person &#123; public static void prt(String s) &#123; System.out.println(s); &#125; Person() &#123; prt("父类·无参数构造方法： "+"A Person."); &#125;//构造方法(1) Person(String name) &#123; prt("父类·含一个参数的构造方法： "+"A person's name is " + name); &#125;//构造方法(2) &#125; public class Chinese extends Person &#123; Chinese() &#123; super(); // 调用父类构造方法（1） prt("子类·调用父类”无参数构造方法“： "+"A chinese coder."); &#125; Chinese(String name) &#123; super(name);// 调用父类具有相同形参的构造方法（2） prt("子类·调用父类”含一个参数的构造方法“： "+"his name is " + name); &#125; Chinese(String name, int age) &#123; this(name);// 调用具有相同形参的构造方法（3） prt("子类：调用子类具有相同形参的构造方法：his age is " + age); &#125; public static void main(String[] args) &#123; Chinese cn = new Chinese(); cn = new Chinese("codersai"); cn = new Chinese("codersai", 18); &#125; &#125;``` 运行结果:父类·无参数构造方法： A Person.子类·调用父类”无参数构造方法“： A chinese coder.父类·含一个参数的构造方法： A person’s name is codersai子类·调用父类”含一个参数的构造方法“： his name is codersai父类·含一个参数的构造方法： A person’s name is codersai子类·调用父类”含一个参数的构造方法“： his name is codersai子类：调用子类具有相同形参的构造方法：his age is 18 从本例可以看到，可以用super和this分别调用父类的构造方法和本类中其他形式的构造方法。 例子中Chinese类第三种构造方法调用的是本类中第二种构造方法，而第二种构造方法是调用父类的，因此也要先调用父类的构造方法，再调用本类中第二种，最后是重写第三种构造方法。 super和this的异同： super（参数）：调用基类中的某一个构造函数（应该为构造函数中的第一条语句） this（参数）：调用本类中另一种形成的构造函数（应该为构造函数中的第一条语句） super: 它引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如：super.变量名 super.成员函数据名（实参） this：它代表当前对象名（在程序中易产生二义性之处，应使用this来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用this来指明成员变量名） 调用super()必须写在子类构造方法的第一行，否则编译不通过。每个子类构造方法的第一条语句，都是隐含地调用super()，如果父类没有这种形式的构造函数，那么在编译的时候就会报错。 super()和this()类似,区别是，super()从子类中调用父类的构造方法，this()在同一类内调用其它方法。 super()和this()均需放在构造方法内第一行。 尽管可以用this调用一个构造器，但却不能调用两个。 this和super不能同时出现在一个构造函数里面，因为this必然会调用其它的构造函数，其它的构造函数必然也会有super语句的存在，所以在同一个构造函数里面有相同的语句，就失去了语句的意义，编译器也不会通过。 this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。 从本质上讲，this是一个指向本对象的指针, 然而super是一个Java关键字。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>java</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之排序总结]]></title>
    <url>%2F2018%2F12%2F18%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[数据结构的排序总结首先先展示一张图，来说明每一个排序之间的复杂度和稳定性 冒泡排序这种排序往往属于最基本的排序了，比较稳定，而且代码也比较简单，这里不做多讲，直接贴代码 123456789101112131415void maopao(int *p)&#123; for (int i=0;i!=maxn;i++) &#123; for (int j=i+1;j!=maxn;j++) &#123; if (*(p+i)&gt;*(p+j))&#123; int temp = *(p+i); *(p+i) = *(p+j); *(p+j) = temp; &#125; &#125; &#125; print(p);&#125; 快速排序 进阶版的冒泡排序，即对冒泡排序进行算法优化过得结果 快速排序的基本思想就是，通过找到一个中间值(枢纽值)，然后比枢纽值小的放到枢纽值的左边，比枢纽值大的放在枢纽值的右边，然后通过枢纽值来进行划分，一次往下面划分，利用递归或者是非递归的栈来实现，最终实现相应的排序。 算法步骤 首先找到一个枢纽,一般找最中间的一个值，或者找最左边的一个值，或者最右边的值，但是这样就会有缺陷，在某些特殊情况下会会存在很多不必要的开销。 如果最后这个值刚好是整段序列最大或者最小的值，那么这次划分就是没意义的。 所以当序列是正序或者逆序时，每次选到的枢轴都是没有起到划分的作用。快排的效率会极速退化。所以可以每次在选枢轴时，在序列的第一，中间，最后三个值里面选一个中间值出来作为枢轴，保证每次划分接近均等。 所以采用的是三值取中法： 12345678910111213141516int get_mid(int *a,int left,int right)&#123; int mid = (left + right) / 2; if (a[left] &lt;= a[right]) &#123; if (a[mid] &lt; a[left]) return left; else if (a[mid] &gt; a[right]) return right; else return mid; &#125; else &#123; if (a[mid] &lt; a[right]) return right; else if (a[mid] &gt; a[left]) return left; else return mid; &#125;&#125; 当取到中间的枢纽值之后，接下来需要完成的是将枢纽值放到最右边，并且一次进行比较排序，将比枢纽值小的放在左边，比枢纽值大的放在右边。最后返回最终枢纽值所在的位置，按照此位置进行划分子区，从而完成一次快速排序，然后再到每一个子区进行重复上述过程。 以下介绍两种方法，而这两种方法代码类似，而两者唯一的区别也就在于对于key的处理了，一个是直接将key当做是引用，而另一个则是直接拷贝。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//左右指针交换的办法int part_sort1(int *a,int left,int right)&#123; int mid = get_mid(a,left,right); swap(a[mid],a[right]); int &amp;key = a[right]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; a[left] &lt;= key) ++left; while (left &lt; right &amp;&amp; a[right] &gt;= key) --right; //交换左右两个的值，分别根据key值进行一个有效的划分 swap (a[left],a[right]); &#125; //由于这里的key是一个引用，直接附在了枢纽值上面，无论怎么移动，都可以在这个地方直接进行交换 swap(a[right],key); //然而这里需要注意就是，无论这里是写right还是left，到最后right与left一定会相同的，因为每一次划分最后到不能划分之后，左右指针就会进行一个重叠。 return right;&#125;//挖坑填补法int part_sort2(int *a,int left,int right)&#123; int mid = get_mid(a,left,right); swap (a[mid],a[right]); //这里实际上就是直接将枢纽值进行拷贝给temp上面 int key = a[right]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; a[left] &lt;= key) ++left; a[right] = a[left]; //每一步骤就进行占位 while (left &lt; right &amp;&amp; a[right] &gt;= key) --right; //相当于此处进行一个有效的位置互换 a[left] = a[right]; &#125; a[right] = key; //然后这里right指向的元素就应该是多余且本应该存放枢纽值的位置 return right;&#125; 当每一步结束之后，可以利用递归，也可以使用非递归的栈来实现对每一步的分区进行快排的操作。 123456789void quick_sort(int *a,int left,int right)&#123; if (left &lt; right) &#123; int index = part_sort1(a,left,right); quick_sort(a,left,index-1); quick_sort(a,index+1,right); &#125;&#125; 选择排序简单选择排序是最简单直观的一种算法，基本思想为每一趟从待排序的数据元素中选择最小（或最大）的一个元素作为首元素，直到所有元素排完为止，简单选择排序是不稳定排序。 算法思想：每一趟确定最小元素的时候会通过不断地比较交换来使得首位置为当前最小，交换是个比较耗时的操作。通过设置一个变量min，每一次比较仅存储较小元素的数组下标，当轮循环结束之后，那这个变量存储的就是当前最小元素的下标，此时再执行交换操作即可。（这里不做过多阐述） 12345678910111213141516171819void xuanze(int *p)&#123; for (int i=0;i!=maxn;i++) &#123; int Min = i; for (int j = i+1; j!=maxn ;j++) &#123; if (*(p+Min) &gt; *(p+j)) Min = j; &#125; if (Min != i) &#123; int temp = *(p + Min); *(p + Min) = * (p + i); *(p + i) = temp; &#125; &#125; print(p);&#125; 堆排序堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，（可以理解成特殊的选择排序，相当于完全二叉树型的选择排序）它的最坏，最好，平均时间复杂度均为O(nlogn)，它也是不稳定排序。 首先简单了解下堆结构。 堆堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。如下图： 堆排序的思想：首先先将给出的序列进行一个调整，调整成一个大顶堆或者一个小顶堆，调整之后，再把栈顶的元素与最后一个元素进行交换，交换完成之后在进行调整，最后完成堆排序。 堆排序步骤: 构造大顶堆或者小顶堆，通过调整的方式 最初模样 从最后一个非叶子节点开始，从左到右，从上到下进行调整 找到根节点，左孩子，右孩子，中的最大的一个，使其放在根节点的位置。 继续向上面调整，一步一步的更替到下面 代码如下：123456789101112131415161718void adjust(int *a,int root,int len)&#123; int temp = a[root]; //堆排序这里如果是数组是从0开始计数的话 这里必须加上一个1 //但是如果是从0开始计数的话，那么这里就这样写 int child = 2 * root; while (child &lt; len) &#123; if (child + 1 &lt; len &amp;&amp; a[child] &lt; a[child + 1]) child ++; if (temp &gt;= a[child]) break; a[root] = a[child]; root = child; child = 2 * child; &#125; a[root] = temp;&#125; 将栈顶元素与最后一个元素进行交换，使末尾元素最大，然后再来慢慢调整。 以下的四张图就是交换元素，并且每交换一次都会调整元素一次 代码如下12345678910111213void heap_sort(int *a)&#123; //注意这里必须从后面开始往前面递归的意思就在于便于改变上面之后可以有效的推至下面，相当于一个小型递归 for (int i = maxn / 2;i &gt;= 0;i--) adjust(a,i,maxn); for (int i = maxn - 1;i &gt; 0;i--)&#123; swap (a[0],a[i]); //这里需不需要减1 是根据上面的adjust里面对于上限值的处理 如果是大于等于就需要减去1 如果仅仅只是小于，那么就不需要减去1 adjust(a,0,i); &#125; print (a);&#125; 插入排序算法思想： 从后面往前面递进，将每一个树直接插入到前面已经排好序的序列里面去。(后面再详细阐明) 123456789101112131415161718void charu(int *p)&#123; for (int i=1;i!=maxn;i++) &#123; int temp = *(p+i); int j = i; while (j&gt;0 &amp;&amp; temp &lt; *(p+j-1) ) &#123; *(p+j) = *(p+j-1); j--; &#125; if (i != j) &#123; *(p+j) = temp; &#125; &#125; print(p);&#125; 希尔排序 其实希尔排序也就是基于插入排序的优化版本，而插入排序则可以看做是增值为1的希尔排序 算法思想希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止 可以观看下面图示： 算法步骤：首先找出每一个gap值（增值），然后根据增值进行相除，找到每一个间隔位置的元素，来比较大小然后排序，而gap值所造成的间隔会越来越小，直到最后增值为一，成为最后的插入排序。 一般gap值为2，即用2去整除，但是有的算法表示同样也可以用到3 代码如下：12345678910111213141516171819202122void xier(int *a)&#123; for (int gap = maxn/2;gap&gt;0;gap=gap/2) &#123; //从后面往前面进行递增，获取gap的值，然后依次除以2. for (int i=gap;i&lt;maxn;i++) &#123; //下面就类似于插入排序了，只不过增值要从1变成gap。 int temp = a[i]; int j = i; //这个地方需要注意的是对于插入排序 最后一个值是需要到j&gt;=1，而这里要到gap，注意清楚范围。 while (j&gt;gap-1 &amp;&amp; temp &lt; *(a+j-gap)) &#123; *(a+j) = *(a+j-gap); j -= gap; &#125; //上一步每一个都伦换过后，将最初这里的值换到相应的位置上面 *(a+j) = temp; &#125; &#125; print(a);&#125; 归并排序 归并排序是利用归并的思想实现的排序方法，该算法采用经典的分治策略（分治法将问题分成一些小的问题然后递归求解，而治的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 算法思想:其实有点像完全二叉树的结构，但是又有很大的不同,主要就是借助另外一个同样长的数组来存储合并之后的结果，合并的时候可以使用递归或者使用栈来决定合并部位。然后合并的过程中分成无数个小部分，然后一一往新的数组上面添加，最后拷贝到原来的数组上面。 算法步骤： 决定合并部位，这里贴出两个，一个是直接利用递归，另一个是利用循环，用1，2，4，8…乘数扩大进行操作。 递归版本： 12345678910void gui_sort(int *a,int left,int right,int *temp)&#123; if (left &lt; right) &#123; int mid = (left + right) / 2; gui_sort(a,left,mid,temp); gui_sort(a,mid+1,right,temp); merge(a,left,mid,right,temp); &#125;&#125; 非递归版本： 12345678910111213141516171819202122void fei_gui_sort(int *a,int *temp)&#123; int size=1,low,mid,high; while(size&lt;=maxn-1) &#123; low=0; //这个步骤就相当于上面递归内部进行的步骤了，从1到2到4到8到16，依次进行。 //但是这种非递归的版本可以带来节省很多由栈带来的递归开销。 while(low+size&lt;=maxn-1) &#123; mid=low+size-1; high=mid+size; if(high&gt;maxn-1) high=maxn-1; merge(a,low,mid,high,temp); low=high+1; &#125; //这里乘以2。 size*=2; &#125;&#125; 然后就是合并操作了，设置几个指针节点，然后依次比较大小，把小的那个先放入排序中。 12345678910111213141516171819202122232425void merge(int *a,int left,int mid,int right,int *temp)&#123; int i =left; int j = mid +1; int t = 0; //左边与右边开始进行比较 while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; if (a[i] &lt; a[j]) temp[t++] = a[i++]; else temp[t++] = a[j++]; &#125; //左边剩下的 while (i &lt;= mid) temp[t++] = a[i++]; //右边剩下的 while (j &lt;= right) temp[t++] = a[j++]; t = 0; //拷贝到原数组中去 while (left &lt;= right) a[left++] = temp[t++];&#125; 全部代码(可直接运行)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330/************************************************************************* &gt; File Name: 排序代码.cpp &gt; Author: wangshuxiao &gt; Mail: wsx1128@outlook.com &gt; Created Time: Mon 17 Dec 11:23:48 2018 ************************************************************************/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;const int maxn = 20;//这里使用STL算法中的shuffle来使最初的排序全部随机void print(int *p)&#123; for (int i = 0; i != 20; i++) &#123; cout &lt;&lt; *p++ &lt;&lt;" "; &#125; cout &lt;&lt; endl &lt;&lt; endl;&#125;void random(int *p)&#123; random_shuffle(p,p+maxn); print(p);&#125;void maopao(int *p)&#123; for (int i=0;i!=maxn;i++) &#123; for (int j=i+1;j!=maxn;j++) &#123; if (*(p+i)&gt;*(p+j))&#123; int temp = *(p+i); *(p+i) = *(p+j); *(p+j) = temp; &#125; &#125; &#125; print(p);&#125;void xuanze(int *p)&#123; for (int i=0;i!=maxn;i++) &#123; int Min = i; for (int j = i+1; j!=maxn ;j++) &#123; if (*(p+Min) &gt; *(p+j)) Min = j; &#125; if (Min != i) &#123; int temp = *(p + Min); *(p + Min) = * (p + i); *(p + i) = temp; &#125; &#125; print(p);&#125;void charu(int *p)&#123; for (int i=1;i!=maxn;i++) &#123; int temp = *(p+i); int j = i; while (j&gt;0 &amp;&amp; temp &lt; *(p+j-1) ) &#123; *(p+j) = *(p+j-1); j--; &#125; if (i != j) &#123; *(p+j) = temp; &#125; &#125; print(p);&#125;void xier(int *a)&#123; for (int gap = maxn/2;gap&gt;0;gap=gap/2) &#123; for (int i=gap;i&lt;maxn;i++) &#123; int temp = a[i]; int j = i; while (j&gt;gap-1 &amp;&amp; temp &lt; *(a+j-gap)) &#123; *(a+j) = *(a+j-gap); j -= gap; &#125; *(a+j) = temp; &#125; &#125; print(a);&#125;void merge(int *a,int left,int mid,int right,int *temp)&#123; int i =left; int j = mid +1; int t = 0; while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; if (a[i] &lt; a[j]) temp[t++] = a[i++]; else temp[t++] = a[j++]; &#125; while (i &lt;= mid) temp[t++] = a[i++]; while (j &lt;= right) temp[t++] = a[j++]; t = 0; while (left &lt;= right) a[left++] = temp[t++];&#125;void gui_sort(int *a,int left,int right,int *temp)&#123; if (left &lt; right) &#123; int mid = (left + right) / 2; gui_sort(a,left,mid,temp); gui_sort(a,mid+1,right,temp); merge(a,left,mid,right,temp); &#125;&#125;void guibing(int *a)&#123; int *temp = new int [maxn]; gui_sort(a,0,maxn-1,temp); print(a); delete [] temp; return ;&#125;void fei_gui_sort(int *a,int *temp)&#123; int size=1,low,mid,high; while(size&lt;=maxn-1) &#123; low=0; while(low+size&lt;=maxn-1) &#123; mid=low+size-1; high=mid+size; if(high&gt;maxn-1) high=maxn-1; merge(a,low,mid,high,temp); low=high+1; &#125; size*=2; &#125;&#125;void fei_guibing(int *a)&#123; int *temp = new int [maxn]; fei_gui_sort(a,temp); print(a); if (temp != NULL) delete [] temp;&#125;int get_mid(int *a,int left,int right)&#123; int mid = (left + right) / 2; if (a[left] &lt;= a[right]) &#123; if (a[mid] &lt; a[left]) return left; else if (a[mid] &gt; a[right]) return right; else return mid; &#125; else &#123; if (a[mid] &lt; a[right]) return right; else if (a[mid] &gt; a[left]) return left; else return mid; &#125;&#125;//左右指针交换的办法int part_sort1(int *a,int left,int right)&#123; int mid = get_mid(a,left,right); swap(a[mid],a[right]); int &amp;key = a[right]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; a[left] &lt;= key) ++left; while (left &lt; right &amp;&amp; a[right] &gt;= key) --right; swap (a[left],a[right]); &#125; swap(a[right],key); return right;&#125;//挖坑填补法int part_sort2(int *a,int left,int right)&#123; int mid = get_mid(a,left,right); swap (a[mid],a[right]); int key = a[right]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; a[left] &lt;= key) ++left; a[right] = a[left]; while (left &lt; right &amp;&amp; a[right] &gt;= key) --right; a[left] = a[right]; &#125; a[right] = key; return right;&#125;void quick_sort(int *a,int left,int right)&#123; if (left &lt; right) &#123; int index = part_sort1(a,left,right); quick_sort(a,left,index-1); quick_sort(a,index+1,right); &#125;&#125;void kuaisu(int *a)&#123; quick_sort(a,0,maxn-1); print(a);&#125;void adjust(int *a,int root,int len)&#123; int temp = a[root]; int child = 2 * root + 1; while (child &lt; len) &#123; if (child + 1 &lt; len &amp;&amp; a[child] &lt; a[child + 1]) child ++; if (temp &gt;= a[child]) break; a[root] = a[child]; root = child; child = 2 * child; &#125; a[root] = temp;&#125;void heap_sort(int *a)&#123; for (int i = maxn / 2;i &gt;= 0;i--) adjust(a,i,maxn); for (int i = maxn - 1;i &gt; 0;i--)&#123; swap (a[0],a[i]); adjust(a,0,i); &#125; print (a);&#125;int main()&#123; int a[20] = &#123;1,2,3,4,5,6,7,8,9,10,11, 12,13,14,15,16,17,18,19,20&#125;; cout &lt;&lt; "最初的顺序为" &lt;&lt; endl; print(a); //以上为初始化过后，并且进行打乱顺序的排列顺序 //冒泡排序 cout &lt;&lt; "冒泡排序" &lt;&lt; endl; random(a); maopao(a); //选择排序 cout &lt;&lt; "选择排序" &lt;&lt; endl; random(a); xuanze(a); //插入排序 cout &lt;&lt; "插入排序" &lt;&lt; endl; random(a); charu(a); //希尔排序 cout &lt;&lt; "希尔排序" &lt;&lt; endl; random(a); xier(a); //归并排序 cout &lt;&lt; "递归版本归并排序" &lt;&lt; endl; random(a); guibing(a); cout &lt;&lt; "非递归版本的归并排序" &lt;&lt; endl; random (a); fei_guibing(a); //快速排序 cout &lt;&lt; "快速排序" &lt;&lt; endl; random(a); kuaisu(a); //堆排序 cout &lt;&lt; "堆排序" &lt;&lt; endl; random(a); heap_sort(a); return 0;&#125; 文中图片转载自多个博客，这里不贴出来源了，如若侵权，即刻删除，谢谢。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树总结]]></title>
    <url>%2F2018%2F12%2F04%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[今天花时间整理一下二叉树的一切内容下面的部分包括： 二叉树的创建 二叉树的遍历 二叉树的层序遍历 二叉树的深度遍历 二叉树递归先序遍历 二叉树递归中序遍历 二叉树递归后序遍历 二叉树非递归先序遍历 二叉树非递归中序遍历 二叉树非递归后序遍历 线索树 下面直接贴代码（在代码内部进行注释）：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273/************************************************************************* &gt; File Name: tree.cpp &gt; Author: wangshuxiao &gt; Mail: wsx1128@outlook.com &gt; Created Time: 二 11/20 18:51:16 2018 ************************************************************************/#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;string&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;memory&gt;#include &lt;string&gt;using namespace std;class Node&#123;public: Node():left(0),right(0)&#123;&#125;; Node(char e): value(e)&#123;left = 0;right = 0;&#125;;public: char value; Node* left; Node* right;&#125;;class Bi_tree&#123;public: Bi_tree()=default; ~Bi_tree() &#123; clear(); &#125;//由于建树与析构都要使用到递归，所以对于类而言，必须使用另外一个函数来进行递归，才不会影响私有成员 void bulid (); Node* _bulid (Node *); bool isEmpty () const &#123; return root == 0; &#125;; void breath_order() void preorder(Node *t); void inorder(Node *t); void postorder(Node *t); void iter_preorder(); void iter_inorder(); void iter_postorder(); Node * get_root() &#123;return root;&#125;private: void clear(); void clear(Node *); void print(Node *p); Node *root; &#125;;void Bi_tree::clear()&#123; clear(root); root = 0;&#125;void Bi_tree::clear(Node *n)&#123; if (n) &#123; if (n-&gt;left) clear(n-&gt;left); if (n-&gt;right) clear(n-&gt;right); delete n; &#125;&#125;void Bi_tree::print(Node *p)&#123; cout &lt;&lt; p-&gt;value &lt;&lt; " ";&#125;void Bi_tree::bulid()&#123; root = _bulid(root);&#125;//另外这里还是需要注意到的是，由于类的逻辑与C语言的不太相同，所以再循环的时候不能直接返回为空，所以必须要返回一个`Node*`，这样才可以把之前的给联系在一起。//或者还有一种办法是，使用指针的引用，这样也就是所谓的二级指针，才能造成效果。Node * Bi_tree::_bulid(Node *t)&#123; //creat the tree by preorder char ch; cin &gt;&gt; ch; if (ch =='#') t = nullptr ; else&#123; t = new Node; t-&gt;value = ch; t-&gt;left = _bulid(t-&gt;left); t-&gt;right = _bulid(t-&gt;right); &#125; return t;&#125;// 层序遍历void Bi_tree::breath_order()&#123; queue&lt;Node*&gt; q_tree; Node *t = root; if ( t != 0 ) &#123; q_tree.push(t); while (!q_tree.empty()) &#123; t = q_tree.front(); q_tree.pop(); print(t); if (t-&gt;left != 0) q_tree.push(t-&gt;left); if (t-&gt;right != 0) q_tree.push(t-&gt;right); &#125; &#125;&#125;//递归 先序遍历void Bi_tree::preorder(Node *t)&#123; if (t) &#123; print(t); preorder(t-&gt;left); preorder(t-&gt;right); &#125; return ;&#125;//递归 中序遍历void Bi_tree::inorder(Node *t)&#123; if (t) &#123; inorder(t-&gt;left); print(t); inorder(t-&gt;right); &#125; return ;&#125;//递归 后序遍历void Bi_tree::postorder(Node *t)&#123; if (t) &#123; postorder(t-&gt;left); postorder(t-&gt;right); print(t); &#125; return ;&#125;//非递归 先序遍历 使用栈void Bi_tree::iter_preorder()&#123; stack&lt;Node*&gt; s_tree; Node *t = root; if (t != 0) &#123; s_tree.push(t); while (!s_tree.empty()) &#123; t = s_tree.top(); s_tree.pop(); print(t); if (t-&gt;right != 0) &#123; s_tree.push(t-&gt;right); &#125; if (t-&gt;left != 0) &#123; s_tree.push(t-&gt;left); &#125; &#125; &#125; return ;&#125;//非递归 中序遍历 使用栈void Bi_tree::iter_postorder()&#123; stack&lt;Node*&gt; s_tree; Node *p = root , *q = root; while (p != 0) &#123; for ( ;p-&gt;left != 0;p = p-&gt;left) s_tree.push(p); while (p-&gt;right == 0 || p-&gt;right == q) &#123; print(p); q = p; if (s_tree.empty()) return ; p = s_tree.top(); s_tree.pop(); &#125; s_tree.push(p); p = p-&gt;right; &#125;&#125;// 非递归 后序遍历 使用栈void Bi_tree::iter_inorder()&#123; stack &lt;Node*&gt; s_tree; Node *p = root; while (p != 0) &#123; while (p != 0) &#123; if (p-&gt;right) s_tree.push(p-&gt;right); s_tree.push(p); p = p-&gt;left; &#125; p = s_tree.top(); s_tree.pop(); while (!s_tree.empty() &amp;&amp; p-&gt;right == 0) &#123; print (p); p = s_tree.top(); s_tree.pop(); &#125; print(p); if (!s_tree.empty()) &#123; p = s_tree.top(); s_tree.pop(); &#125; else p = 0; &#125; return ;&#125;int main()&#123; Bi_tree b; b.bulid(); if (b.isEmpty()) cout &lt;&lt; "空的" &lt;&lt; endl; cout &lt;&lt; "下面是递归形式的遍历方式"&lt;&lt;endl; cout &lt;&lt; "递归形式先序遍历" &lt;&lt; endl; b.preorder(b.get_root()); cout &lt;&lt;endl; cout &lt;&lt; "递归形式后续遍历" &lt;&lt;endl; b.postorder(b.get_root()); cout &lt;&lt; endl; cout &lt;&lt; " 非递归形式的中序遍历"&lt;&lt; endl; b.iter_inorder(); cout &lt;&lt; endl; cout &lt;&lt; " 非递归形式的后序遍历"&lt;&lt; endl; b.iter_postorder(); cout &lt;&lt; endl; return 0;&#125; 线索树线索二叉树原理通过考察各种二叉链表，不管儿叉树的形态如何，空链域的个数总是多过非空链域的个数。准确的说，n各结点的二叉链表共有2n个链域，非空链域为n-1个，但其中的空链域却有n+1个。因此，提出了一种方法，利用原来的空链域存放指针，指向树中其他结点。这种指针称为线索。 记ptr指向二叉链表中的一个结点，以下是建立线索的规则： 如果ptr-&gt;lchild为空，则存放指向中序遍历序列中该结点的前驱结点。这个结点称为ptr的中序前驱； 如果ptr-&gt;rchild为空，则存放指向中序遍历序列中该结点的后继结点。这个结点称为ptr的中序后继； 显然，在决定lchild是指向左孩子还是前驱，rchild是指向右孩子还是后继，需要一个区分标志的。因此，我们在每个结点再增设两个标志域ltag和rtag，注意ltag和rtag只是区分0或1数字的布尔型变量，其占用内存空间要小于像lchild和rchild的指针变量。 其中： ltag为0时指向该结点的左孩子，为1时指向该结点的前驱； rtag为0时指向该结点的右孩子，为1时指向该结点的后继； 因此对于上图的二叉链表图可以修改为下图的养子。 线索二叉树的代码实现对接下来的例子中，线索二叉树的中序遍历。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>二叉树</tag>
        <tag>遍历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海边的卡夫卡的短书评]]></title>
    <url>%2F2018%2F12%2F02%2F%E6%B5%B7%E8%BE%B9%E7%9A%84%E5%8D%A1%E5%A4%AB%E5%8D%A1%E7%9A%84%E7%9F%AD%E4%B9%A6%E8%AF%84%2F</url>
    <content type="text"><![CDATA[《海边的卡夫卡》这本书以一个悲剧戏剧为蓝本，进行双线构造，相互交织，相互迎合，从而使一个十五岁的少年的成长历程逐渐完善。虽然取自于俄狄浦斯王中杀父奸母的桥段，但是结局导向以及传达出来的意义绝不一样，前者是悲剧式的自我毁灭以及无常命运的慨叹，而后者则是彻彻底底的自我救赎式的成长。不知有多少人曾在那里流血，你本身也会流血，温暖而又鲜红的血。你的双手将会接住它们，那既是你的血，又是别人的血，而沙尘暴偃旗息鼓的时候，你恐怕还不能完全明白自己是如同从中穿过而得以逃生的。甚至它是否过去都无从判断，不过有一点是你一定是非常清楚的，从沙尘暴中逃生的不再是跨入沙尘暴的你。每一个人的成长都是自由的，但同时却也是不可预测的。村上君用一个十五岁少年的成长史告诉我们在命运的妥协与抗争之间还存在救赎和成长。但是如果仅仅写出少年的成长史的话只能算一般小说。但是村上君肯定不会这样落入俗套，于是他巧妙利用第二条故事线，一个十五岁之后丧失一切的老爷爷的奇遇，这位老爷爷拥有着诸多神奇的能力，但是就是无法思考，记不清楚发生在自己身上的一切，甚至是与整个世界脱轨。看似与第一条故事线没有任何关联，实则丝丝入扣，一个十五岁之后拥有无限可能的人生经历和一个十五岁之后一切都是空白的人生经历相对比，更加深了本文成长与救赎的主题。这本书另一个引人注目的地方也就是作者村上春树对成长中最大的敌人的定义：缺乏想象力的狭隘，苛刻，自以为是的命题，空洞的术语，被篡夺的理想，僵化的思想体系，这些才是最可怕的，但是何为正确，何为不正确，这些都是值得深思的话题，但是某种个体的判断失误，在很多情况下事后不是不可能挽回，只要有勇气主动承认错误，都是可以补救。村上春树这本书以一个全新的视角诠释我们在成长之行上必定会遇到的善与恶，以及一步步走向顽强的心路历程，不要畏惧前方有未知的风暴，因为你是世界上最顽强的是19岁的少年。]]></content>
      <tags>
        <tag>书评</tag>
        <tag>村上春树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款05：了解 C++默默编写并调用了哪些函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE05%EF%BC%9A%E4%BA%86%E8%A7%A3%20C%2B%2B%E9%BB%98%E9%BB%98%E7%BC%96%E5%86%99%E5%B9%B6%E8%B0%83%E7%94%A8%E4%BA%86%E5%93%AA%E4%BA%9B%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[几乎每一个 class 都会用一个或多个构造函数，一个析构函数，一个拷贝重载运算符，有些是系统自动生成的合成版本，有些是需要自定义的版本，所以这一条款的目的是为了探寻哪些是需要自己去写，哪一些是需要系统自身合成的。 千万不要写完构造函数或者拷贝构造函数或者是析构函数之后不去定义，那么会造成问题，而且此类问题会造成很多方面上的无法适应问题。 另外这里额外需要注意的是 C++11上增加的移动语义，只有在拥有了拷贝构造函数和拷贝赋值运算符之后，编译器才会自动生成移动构造函数，和移动赋值运算符。 最后这个条款需要注意的就是编译器自动生成的函数具有普遍性，所以就不具有特异性，一些特殊的操作在合成版本上面可能会出现大问题。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于STL里面函数简单的应用]]></title>
    <url>%2F2018%2F12%2F01%2F%E5%85%B3%E4%BA%8ESTL%E9%87%8C%E9%9D%A2%E5%87%BD%E6%95%B0%E7%AE%80%E5%8D%95%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[代码如下：1234567891011121314151617181920212223#include&lt;iostream&gt;#include&lt;set&gt;using namespace std;int main()&#123; int n,t; cin&gt;&gt;n; set&lt;int&gt;s; s.insert(0); for (int i =0;i!=n;i++)&#123; cin&gt;&gt;t; //这道题目的主要做法是记住几个upper_bound 的STL函数 if(t &lt; *s.rbegin()) &#123; s.erase(*(s.upper_bound(t))); &#125; s.insert(t); &#125; cout &lt;&lt; s.size() - 1; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一道有趣的题目——逆波兰计算器]]></title>
    <url>%2F2018%2F12%2F01%2F%E4%B8%80%E9%81%93%E6%9C%89%E8%B6%A3%E7%9A%84%E9%A2%98%E7%9B%AE%E2%80%94%E2%80%94%E9%80%86%E6%B3%A2%E5%85%B0%E8%AE%A1%E7%AE%97%E5%99%A8%2F</url>
    <content type="text"><![CDATA[题解首先这道题毫无疑问是要用到stringstream流的。分别依次读取字符串，并且将其导入到char型的代码中去。比如说a+b可以变成ab+，这里最好运用到栈的知识，来控制出栈与进栈。==注意以下几个地方== 注意输入cin&gt;&gt;t以后，需要用getchar()来清空上一个步骤留下来的回车符号 注意此处需要严格进行判断栈内是否为空。 这里是将乘除求模的运算放在最右边，这样就可以有优先级存在了 括号会提前进行一步运算，然后消除掉左括号，或者左边的所有运算式，进行一个结算。 map这里存在的意义就在于 为判断进行提供条件。 此道题目涉及字符串，栈，模拟的相应算法，需要有空的时候可以多看看。 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;algorithm&gt;#include&lt;stack&gt;#include&lt;sstream&gt;#include&lt;map&gt;using namespace std;stack&lt;char&gt;ope;stack&lt;int&gt;num;string str;map&lt;char,int&gt;m;void init()&#123; m['+']=m['-']=1; m['*']=m['/']=m['%']=m['(']=m[')']=2; while(!num.empty()) num.pop(); while(!ope.empty()) ope.pop();&#125;//此处为基本的运算规模。void op1(int &amp;a,int &amp;b,const char &amp;c)&#123; if (c =='+') a += b; else if (c == '-') a=b-a; else if (c == '*') a*=b; else if (c == '/') a=b/a; else if (c == '%') a=b%a;&#125;//此处就是控制出栈的运算，一般就是括号内部的计算了。算出每一个括号内部的运算式。void op2()&#123; char ch = ope.top(); while (ch != '('&amp;&amp;!ope.empty())&#123; ope.pop(); int a = num.top(); num.pop(); int b = num.top(); num.pop(); op1(a,b,ch); num.push(a); if (!ope.empty()) ch = ope.top(); &#125;//这个下面要注意的判断条件中一定要加上判断是否为空。 if (!ope.empty()&amp;&amp;ope.top() =='(') ope.pop();&#125;int main()&#123; int t; cin&gt;&gt;t; getchar(); while (t--)&#123; getline(cin,str); stringstream s(str); init(); char tmp; while (s&gt;&gt;tmp)&#123; if(tmp&gt;='0'&amp;&amp;tmp&lt;='9')&#123; int x = 0; do&#123; if (m[tmp]) break; x *= 10; x += tmp - '0';//此处是将char转换成int &#125;while(s&gt;&gt;tmp); num.push(x); &#125; //注意这个地方的高明之处就在于碰见‘）’的返回，以及判断有没有‘（’， 比如连加的情况就把加减乘除的优先运算级给表示出来了。 //最后相当于将运算优先级高的全部放到了右边，然后有括号的就先解决括号， 及时左括号被提前弄没了也不要紧，存在有右括号就行，然后乘除永远放在加减的左边。 if (tmp==')') op2(); else if (m[tmp]==1)&#123; if (!ope.empty()&amp;&amp;ope.top()!='(') op2(); ope.push(tmp); &#125; else if (m[tmp]) ope.push(tmp); &#125; int ans = num.top(); num.pop(); while (!num.empty()&amp;&amp;!ope.empty())&#123; op1(ans,num.top(),ope.top()); ope.pop(); num.pop(); &#125; cout &lt;&lt; ans &lt;&lt; endl; &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于模拟与搜索的相应简单题目]]></title>
    <url>%2F2018%2F12%2F01%2F%E5%85%B3%E4%BA%8E%E6%A8%A1%E6%8B%9F%E4%B8%8E%E6%90%9C%E7%B4%A2%E7%9A%84%E7%9B%B8%E5%BA%94%E7%AE%80%E5%8D%95%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[题目 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;algorithm&gt;#include&lt;cmath&gt;using namespace std;int main()&#123; string w,v; int x,y,m; char ch; while(cin&gt;&gt;w&gt;&gt;v)&#123; string s; int flag=0; reverse(w.begin(),w.end()); reverse(v.begin(),v.end()); if (w.size()&gt;v.size())&#123; m=w.size()-v.size(); for (int i=0;i!=v.size();i++)&#123; x=w[i]-'0'; y=v[i]-'0'; x+=y; if (flag)&#123; flag=0; x++; &#125; if (x&gt;=10)&#123; flag=1; x=x-10; &#125; ch=x+'0'; s.push_back(ch); &#125; int i=v.size(); while (flag==1&amp;&amp;i&lt;=m)&#123; flag=0; x=w[i]-'0'; x++; if (x&gt;=10)&#123; flag=1; x=x-10; &#125; ch=x+'0'; s.push_back(ch); i++; &#125; if (flag&amp;&amp;i==w.size())&#123; s.push_back('1'); &#125; &#125; else &#123; m=v.size()-w.size(); for (int i=0;i!=w.size();i++)&#123; x=w[i]-'0'; y=v[i]-'0'; x+=y; if (flag)&#123; flag=0; x++; &#125; if (x&gt;=10)&#123; flag=1; x=x-10; &#125; ch=x+'0'; s.push_back(ch); &#125; int i=w.size(); while (flag&amp;&amp;i&lt;=m)&#123; flag=0; x=w[i]-'0'; x++; if (x&gt;=10)&#123; flag=1; x=x-10; &#125; ch=x+'0'; s.push_back(ch); i++; &#125; if (flag&amp;&amp;i==v.size())&#123; s.push_back('1'); &#125; &#125; reverse(s.begin(),s.end()); cout&lt;&lt;s&lt;&lt;endl; &#125;&#125; 题解：其实这道题目属于一道相应简单的题目，就是要注意相应string与char之间的区别就行了。另外 int转换char是加上‘0’char转换int是减去‘0’。 一道简单的dfs的题目 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;vector&gt;using namespace std;const int maxn = 105;char h[maxn][maxn];int n,m,cnt=0;void dfs(int i,int j)&#123; if (i&lt;0||i&gt;=n||h[i][j]!='W') return ; if (j&lt;0||j&gt;=m||h[i][j]!='W') return ; if (h[i][j]=='W')&#123; h[i][j]='.'; dfs(i-1,j); dfs(i-1,j-1); dfs(i+1,j); dfs(i+1,j+1); dfs(i,j-1); dfs(i-1,j+1); dfs(i,j+1); dfs(i+1,j-1); &#125;&#125;int main()&#123; int ans=0; while(cin&gt;&gt;n&gt;&gt;m&amp;&amp;(n!=0&amp;&amp;m!=0))&#123; for (int i=0;i!=n;i++) for (int j=0;j!=m;j++)&#123; cin&gt;&gt;h[i][j]; &#125; for (int i=0;i!=n;i++)&#123; for (int j=0;j!=m;j++)&#123; if (h[i][j]=='W')&#123; dfs(i,j); ans++; &#125; &#125; &#125; cout&lt;&lt;ans&lt;&lt;endl; ans=0; &#125; return 0;&#125; 题解简单的dfs搜索出每一种情况，然后让其返回就行了。 一道经典的BFS的题目题目 代码如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include&lt;stdio.h&gt;#include&lt;queue&gt;using namespace std;int fxy[4][2]=&#123;&#123;1,0&#125;,&#123;-1,0&#125;,&#123;0,1&#125;,&#123;0,-1&#125;&#125;;//朝着四个方向char dis[101][101];int kp[101][101];//以下的node就作为每一次前进的节点struct node&#123; int x,y,cnt; node(int a=0,int b=0,int c=0)&#123; x=a; y=b; cnt=c; &#125;&#125;;int main()&#123; int m,n,k,g,k1,g1; while(~scanf("%d %d",&amp;m,&amp;n)) &#123; for(int i=0;i&lt;m;i++) &#123; scanf("%s",dis[i]); &#125; // 用队列整合的思想来完成 queue&lt;struct node&gt;q; for(int i=0;i&lt;m;i++) for(int j=0;j&lt;n;j++)&#123; kp[i][j]=-1; &#125; // 两种初始化过程，并且找到起点与终点的所在位置 for(int i=0;i&lt;m;i++) for(int j=0;j&lt;n;j++)&#123; if(dis[i][j]=='S')&#123; k=i; g=j; &#125; if(dis[i][j]=='E')&#123; k1=i; g1=j; &#125; &#125; // 将起点存进去 node a(k,g,0); q.push(a); // 下面就是为bfs的相应搜索 while(!q.empty())&#123; struct node now=q.front(); q.pop(); kp[now.x][now.y]=now.cnt; // 将起点走了多少步数以及起点的坐标点存入到题目中去 for(int i=0;i&lt;4;i++)&#123; node next; next.x=now.x+fxy[i][0]; next.y=now.y+fxy[i][1]; // 判断走的下一步有没有出界，或者使下一步走的不会碰到路障 if(next.x&gt;=0&amp;&amp;next.x&lt;m&amp;&amp;next.y&gt;=0&amp;&amp;next.y&lt;n&amp;&amp;dis[next.x][next.y]!='#'&amp;&amp;kp[next.x][next.y]==-1)&#123; node empt(next.x,next.y,now.cnt+1); q.push(empt); &#125; &#125; &#125; if(kp[k1][g1]==-1) printf("Trapped!\n"); else printf("Escaped in %d minute(s).\n",kp[k1][g1]); &#125; return 0;&#125; 记住上面相应的队列思想。 一道DFS与BFS的综合题==需要多花时间来温习一遍== 题目 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112#include&lt;iostream&gt;#include&lt;queue&gt;#include&lt;algorithm&gt;using namespace std;int n,m,k,cnt = 0;int x_begin,x_end,y_begin,y_end;const int maxn = 1005;int dis[maxn][maxn];char ch[maxn][maxn];class Position&#123;public: int x; int y; int distance; public: Position() = default; Position(int a, int b, int c):x(a),y(b),distance(c)&#123;&#125;; Position move(int i);&#125;;Position Position::move(int i)&#123; Position post = *this; if (i == 0) post.x = this -&gt; x + 1; else if (i == 1) post.x = this -&gt; x - 1; else if (i == 2) post.y = this -&gt; y + 1; else if (i == 3) post.y = this -&gt; y - 1; return post;&#125;void bfs()&#123; queue&lt;Position&gt;q_dis; Position p_begin (x_begin,y_begin,0); q_dis.push(p_begin); while(!q_dis.empty())&#123; Position now = q_dis.front(); q_dis.pop(); dis[now.x][now.y]=now.distance; for(int i = 0; i != 4; i++)&#123; Position next; next = now.move(i); if (next.x &gt;= 0 &amp;&amp; next.x &lt; n &amp;&amp; next.y &gt;= 0 &amp;&amp; next.y &lt; m &amp;&amp; dis[next.x][next.y] == -1 &amp;&amp; ch[next.x][next.y] != '#')&#123; Position empt (next.x,next.y,now.distance + 1); q_dis.push(empt); &#125; &#125; &#125;&#125;void dfs(int x,int y)&#123; if (x &lt; 0 || x &gt;= n || y &lt; 0 || y &gt;= m) return ; if (ch[x][y]=='L') &#123; cnt++; return; &#125; if (dis[x][y] == -1) return; // 前面已经有dis可以表示每一步走的距离，所以只需要一步一步来看，这样的做法便可以完全规避障碍物，单单从路径上面考虑。 if (dis[x][y]==dis[x+1][y]+1) dfs(x+1,y); if (dis[x][y]==dis[x-1][y]+1) dfs(x-1,y); if (dis[x][y]==dis[x][y+1]+1) dfs(x,y+1); if (dis[x][y]==dis[x][y-1]+1) dfs(x,y-1);&#125;int main()&#123; int T,Case = 0; cin&gt;&gt;T; while(T--)&#123; Case++; cin&gt;&gt;n&gt;&gt;m&gt;&gt;k; bool f_begin = false,f_end = false; for (int i = 0; i != n; i++)&#123; for (int j = 0; j != m; j++)&#123; cin &gt;&gt; ch[i][j]; dis[i][j] = -1; &#125; &#125; for (int i = 0; i != n; i++)&#123; for (int j = 0; j != m; j++)&#123; if (f_end &amp;&amp; f_begin) break; if (ch[i][j] == 'L')&#123; x_begin = i; y_begin = j; f_begin = true; &#125; if (ch[i][j] == 'C')&#123; x_end = i; y_end = j; f_end = true; &#125; &#125; &#125; bfs(); if (dis[x_end][y_end] == -1 ||dis[x_end][y_end] &gt; k ) cout &lt;&lt; "Case #"&lt;&lt;Case&lt;&lt;": "&lt;&lt;-1&lt;&lt;endl; else&#123; dfs(x_end,y_end); cout&lt;&lt;"Case #"&lt;&lt;Case&lt;&lt;": "&lt;&lt;dis[x_end][y_end]&lt;&lt;" "&lt;&lt;cnt&lt;&lt;endl; cnt = 0; &#125; &#125; return 0;&#125; 这里注明一下关于==默认实参==的知识点，因为在这个地方可以直接对类的构造函数赋值一个默认实参，可以避免输入默认构造函数了。 下面则是一道DFS的题目，这道题目看上去可以用bfs来做 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;using namespace std;const int maxn = 100;int road[maxn][maxn];int dp[maxn][maxn];int n, m;int dfs (int i,int j)&#123; if (dp[i][j] != -1) return dp[i][j]; int Max = 0; if (i-1&gt;=0 &amp;&amp; road[i][j]&gt;road[i-1][j]&amp;&amp;Max&lt;dfs(i-1,j)) Max = dfs(i-1,j); if(i+1&lt;n &amp;&amp; road[i][j]&gt;road[i+1][j]&amp;&amp;Max&lt;dfs(i+1,j)) Max=dfs(i+1,j); if(j-1&gt;=0 &amp;&amp; road[i][j]&gt;road[i][j-1]&amp;&amp;Max&lt;dfs(i,j-1)) Max=dfs(i,j-1); if(j+1&lt;m &amp;&amp; road[i][j]&gt;road[i][j+1]&amp;&amp;Max&lt;dfs(i,j+1)) Max=dfs(i,j+1); return dp[i][j]=Max+1;&#125;int main()&#123; while (cin &gt;&gt; n &gt;&gt; m) &#123; for (int i = 0; i != n; i++) &#123; for (int j = 0; j != m; j++) &#123; cin &gt;&gt; road[i][j]; dp[i][j] = -1; &#125; &#125; int MAX = -1; for (int i = 0; i != n; i++) &#123; for (int j = 0; j != m; j++) &#123; MAX = max (dfs(i,j),MAX); &#125; &#125; cout &lt;&lt; MAX &lt;&lt; endl; &#125; return 0;&#125; 题解 此题其实最重要的就在于这个题目不同于其他题目，这个题目找的是最长路径，还不是最短路径，一般来说，BFS找的是最短路径，DFS找的是最短路径的条数。而这里就是利用dfs的返回值（每走一步的最大值，意思就是从各个角度上）记录在dp中，将每一个位置都走到不能走为止，然后存储在dp中，最后找最大值的DP即可。不过自己可以试试遍历的其他方法。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>模拟与搜索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构相应总结]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9B%B8%E5%BA%94%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[栈 栈的概念此处只需要记住栈的思想最重要的就是先进后出思想，也就是最先进去的最后出来。 两种方法表示这种栈的实现 第一种则是 直接用c语言实现，采用一个一维数组来存储栈，用两个指针一个指向栈顶，另一个指向栈底。用top=bottom作为栈空的标记或者说是栈遍历完毕的标记。 第二种就是直接用C++里面STL模板首先先定义一个stack&lt;int&gt; s 然后以下就是其的操作。 注意其不能使用push_back只能使用push 1234s.pop() 删除栈顶元素，也就是出栈的作，把刚刚进来的元素出栈,不返回元素值。s.push() 创建一个新元素压入栈顶，可以通过拷贝，移动，甚至是构造而来。s.top() 返回栈顶的元素，也就是刚刚进来的元素。s.bottom() 返回栈底的元素，也就是最后一个元素 队列适配器队列这里分为两种一种是普通队列，还有一种是特殊排列好的优先队列，但是这二者的区别就在于，虽然都符合先进先出的思想，但是前者是不加任何排序的先进先出，而后者就是让代码编辑者自己定义一种排序方式，然后通过这种排序方式，再来出队操作。 与上面一样，先定义一个queue&lt;int&gt; q与priority_queue&lt;int&gt; q。 1234567q.pop() 按照先进先出的思想，删除首元素或者优先级最高的元素q.front() 返回首元素。q.back() 返回尾元素。以上两个是只适用于队列。q.top() 返回优先队列中优先级最高的元素。q.push()q.emplace() 加入元素到队尾，或者优先队列中一个恰当的位置，要么构造，要么拷贝。 这里需要提一下==优先队列的构造方法==以及==优先队列的特殊排序==应该怎么构造 123456789下面两种优先队列的定义是等价的priority_queue&lt;int&gt; q;priority_queue&lt;int,vector&lt;int&gt;,less&lt;int&gt; &gt;;//后面有一个空格默认都是从小到大排序接受三个参数，第一个参数为数据类型，第二个参数为承载容器的类型，第三个就是自定义的比较函数了。可以使lamda匿名函数，也可以是function头文件里面的函数模板。 链表特点：自定义，不连续的。同时链表也是后面相应树形结构的基础实际上就是把每一个不连续的内存空间连在一起，可以认为的控制进程这个需要自己改天把链表的遍历，删除，增加自己再写一遍，因为不是什么新东西，所以这里就不多说了 动态数组这里就是vector 存在的意义了 vector里面重要的概念 容量，长度。 树与二叉树一般的树 以上就是一般树的形态。下面则是关于树的基本用语。关于上面重要的概念就是结点和结点的度了。 二叉树二叉树的定义: 二叉树有五种基本形态： 二叉树的性质:上面所写到的==至多==都是由于将其当成了满二叉树来进行计算的。 满二叉树与完全二叉树前者全部都有子节点，后者基于深度为k的基础上，编号从1到n的结点一一对应。完全二叉树是满二叉树的一部分，而满二叉树是完全二叉树的特例。 二叉树的存储结构： 数组存储： 二叉链式存储（原理类似链表）：将链表内部的*next，变成了指向两边的子节点的指针。 三叉链式存储：比二叉链式结构多了一个回指向父节点的指针。 遍历二叉树的方法 先序遍历（根-&gt;左-&gt;右）： 代码: 12345678void PreOrderTraverse(BiTree *T)&#123; if(T != NULL)&#123; printf("%c", T-&gt;data); PreOrderTraverse(T-&gt;lchild); PreOrderTraverse(T-&gt;rchild); &#125;&#125; 图示： 最终结果就是==ABDGHCEIF==。 中序遍历（左-&gt;根-&gt;右)： 若二叉树为空，则空操作返回，否则从根节点开始（注意不是先访问根节点），中序遍历根节点的左子树，然后是访问根节点，最后中序遍历右子树。 代码： 12345678void InOrderTraverse(BiTree T)&#123; if(T != NULL)&#123; PreOrderTraverse(T-&gt;lchild); printf("%c", T-&gt;data); PreOrderTraverse(T-&gt;rchild); &#125;&#125; 最终结果为==GDHBAEICF==。 后序遍历（左-&gt;右-&gt;根） 若二叉树为空，则空操作返回，否则从根节点开始（注意不是先访问根节点），中序遍历根节点的左子树，然后是访问根节点，最后中序遍历右子树。 代码： 12345678void PostOrderTraverse(BiTree T)&#123; if(T != NULL)&#123; PreOrderTraverse(T-&gt;lchild); PreOrderTraverse(T-&gt;rchild); printf("%c", T-&gt;data); &#125;&#125; 最终结果为==GHDBIEFCA==。 关于二叉树的建立代码：代码我等下自己写出来。 图图的定义 图结构：是研究数据元素之间的多对多的关系。在这种结构中，任意两个元素之间可能存在关系。即结点之间的关系可以是任意的，图中任意元素之间都可能相关。 图的专业术语： 图-生成树 邻接矩阵的表示方法（数组）不带权值的表示方法 一般就是用二维数组来表示每一个结点之间的关系 关于图的遍历就最好用一个bool 类型的同二维数组 然后通过这个来标记哪些是否已经被遍历过得。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数论基础第一节]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%95%B0%E8%AE%BA%E5%9F%BA%E7%A1%80%E7%AC%AC%E4%B8%80%E8%8A%82%2F</url>
    <content type="text"><![CDATA[初等数论是用初等方法研究的数论，它的研究方法本质上说，就是利用整数环的整除性质，主要包括整除理论、同余理论、连分数理论。 整除问题引申到同余问题 同余的性质 可以换算成以下式子：a=c(modb) 这里c为余数，而b为除数 同余的性质 自反性 a=a mod m 对称性 a=b mod m 等价于 b=a mod m 传递性 a=b mod m 与 b=c mod m 等价于 a=c mod m 线性合成 a=b mod m 与 c= mod m 等价于 a±c=b±d mod m 与 ac= bd mod m 消去公因子 ac=bc mod m &amp;&amp; gcd(c,m)=1 等价于 a=b mod m 素数筛 朴素筛 一般就是循环2~√n次 埃拉托斯特尼筛 循环次数 欧拉筛 相应代码如下：12 最大公约数以及最小公倍数 最大公约数 函数_gcd(a,b)而多个数的最大公约数 就是 _gcd(a,b,c)=_gcd(gcd(a,b),c) 最小公倍数_lcm(a,b)=ab/_gcd(a,b) 扩展欧几里得 关于求解线性同余方程 关于求逆元 关于快速幂 费马小定理 另外 欧拉函数 欧拉函数定义 欧拉函数性质 求值公式 上述公式 可以用来： 求逆元 欧拉降幂公式 数论函数 中国剩余定理 解法]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>acm</tag>
        <tag>数论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于组合数学，两道思维题目，这里贴两道题目]]></title>
    <url>%2F2018%2F12%2F01%2F%E5%85%B3%E4%BA%8E%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6%EF%BC%8C%E4%B8%A4%E9%81%93%E6%80%9D%E7%BB%B4%E9%A2%98%E7%9B%AE%EF%BC%8C%E8%BF%99%E9%87%8C%E8%B4%B4%E4%B8%A4%E9%81%93%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[第一道 简单的排列组合： 题解如下： 题目大致可以理解为4堆牌a,b,c,d，每次从一堆牌里拿出牌顶的一张牌，问共有多少种拿法。其实我们可以一堆一堆的分析，假设只有一堆a时只有1种拿法，那两堆a,b时我们可以认为是从a个牌中插入b张牌，用数学表达式就是==C(b,a+b)==;那么三堆的话我们可以把前两堆看成一堆，那么表达式就是==C(c,a+b+c)==，这是我们需要与前两堆的组成方法相乘，就是==C(b,a+b)C(c,a+b+c)==。4堆的话就是==C(b,a+b)C(c,a+b+c)C(d,a+b+c+d)==。所以答案就是==C(a,a)C(b,a+b)C(c,a+b+c)C(d,a+b+c+d)==。此外，有一公式==C(a,b)=C(a,b-1)+C(a-1,b-1)==，所以我们用数组来代替C(m,n)操作 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int maxn = 501;const long long mod = 1000000007;long long a[4],sum[4]=&#123;0&#125;;//此处用到记忆化搜索，动态规划。long long dp[maxn*4][maxn*4];void init()&#123; dp[0][0]=0; for (int i=1;i!=4*maxn;i++)&#123; dp[i][0]=1; //根据表格来看的确是每一行的第一个是1 for (int j=1;j&lt;i;j++)&#123; //这个地方就是状态转移方程 //C(a,b)=C(a,b-1)+C(a-1,b-1)根据公式来做的 dp[i][j]=dp[i-1][j]+dp[i-1][j-1]; //dp[i][j]=dp[i][j]%mod; &#125; dp[i][i]=1; &#125;&#125;int main()&#123; int t; cin&gt;&gt;t; while (t--)&#123; init();//这个地方就开始初始化表格了。 long long ans =1; for (int i = 0; i&lt;4;i++)&#123; if (!i) sum[i]=0; else sum[i]=sum[i-1]; cin&gt;&gt;a[i]; sum[i] += a[i]; if (a[i] &gt; sum[i]-a[i]) a[i]=sum[i]-a[i]; &#125; for (int i = 1 ; i != 4; i++)&#123; ans *= dp[sum[i]][a[i]]; //ans %=mod; &#125; cout&lt;&lt;ans&lt;&lt;endl; &#125; return 0;&#125; 第二题 第一题的变式： 题解如上，与上面一题有区别的地方就在于要有一个取模的操作 代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int maxn = 501;const long long mod = 1000000007;long long a[4],sum[4]=&#123;0&#125;;//此处用到记忆化搜索，动态规划。long long dp[maxn*4][maxn*4];void init()&#123; dp[0][0]=0; for (int i=1;i!=4*maxn;i++)&#123; dp[i][0]=1; //根据表格来看的确是每一行的第一个是1 for (int j=1;j&lt;i;j++)&#123; //这个地方就是状态转移方程 //C(a,b)=C(a,b-1)+C(a-1,b-1)根据公式来做的 dp[i][j]=dp[i-1][j]+dp[i-1][j-1]; dp[i][j]=dp[i][j]%mod; &#125; dp[i][i]=1; &#125;&#125;int main()&#123; int t; cin&gt;&gt;t; while (t--)&#123; init();//这个地方就开始初始化表格了。 long long ans =1; for (int i = 0; i&lt;4;i++)&#123; if (!i) sum[i]=0; else sum[i]=sum[i-1]; cin&gt;&gt;a[i]; sum[i] += a[i]; if (a[i] &gt; sum[i]-a[i]) a[i]=sum[i]-a[i]; &#125; for (int i = 1 ; i != 4; i++)&#123; ans *= dp[sum[i]][a[i]]; ans %=mod; &#125; cout&lt;&lt;ans&lt;&lt;endl; &#125; return 0;&#125; ==以后学到后面再花时间来深究==]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>组合数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法]]></title>
    <url>%2F2018%2F12%2F01%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[贪心算法定义贪心算法的本质目的也就在于对于一个问题来看，我可以用最简单的办法算出局部的解集，并且按照这个最简单的办法同样可以算出该问题的最终解决办法，即贪心算法。 三个经典的贪心算法问题 事件的序列问题： 遇到这样的题目，首先就是要想着能不能找到最长的子序列的前提，到底是按节目的开始时间进行排序，还是按照节目的结束时间进行排序。下面就是核心代码12345678910111213141516171819202122232425262728293031#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int maxn = 100+5;struct Show&#123; int beg; int en;&#125;show[maxn];int main()&#123; int n; while (cin&gt;&gt;n&amp;&amp;n!=0)&#123; for (int i=0;i!=n;i++)&#123; cin&gt;&gt;show[i].beg&gt;&gt;show[i].en; &#125; stable_sort(show,show+n, [](const Show &amp;a, const Show &amp;b)&#123;return a.en&lt;b.en;&#125;); int cnt=1; for (int i=1,j=0;i&lt;n;i++)&#123; if (show[i].beg&gt;=show[j].en)&#123; cnt++; j=i; &#125; &#125; cout&lt;&lt;cnt&lt;&lt;endl; &#125;&#125; 此处的关键就是从第一个开始把结束时间最早的进行一个相对位置的排序，然后把第一个结束的与后面开始的时间进行挨个挨个的比较，最终得出的结果就是在这里。 区间覆盖问题下面就是这道题目的核心代码：123456789int greedy(vector&lt;int&gt; x,int k)&#123; int i,sum = 1,n=x.size(); sort(x.begin(),x.end()); int temp = x[0]; //区间的起始位置 for(i=1;i &lt; n; ++i) if(x[i] - temp &gt; k) &#123;sum++,temp=x[i]&#125;; return sum;&#125; 题目这里就是分别计数，用一个最简单的思维做出一整道题目的思路。 区间相交问题：其实就是跟第一道题目类似 算连续的序列 并且把总长度减去这些连续的序列之后得到的是剩余的区间，即得到题目答案。 ==以后若还有关于贪心类型的题目可以继续往上面加== 一下就是贪心的习题]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>贪心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款27：尽量少做转型动作]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE27%EF%BC%9A%E5%B0%BD%E9%87%8F%E5%B0%91%E5%81%9A%E8%BD%AC%E5%9E%8B%E5%8A%A8%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[C++ 规则的设计目标之一就是，保证“类型错误” 绝不可能发生，但是在 C++的某些特殊的情形下面不得不去使用转型这一特性，而 C 语言的转型语句则类似于以下： 然而 C++提供四种新式的类型转换 注意 在真正进行类型转换的时候，我们不能仅仅认为编译器到最后仅仅只是更改一个文件名字，编译器改变的底层的编码，比如 int 转型到 double 之间底层描述是不一样的。 另外 C++中的一个特性使得多重继承的时候，一个对象含有多个地址。 所以需要注意的是以下几点，如果可以的话，尽量避免转型，特别是在注重代码中避免dynamic_cast. 如果有设计需要转型动作的话，去试试无需转型的替代设计。 如果转型是必要的，那么试着将其隐藏在某个函数背后。客户随后可以调用该函数，而不需要讲转型放进他们自己的代码中。 宁可使用 C++新式的转型，也不要使用旧式的转型，前者很容易识别出来，而且也有着不叫分们别类的职掌。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一道STL的题解题目，需要以后花时间理解题目意思]]></title>
    <url>%2F2018%2F12%2F01%2F%E4%B8%80%E9%81%93STL%E7%9A%84%E9%A2%98%E8%A7%A3%E9%A2%98%E7%9B%AE%EF%BC%8C%E9%9C%80%E8%A6%81%E4%BB%A5%E5%90%8E%E8%8A%B1%E6%97%B6%E9%97%B4%E7%90%86%E8%A7%A3%E9%A2%98%E7%9B%AE%E6%84%8F%E6%80%9D%2F</url>
    <content type="text"><![CDATA[代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include&lt;iostream&gt;#include&lt;set&gt;#include&lt;algorithm&gt;#include&lt;queue&gt;//#include&lt;function&gt;#define ll long longusing namespace std;const int fort = 1314;ll a[6];//这道题目就换一种思考方式，让基数分贝加上加数，这样一来，就会简化很多步骤int main()&#123; int t; cin&gt;&gt;t; while(t--)&#123; cin&gt;&gt;a[0]&gt;&gt;a[1]&gt;&gt;a[2]; a[3] = 5; a[4] = 2; a[5] = 0; sort(a, a + 6, [](const ll &amp;a,const ll &amp;b)&#123;return a&gt;b;&#125;); priority_queue&lt;ll, vector&lt;ll&gt;, greater&lt;ll&gt; &gt; pq; set&lt;ll&gt;s; set&lt;ll&gt;ans; pq.push(1); s.insert(1); for(int i = 0;;i++)&#123; ll x = pq.top(); pq.pop(); if(i)&#123; for(int k = 3;k &lt; 6;k++)&#123; ans.insert(x - a[k]); if(ans.size()==fort) break; &#125; if(ans.size()==fort)&#123; /*int ttt = 1; for(set&lt;ll&gt;::iterator it = ans.begin();it!=ans.end();it++) cout&lt;&lt;ttt++&lt;&lt;' '&lt;&lt;*it&lt;&lt;endl;*/ auto it = ans.rbegin(); cout&lt;&lt;*it&lt;&lt;endl; break; &#125; &#125; for(int j = 0;j&lt;3;j++)&#123; ll x2=x*a[j]; if(!s.count(x2))&#123; s.insert(x2); pq.push(x2); &#125; &#125; &#125; &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款25：考虑写出一个不抛异常的swap函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE25%EF%BC%9A%E8%80%83%E8%99%91%E5%86%99%E5%87%BA%E4%B8%80%E4%B8%AA%E4%B8%8D%E6%8A%9B%E5%BC%82%E5%B8%B8%E7%9A%84swap%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[所谓 swap 两对象值，意思就是将两个对象的值彼此赋予对方，缺省的情况下 swap 的动作可以由标准库程序提供的 swap来完成。 其中有一个最主要的方法就是，以指针指向一个对象，内含真正的数据“ 即”pimpl 手法”所以一般对于一个对象而言，直接交换里面的指针对象即可。就如同以下的写法： 以上就是该对象的特化版本。这同时也是一个模板类的偏特化的例子。 如果想特化一个函数模板的话，通常的做法就是添加一个重载版本。 但是这种特化存在问题： 我们可以全特化 std 内的模板，但是不可以添加新的模板到 std 里面去，因为 std 的内容完全由 C++标准委员会决定的。 有的时候不能直接访问私有成员，因为封装层面的相关权限缺失。 解决的办法很简单，声明一个非成员版本的 swap 函数，然后让他调用其的成员函数，而不是将那个不是成员函数的 swap 声明为 std：：中的特化版本或者是重载版本。下面就是相关步骤： 提供一个 public swap 成员函数，让它高效地置换你的类型的两个对象（注意这个地方时高效的置换），但是这个函数不应该抛出异常。 在你的类或者模板所在的命名空间内，提供一个非成员函数的 swap，并且另其调用 swap 成员函数。 如果你正在编写一个 class 而不是一个模板类的时候，为你的类特化std：：swap。并令其调用你的 swap 成员函数。 最后，在调用奇函数的时候，请确定包含一个 using 生命是，以便于让 std：：swap 在你的函数内曝光可见，直接赤裸裸的调用 swap。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款04：确定对象被使用前已先被初始化]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE04%EF%BC%9A%E7%A1%AE%E5%AE%9A%E5%AF%B9%E8%B1%A1%E8%A2%AB%E4%BD%BF%E7%94%A8%E5%89%8D%E5%B7%B2%E5%85%88%E8%A2%AB%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[在 C 语言中对象的初始化可能会变得异常容易，但是在 C++中某些语境下进行对象可能不会存在自动的初始化过程，也许会在使用 C part of C++ 会自动有一个初始化过程，但是在其他部分下面的 C++就不能保证初始化过程了。 特别是在类的过程中，初始化的过程一般直接交给构造函数，初始化的过程并不等同于赋值，所以在写类的构造函数的时候，尽量不要在函数体里面写赋值给私有成员的语句，可以直接在列表上面直接写初始化的。 对于拥有多个构造函数，且每个构造函数具有自己的成员初值列，如果这些类存在许多成员变量或者基类的话，多种成员初始列表就会导致不受欢迎的重复，那么这个时候可以遗漏一些“赋值跟初始化过程差不读的成员变量”，改用他们的赋值操作，并且把这些操作放置在 private 中。 C++有着十分固定的成员初始化过程，基类的初始化会早于派生类，而类的成员变量总是以其声明的次序被初始化。 关于类的静态成员的初始化 一般在类内部进行声明，然后再类的外部进行定义，赋值，其的声明周期一般是从程序开始到程序结束。 构造函数初始化的次序非常重要，举个例子就是初始化的时候必须要为数组指定大小，所以指定大小的变量必须具有先值 对于不同人在不同时间下不同的源码文件建立起来，其的初始化相对次序并没有明确定义，所以解决办法就是将一个对象搬到自己的专属函数里面去，然后声明成静态成员，并且返回一个引用即可，后面用户直接调用这些函数，就可以无视初始化的次序问题了。具体可以看书里面P32面的相关代码。 最后总结一句为了免除“跨编译单元之初始化次序”问题，一般用 local static 对象替换 non-local static 对象。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL的简单总结]]></title>
    <url>%2F2018%2F12%2F01%2FSTL%E7%9A%84%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[补一个加快C++输入输出速度的方法： 花上一天的时间来总结 C++ primer 里面的算法以及容器这一章，多余的用法可以上网去查找当做是相应的扩展。 字符串 string与字符数组 构造string的方法 操作string的方法 上面的成员函数有的说要返回，同时，有的也存在不返回值。 搜索string的方法 以上就是find函数的一些用法，在泛型算法一章，还会继续涉及到。题目返回的是下标 补充一下关于string中的比较函数一般在string中可以直接用运算符进行比较 int与string之间的转化 getline()的两种写法注意在cin&gt;&gt;t;必须要一个getchar()来吞掉其前面的回车符号。之后才能用getline()。 顺序容器 容器种类 vector&lt;vector&lt;int&gt; &gt;来表示二维数组。 容器基础操作补充一个assign的用法：允许从一个不同但相容的类型里面去赋值，或者从容器的一个子序列赋值。 还有第二个版本：接受一个整型值和一个元素值，用指定数目且具有相同给定元素替换容器中原有的元素： 再补充一个resize的用法： 需要记住有一些类型声明可以直接用auto。 初始化有两种一种直接初始化和拷贝初始化。 顺序容器添加元素上面已经列出了各种形式的插入。插入是在迭代器指向的元素之前插入。插入想要插入的元素前面，比如说push_back是插入到了尾后迭代器的前面。而返回的是新添加的第一个元素的迭代器，同样也可也==不返回==。 这里要注意的是push_front会改变整个容器的迭代器指向，而push_back不会。 访问元素 链表，单向链表，栈，队列都不支持随机访问，也就不支持下标访问了。 删除元素 删除的是迭代器指向的元素，返回的是删除元素的后迭代器也就是被删除的元素下一个元素的前面的迭代器，同样也可以不返回。 这里需要注意的就是删除一个元素之后，必定会改变原容器中迭代器的指向，所以务必小心（除了pop_back） 改变容器大小的操作 特殊的forward_list（单向链表） 由于迭代器的添加删除操作都涉及到了首前和尾后，所以对于单向链表来说这里添加了一个首前迭代器before_begin而对于单向链表的插入而言 是在元素的后面进行插入，删除也是一样，指向都是迭代器指向元素之后的元素。 关联容器 **关联容器里面的pair 关联容器的操作 关联容器的添加操作 一般都是直接用下标操作添加map里面的操作。at操作只能判断存不存在 关联容器的删除操作 关联容器的访问操作 上面关于排序的操作不适用于无序的关联容器。 当允许关键词重复的multimap中查找元素时，一般使用find函数与count函数同时进行。 算法大部分函数算法都放在&lt;algorithm&gt;的头文件里面了。还有一些数值算法是放在了&lt;numeric&gt;的头文件里面。 只读算法 accumulate 求和算法，接受三个参数，前面两个参数是累加范围，第三个是和的初值。equal 判断两个序列里面是否所有的值都相同。后面网上查找 有的再补充。find算法binary_search()二分查找函数find_end()最后一次出现算法find_first_of()第一次出现的算法find_if ()第三个参数就为自定义函数搜索lower_bound()第一个不小于的元素upper_bound()第一个大于的元素count（）算法 计算出现次数count_if（）函数自定义计数 写容器的算法 fill 填充算法 类似于memset函数前者在于可以赋值赋任何值，而后者理论上只能赋值0或者1或者0x3f3f3f3f。fill_n也是三个参数，第一个是开始点，第二个是赋值数目，第三个为赋值初始化。copy 拷贝算法，接收三个迭代器，前面两个表示输入范围，第三个为拷贝目标序列的起点。replace 替换算法，将目标序列里面的某些值更改成某些值，接受四个参数，前面两个是目标序列的范围，第三个是要搜索的值，第四个是要将搜索到的第三个的值更改后的值。remove 去除掉函数里面包括的参数的元素。remove_if 自定义。remove_copy 拷贝结果。swap（）交换两个对象的值。swap_range()交换两个序列的值。 重排容器的算法 其排序的算法中，定义的排序方式就在于自定义函数传入算法中。有三种自定义函数： 普通bool型自定义函数，比较排列顺序。 lambda 匿名小函数。 bind 函数 绑定谓词。灵活的应用自定义函数。 unique 将容器中所有重复的值全部排列到后面去，接受目标序列的迭代器范围，返回指向第一个重复元素的迭代器。sort 排序 本质上运用的是快速排序。stable_sort 本质上运动的是归并排序。stable_partition 前面进行排序后，把自定义排列的分割开来。reverse 倒排函数。reverse_copy 倒排函数。rotate 接受三个参数，前面两个是要往后面排的范围。 迭代器 插入迭代器back_inserter 类似于push_back的迭代器，创建并且使用front_inserter 创建并且使用一个push_front的迭代器inserter 创建一个普通插入的迭代器 流迭代器istream_iterator 输入迭代器 ostream_iterator 输出迭代器 反向迭代器reverse_iterator 移动迭代器后面复习到在总结 移动、拷贝、右值引用。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>数据结构</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分法思想]]></title>
    <url>%2F2018%2F12%2F01%2F%E4%BA%8C%E5%88%86%E6%B3%95%E6%80%9D%E6%83%B3%2F</url>
    <content type="text"><![CDATA[二分查找实现在单调有序的集合中查找元素，每次江集合分为左右两个部分，并且通过判断集合在哪个部分从而调整集合的上下界，重复知道找到目标元素为止。 举一个简单的例子，我要在1到100里面查找62，先拿62根这个其最中间的一个数进行比较。然后在一步一步的缩小集合的上下界，最后再来一步一步往里面缩 下面是C++STL里面二分查找的函数： binary_search 返回bool值,是否存在lower_bound 返回可插入的最小位置的迭代器 即返回第一个符合条件的元素位置upper_bound 返回可插入的最大位置的迭代器 即返回最后一个符合条件的元素位置 在二分查找里面最典型的题目就是二分逼近求方程式的根了。 代码如下123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;#include&lt;cmath&gt;#include&lt;algorithm&gt;#include&lt;iomanip&gt;using namespace std;const double pre =1e-4;double x,y;double f(double x)&#123; return 8*pow(x,4)+7*pow(x,3)+2*pow(x,2)+3*x+6-y;&#125;int main()&#123; int t; cin&gt;&gt;t; while (t--)&#123; cin&gt;&gt;y; double x1=0,x2=100;//先把上下界在这里确定好 double mid=(x1+x2)/2; if (f(x1)*f(x2)&gt;0) cout&lt;&lt;"No solution!"&lt;&lt;endl; else &#123; while (x2-x1&gt;=pre)&#123;//这里必须写的是上下界线是多少， 不能写的是用于判断mid的条件。 if (f(x1)*f(mid)&lt;0)&#123; x2=mid; mid=(x1+x2)/2; &#125; else &#123; x1=mid; mid=(x1+x2)/2; &#125; &#125; cout&lt;&lt;fixed&lt;&lt;setprecision(4)&lt;&lt;mid&lt;&lt;endl; &#125; &#125;&#125; 上面就是我第二次出错的地方，判断二分循环逼近的的条件不应该看mid的取值，而是应该看得是区间上界减去区间下界的范围从而来限定。 此处关于三分法的求解：当需要求某凸性或凹形函数的极值，通过函数本身表达式并不容易求解时，就可以用三分法不断逼近求解。 三分法——求解凸性函数的极值问题http://hi.baidu.com/vfxupdpaipbcpuq/item/81b21d1910ea729c99ce33db 经典例题：侵略的奶牛： 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int maxn = 100005;int a[maxn],n,c;//此过程就是在判断奶牛之间的间隔为这个值合不合适bool cc(int d)&#123; int t=a[0],cnt=1; for (int i=1;i!=n;i++)&#123; if (a[i]-t&gt;=d)&#123; cnt++; t=a[i]; if (cnt&gt;=c) return true; &#125; &#125; return false;&#125;//此过程就是在收录每一个值，然后再分别进行判断int solve()&#123; int x=0,y=a[n-1]-a[0]; while (x&lt;=y)&#123; int mid=(x+y)/2; if (cc(mid)) x=mid+1; else y=mid-1; &#125; return x-1;&#125;//不过这种最大值最小值的题目需要多花时间想想。int main()&#123; while (cin&gt;&gt;n&gt;&gt;c)&#123; for (int i=0;i!=n;i++) cin&gt;&gt;a[i]; sort(a,a+n); cout&lt;&lt;solve()&lt;&lt;endl; &#125;&#125; ==下面则是其他地方关于二分的题目==基础版 POJ 3122 Pie 二分枚举区间是实数POJ 1064 Cable master 二分枚举区间是实数,注意精度POJ 3258 River Hopscotch 最大化最小值POJ 3273 Monthly Expense 最小化最大值LIGHTOJ 1076 Get the Containers 最小化最大值，。和上一个差不多LIGHTOJ 1307 Counting Triangles 进阶版 POJ 3579 二分搜索+二分查找POJ 3685 二分搜索+二分查找ZOJ 3278 也是两个二分嵌套LIGHTOJ 1048和LightOJ 1076一样，不过要输出一组解LIGHTOJ 1383 二分加贪心（区间）ZOJ 3665 某年区域赛题。，二分枚举ZOJ 3726 去年区域赛题，二分查找codeforces 382B 有意思的题codeforces 391D2 难，。。，，、 ==下面就是关于三分的题目== poj3301hdu4454hdu3714hdu2438]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款03：尽可能使用 const]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE03%EF%BC%9A%E5%B0%BD%E5%8F%AF%E8%83%BD%E4%BD%BF%E7%94%A8%20const%2F</url>
    <content type="text"><![CDATA[首先使用 const 可以防止后期莫名其妙的进行改变原有的意思，相当于一个约束语义，另外编译器不论什么时候都会强制施行这项约束。 const 在 C++ 11 中有底层和顶层之分，前者是作用于指针本身，指针不再改变指向对象，而顶层 const 则是指针所指向的对象则不能发生改变。 const 最具威力的用法实在面对函数声明时的用法，在一个函数的声明式里，const 可以和函数的返回值，各自的参数以及函数自身产生关联。 将引用参数设置成 const 好处是在后面写代码的过程中如果把==写成=，可以立马甄别出来。 const 成员函数存在的两个理由，一个使 class 的接口一目了然，因为知道了哪些可以被改动对象而哪些不可以被改动对象，第二则是基于代码编写的高效性而言，操作 const 对象成为可能，因为可以通过 const 成员函数返回 const 对象。 存在一种特殊情况，重载[ ]运算符的时候，如果成员函数是 const 那么其的返回值也必须是 const&amp;类型的。 如果对于const 成员函数，想要改变该对象的内部成员的话，但是又不想全部改变的话，可以在类中的数据成员定义中加上 mutable，来保证可以改变该函数，其存在的意义就在于保证了其他数据成员不能被 const 成员函数改变，但是该数据成员却可以。 7.当 const 和 non-const 成员函数有实质等价的实现时，令 non-const 版本调用 const 版本可避免代码重复。 这一点还不是特别了解，需要看到后面之后花点时间来看看这一点的内容。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款02：尽量以const,enum,inline 替换掉#define]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE02%EF%BC%9A%E5%B0%BD%E9%87%8F%E4%BB%A5const%2Cenum%2Cinline%20%E6%9B%BF%E6%8D%A2%E6%8E%89%23define%2F</url>
    <content type="text"><![CDATA[这个条款其实也就相当于宁可编译器替换预处理器比较好 1. 对于单纯常量而言，使用 const 对象或者是 enums 比 #define 更加省时间 时间上更为节省 作为一个语言常量而不是名称记号，由于在函数体中分配了内存，追寻起来消耗的时间比在函数中使用名称记号所花的时间更少，因为有实处更容易寻找，不像名称记号，可能有的时候并没有进入到记号表中。 还有一些其他的只能使用 const 情况 定义常量指针和类的专属常量]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款01：视 C++ 为一个语言联邦]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE01%EF%BC%9A%E8%A7%86%20C%2B%2B%20%E4%B8%BA%E4%B8%80%E4%B8%AA%E8%AF%AD%E8%A8%80%E8%81%94%E9%82%A6%2F</url>
    <content type="text"><![CDATA[现在发展的C++已经是一个多重泛型编程语言。 一个同时支持过程形式、支持面向对象形式、函数形式、泛型形式、元编程形式的语言，这些能力和弹性使 C++成为了一个无可匹敌的工具。对待其的方式最简单的方法是将其看做是一个由相关语言组成的一个联邦而不是某个次语言。 C 说到底 C++ 仍然是 C 的一个延伸，面对过程的编程思想仍然在某些时候很受用，而某些时刻 C++ 的解法只不过就是比 C 高级了一点点，但是当你以 C++的内 C 成分的工作的时候，高效编程则映照出了 C 语言的局限，没有模板，没有异常，没有重载。 Object-Oriented C++ 这部分也就是 C++ 中面对对象编程思想的直接体现，简单来说就是 C with class 比如 类，封装，继承，多态，虚函数的动态绑定。 Template C++ 这是 C++中的泛型编程部分，template 的相关考虑与设计已经弥漫了整个 C++ 而这种编程思想的强大，直接带来了全新的名字 模板元编程，后面得花上大部分时间去专研这个。 STL 基本上包括 容器，迭代器，算法以及相应的函数对象，一般竞赛可能会直接用到里面的相关容器以及相关算法，熟练使用 STL 也是一名 C++ 程序员应该必备的素质。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一道计算机几何算法相关题目]]></title>
    <url>%2F2018%2F12%2F01%2F%E4%B8%80%E9%81%93%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%87%A0%E4%BD%95%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[题目： 代码如下：1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;iomanip&gt;#include&lt;cmath&gt;using namespace std;double v,s,b;const double pi = acos(-1.0);int main()&#123; while(cin&gt;&gt;v&gt;&gt;s&gt;&gt;b)&#123; if (s&lt;b)&#123; cout&lt;&lt;-1&lt;&lt;endl; continue; &#125; double x = (v * v) / 9.8; if ( x &lt; s ) &#123; cout&lt;&lt;"move "&lt;&lt;fixed&lt;&lt;setprecision(2)&lt;&lt;s-x&lt;&lt;endl; &#125; else &#123; double b = (s * 9.8) / (v * v); //注意反函数的转换。 double a = asin(b) * 90 / pi; //这里有一个进一的操作，因为此题不太会去四舍五入。 int a_ = a; if (a-a_ &gt;= 0.5) a_++; cout&lt;&lt;"a "&lt;&lt;a_&lt;&lt;endl; &#125; &#125; return 0;&#125; 关于这道题目的相关要点 反函数相关要点。注意 反函数最后输出的是 一个弧度值，根据相应数学的算法而言记住 ==弧度值=角度*pi/180== 关于输出中进1的相关操作。按照第几位，先换算成相应的整形数，最后再强转成int型 最后在判断是否大于0.5来考虑时候来加一。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款07：为多态基类声明 virtual 析构函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE07%EF%BC%9A%E4%B8%BA%E5%A4%9A%E6%80%81%E5%9F%BA%E7%B1%BB%E5%A3%B0%E6%98%8E%20virtual%20%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[在进行基类与派生类之间动态绑定的时候，如果发生对象销毁调用的析构函数不是虚函数的话，那么就会造成析构销毁部分的现象。 C++明确指出，当 derived class 对象经由一个 base class指针被删除，而该 base class 带着一个不是虚函数的析构函数的话，其结果往往都是自定义的，就像上述的说法而言，往往是对象的 derived 成分没有被销毁，而且消除这个问题最简单的办法是在基类的析构函数上面加上虚函数的声明。 不要随便继承标准库里面的东西，因为里面大部分东西都不存在虚函数的析构函数，这样一来，如果使用动态绑定的话，那么在销毁对象的过程中就没有办法全部销毁了。 而且不一定是基类的析构函数设置成虚函数，只要类里面有一个函数是虚函数的话，那么就需要将析构函数定义成虚函数。 类的用途不是作为多态的用途的话，那么请不要将析构函数声明成虚函数，因为那样没有作用。 对于一个纯虚函数而言，这个类就是一个抽象类，但是由于存在一个析构函数，所以一般要为这个纯虚函数提供定义，其的运作方式是最深层派生的那个类的析构函数最先被调用，然后就是每一个基类的析构函数被调用，所以编译器会在派生类的析构函数中定一个对基类纯虚析构函数的调用动作，因此，一般都得进行调用。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款08：别让异常逃离析构函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE08%EF%BC%9A%E5%88%AB%E8%AE%A9%E5%BC%82%E5%B8%B8%E9%80%83%E7%A6%BB%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[其实这一项条款没有领悟的很深刻，可以理解成不要再析构函数里面写捕获异常之类的代码。因为某些时候，如果在析构函数里面抓获异常导致程序终止的话，那么就可能造成对象不能完全被销毁 析构函数绝对不要吐出异常，如果一个被析构函数调用的函数可能抛出异常的话，析构函数应该做的应该是捕捉任何异常，然后吞下他们（不传播）或者结束程序。 如果对象需要对摸个操作函数运行期间抛出的异常做出反应，那么 class 应该提供一个普通函数（不应该在析构函数里面）执行该任务。但是该析构函数里面仍然要进行双保险的析构过程，可以在类的内部定义里面加上一个 bool 变量来判断到底有没有运行析构行为，相当于一般写程序的一个 flag。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款06：若不想使用编译器自动生成的函数，就应该明确拒绝]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE06%EF%BC%9A%E8%8B%A5%E4%B8%8D%E6%83%B3%E4%BD%BF%E7%94%A8%E7%BC%96%E8%AF%91%E5%99%A8%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%9A%84%E5%87%BD%E6%95%B0%EF%BC%8C%E5%B0%B1%E5%BA%94%E8%AF%A5%E6%98%8E%E7%A1%AE%E6%8B%92%E7%BB%9D%2F</url>
    <content type="text"><![CDATA[有的时候鉴于某些情况，比如智能指针中 unique_str 和 io 库对象无法发生拷贝和赋值，是因为明确在类的内部进行了拒绝操作，所以无法拷贝与赋值，这一个条款就来讲解有哪些方法可以用来拒绝。 把自己不想要的函数，但是系统默认又会生成的函数放到私有成员中，这种方法很简便，但是有一个缺点就是在类的内部定义中仍然是可以使用拷贝与赋值功能的。 继承一个基类，使用 private 继承方法，然后将这个基类的函数放入私有成员中，这样就可以保证万无一失的方法，但是缺点就是太复杂，还需要定一个基类。 C++11 提出的新办法将函数声明出来，不仅不去定义，而且直接声明成 delete。这样更便捷。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款10：令 operator= 返回一个 自身的返回]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE10%EF%BC%9A%E4%BB%A4%20operator%3D%20%E8%BF%94%E5%9B%9E%E4%B8%80%E4%B8%AA%20%E8%87%AA%E8%BA%AB%E7%9A%84%E8%BF%94%E5%9B%9E%2F</url>
    <content type="text"><![CDATA[一般重载赋值运算符号的时候一般都会返回一个自身的引用，这样可以更方面操作自身，如果仅仅只是返回一个拷贝的对象的话，那么将会在连续使用运算符的时候发生错误，而且在一些较大的类型的话，可能速度会慢些，所以一般返回自身的引用。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款12：复制对象时勿忘其每一个成分]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE12%EF%BC%9A%E5%A4%8D%E5%88%B6%E5%AF%B9%E8%B1%A1%E6%97%B6%E5%8B%BF%E5%BF%98%E5%85%B6%E6%AF%8F%E4%B8%80%E4%B8%AA%E6%88%90%E5%88%86%2F</url>
    <content type="text"><![CDATA[这个条款而言，是无论类发生什么样的内部变化，都必须重写类的管理行为。下面直接分为两个方面进行诠释： 类的内部增加或者减少数据成员，如果未重新编写构造函数的话，那么编译器也不会提醒，这样就会造成不太被需要的局部拷贝。 一旦发生继承，如果还是按照以前的方法仅仅是对函数内部的所有数据成员进行拷贝的是不对的，因为派生类不仅仅是包含着派生类的部分，还仍然包含着基类的部分，所以需要调用基类的拷贝行为，如下图： 另外拷贝构造函数定义内部是不能直接调用赋值运算符，反之亦然，前者就相当于对一个尚未构造好的对象进行赋值，而后者就相当于对一个已经构造对象再进行重新构造。所以千万不要这么做。 如果发现两个拷贝行为有类似的代码时，应该把这个相同的代码放到一个函数中区，然后由两个拷贝行为共同调用。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款13：以对象管理资源]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE13%EF%BC%9A%E4%BB%A5%E5%AF%B9%E8%B1%A1%E7%AE%A1%E7%90%86%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[系统资源的管理规则就是，一旦使用完毕，那么就一定要归还给系统，免得造成内存泄漏的问题，而 C++中需要自己去管理内存，那么为了防止在对象销毁以及内存释放之间发生异常，以及某些其他原因，一种新的基于对象的资源管理办法就应运而生。 使用智能指针， C++11之后智能指针分为三种一种是 share_ptr 指针 智能型的应用计数，共享底层数据。weak_ptr 依附于 share_ptr 作为一种核查类指针存在，最后就是 unique_ptr 指针，仅仅只是为了对象的析构函数自动销毁，上述两种主要的智能指针可以定义自己的删除器（析构函数） 获得资源后立刻放到管理对象中，其所代表的观念就是 “资源取得的时机，就是直接初始化的时机”。 需要注意的就是智能指针默认的删除器是不能删除固定的连续内存空间，意思就是说，需要自定义的删除器才能完成 delete[]。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款09：绝不在构造和析构的过程中调用 virtual 函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE09%EF%BC%9A%E7%BB%9D%E4%B8%8D%E5%9C%A8%E6%9E%84%E9%80%A0%E5%92%8C%E6%9E%90%E6%9E%84%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E8%B0%83%E7%94%A8%20virtual%20%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[绝对不要在构造函数和析构函数期间调用虚函数，因为这样调用的结果不会带来预想的结果。 基类构造函数的时候，虚函数是不会下降到派生类中，原因就是在基类开始构造函数的时候，该类的类型是基类，而不是派生类，简单来说，如果想在构造函数的过程中，直接使用基类的虚函数来折射到派生类，从而帮助派生类完成构造的话，那么这种办法一定行不通。 相同的道理同上，在基类析构函数发生的过程中，同样将其他的派生类视作未定义。 如果将构造函数或者析构函数调用的函数设立成纯虚函数的话，那么当纯虚函数被调用的时候，大多数执行系统会直接终止程序，唯一避免的此问题的做法就是确定构造和析构期间没有调用虚函数。 唯一的替代方案是不设置虚函数，比如在构造一个派生类对象的时候，需要直接调用基类函数的构造函数，然后再完成派生类的构造，而此时最好是将派生类里面一个作用于构造函数的一个成员函数定义成静态函数，这样的话就能在程序刚开始就存在该函数了。 由第四点换句话说，你无法使用虚函数直接从基函数向下调用，但是在基类函数中可以由派生类将信息传递到基类从而进行有效调用。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款15：在资源管理类中提供对原始资源的访问]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE15%EF%BC%9A%E5%9C%A8%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%B1%BB%E4%B8%AD%E6%8F%90%E4%BE%9B%E5%AF%B9%E5%8E%9F%E5%A7%8B%E8%B5%84%E6%BA%90%E7%9A%84%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[一般使用了智能指针之后就不会在建议使用内置指针，以免发生错乱，但是就是有一些类需要在使用智能指针的过程中需要返回内置指针来完成某些函数的参数传递过程，但是需要注意的一点就是 在使用内置指针的过程中 千万不需要 delete，直接让智能指针进行删除操作。 另外除了返回内置指针这种方式来进行对原始资源的访问，还有一种方法就是重载隐式转换运算符，来完成类到资源的转换，但是这样做会加大错误的可能性，因为某些不可控的隐式类型发生转换。 上述的第一种办法属于显示转换，直接使用 get 获得资源，而下面的那种是隐式转换类型，前者比较安全，后者比较方便。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款11：在 operator 中处理自我赋值的情况]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE11%EF%BC%9A%E5%9C%A8operator%E4%B8%AD%E5%A4%84%E7%90%86%E8%87%AA%E6%88%91%E8%B5%8B%E5%80%BC%E7%9A%84%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[本来是可以不用担心拷贝过程中发生自我赋值的情况，但是就是为了防止用户，或者对象自身的这种情况，所以需要完成避免自赋值的情况 比如两个指针对象进行自赋值的时候，为了防止多次删除，需要检查一下自赋值的情况。 同时不仅要考虑的是自我赋值的安全性，仍然需要考虑的是异常的安全，也就是前者是需要判断如果前者的地址等于后者的地址话 就直接返回不作为，并且先删除原本的，再赋值新的，而后者则是先构造一个对象赋值给另外一个，然后先赋值，再删除。 就类似于这样，这样既能保证自赋值的情况，但是又能保证异常安全，不会在new对象的时候发生错误。 还要记住的是一般在移动赋值运算符的时候也应该注意一下自赋值的情况，不过上面的异常安全很少涉及到，因为上面的相比于前者更费点时间。 或者是直接使用自定义的 swap 功能，这样的话对于自赋值的情况以及异常安全的情况来比，更加省事和高效。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款16：成对使用new和delete时需要采取相同的形式]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE16%EF%BC%9A%E6%88%90%E5%AF%B9%E4%BD%BF%E7%94%A8new%E5%92%8Cdelete%E6%97%B6%E9%9C%80%E8%A6%81%E9%87%87%E5%8F%96%E7%9B%B8%E5%90%8C%E7%9A%84%E5%BD%A2%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[其实我根本不知道这个为什么会成为一个单独的条款鉴于此，所以就简单的讲两句话： new 一个数组，那么一定要 delete 一个数组 智能指针默认没有 delete 数组，所以需要自定义删除器。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款14：在资源管理类中小心拷贝行为]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE14%EF%BC%9A%E5%9C%A8%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%B1%BB%E4%B8%AD%E5%B0%8F%E5%BF%83%E6%8B%B7%E8%B4%9D%E8%A1%8C%E4%B8%BA%2F</url>
    <content type="text"><![CDATA[一般在自定义类中会遇到多种多样的拷贝行为，所以一般会采取下面的一些策略 禁止复制 向前面条款06一样，有多种办法，一般对于那些逻辑上拷贝不合理的函数。 对底层数据的共享控制 那么此处这就需要使用智能指针 share_ptr，或者自定义引用计数。并且拥有自定义的删除器，因为某些类的删除操作并不一定是释放内存、销毁对象。 转移底部资源的拥有权 移动操作，C++11 右值引用的移动过程。 复制分为浅层复制以及深层复制 前者是复制其的指针或者引用，达到共享资源的目的，这个时候使用 share_ptr 来进行控制，后者赋值的是全部内存，最好是用 unique_ptr 来保管，但是复制操作得把每一个对象所指向的对象进行拷贝之后，放进 unique_ptr 中进行管理。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款17：以独立语句将new过得对象放入智能指针中]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE17%EF%BC%9A%E4%BB%A5%E7%8B%AC%E7%AB%8B%E8%AF%AD%E5%8F%A5%E5%B0%86-new-%E8%BF%87%E5%BE%97%E5%AF%B9%E8%B1%A1%E6%94%BE%E5%85%A5%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[编译器的编译次序是说不定的，就想下图的 上述的三个次序一旦顺序不对就会发生错误，所以一个最好避免的办法就是想如图所示： 先将对象存储在智能指针中（先完成智能指针的构造），在完成对智能指针的调用。 上述举的例子说明的问题是一定要把对象存入智能指针的过程独立成一个语句]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款19：设计 class 犹如设计 type]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE19%EF%BC%9A%E8%AE%BE%E8%AE%A1%20class%20%E7%8A%B9%E5%A6%82%E8%AE%BE%E8%AE%A1%20type%2F</url>
    <content type="text"><![CDATA[一般设计一个优秀的类，实际上也就是设计一个优秀的类型，而往往需要满足下面这些疑问。 新 type 对象应该如何创建和销毁 关系到类的构造函数与析构函数如何建立 对象的初始化和对象的赋值之间的差别 主要是为了区分构造函数与赋值运算符之间的区别 该类参数传递中有传值也有传引用 传引用与传值之间的区别，以及如何实现，以及究竟何时会去调用这一类的函数。 新 type 的和法制 构造这个类的时候一些合法值，要不要对应自己的私有数据成员，或者是类型转换，通常其都会影响构造函数、赋值操作，以及 setter 函数，甚至还会影响到函数抛出的异常。 是否需要配合某一个继承体系 需要记住的是继承体系的构成一定要满足的是 is - a 的条件，另外虚函数与非虚函数之间的影响，并且还要考虑的时候 是否应该把自己的析构函数也设计成虚函数。 是否需要类型转换 类型转换一般会分为显式转换和隐式转换，实现方式一般有直接在其中一个函数内些类型转换的重载运算符函数，和没有声明 explicit 的单一参数的构造函数。 重载的操作符以及其他相应的函数，是否合理 这里看重载的函数是否符合逻辑条件，不仅仅是代码之间的严禁性质，还需要考虑的就是生活层面的实用性。 哪些成员应该封装？ 这里就设计到哪些成员应该设置成私有，而哪一些函数应该设置成公有函数，并且一些不想编译器生成的函数应该定义成删除。 类型的未声明接口 它对效率、异常安全性以及资源运用提供什么样保证，以及为类的实现代码应该提供什么的约束条件。 是否应该定义成模板 这里就看类的一般性究竟有多大，是否具有普遍价值。 考虑是否会继承与其他的类 有的时候考虑过后，也许这个类就不需要凭空创造出，仅仅只是需要从其他类上面派生出来即可。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款20：宁以传 const 引用也不要传值]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE20%EF%BC%9A%E5%AE%81%E4%BB%A5%E4%BC%A0%20const%20%E5%BC%95%E7%94%A8%E4%B9%9F%E4%B8%8D%E8%A6%81%E4%BC%A0%E5%80%BC%2F</url>
    <content type="text"><![CDATA[这个传值行为是继承与 C 语言的，基本上传引用更加方便，且付出的代价更小，不过需要注意下面了两点。 传引用有的时候会碰到切割问题，比如传参的时候，本来应该传入一个基类对象，但是实际上传入了一个派生类对象，这个时候就会把派生类基类的部分切割出去，其他部分就直接丢了 以上规则不适合某些特殊规则，比如内置类型以及 STL 的迭代器，对它们而言 ，传值往往是最恰当的。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款18：让接口容易被正确使用，不易被误用]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE18%EF%BC%9A%E8%AE%A9%E6%8E%A5%E5%8F%A3%E5%AE%B9%E6%98%93%E8%A2%AB%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%EF%BC%8C%E4%B8%8D%E6%98%93%E8%A2%AB%E8%AF%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[注意类的隐式转换，并且智能指针与内置指针的区别，以及以对象管理的思想来管理资源。 好的接口很容易被正确使用，不容易被误用，应该在接口里面努力达成这些性质。 促进正确使用的办法 包括接口的一致性，与其内置类型的行为一致。 阻止误用的办法包括建立新类型，限制类型上面的操作，以及束缚对象值，以及消除客户的资源管理责任 智能指针支持定制删除器，这样可以防范动态链接程序库的问题]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款21：必须返回对象的时候，不要妄想返回其的引用]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE21%EF%BC%9A%E5%BF%85%E9%A1%BB%E8%BF%94%E5%9B%9E%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%A6%84%E6%83%B3%E8%BF%94%E5%9B%9E%E5%85%B6%E7%9A%84%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[该条款一般适用于某些特殊情况下必须返回值的情况 关于这个条款只需要注意一点，绝不要返回 pointer 或 reference 或者返回引用指向一个全局变量，或者返回指针引用指向一个静态成员，但是同时又需要多个这样的静态成员。在条款4中已经提供了一份设计实例。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款23：宁以非成员友元函数代替成员函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE23%EF%BC%9A%E5%AE%81%E4%BB%A5%E9%9D%9E%E6%88%90%E5%91%98%E5%8F%8B%E5%85%83%E5%87%BD%E6%95%B0%E4%BB%A3%E6%9B%BF%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[同样还是为了封装 宁可拿非成员非友元函数来代替成员函数，这样做可以增加封装性，和包裹弹性，以及机能扩充性。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款24：若所有参数需要类型转换的时候，请设置非成员函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE24%EF%BC%9A%E8%8B%A5%E6%89%80%E6%9C%89%E5%8F%82%E6%95%B0%E9%9C%80%E8%A6%81%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E8%AF%B7%E8%AE%BE%E7%BD%AE%E9%9D%9E%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[该条款就是需要注意一点 如果需要为某个函数的所有参数，包括this 指针所指的隐喻参数，进行类型转换的时候，那么这个函数就必须是非成员函数]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款22：将成员变量声明为 private]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE22%EF%BC%9A%E5%B0%86%E6%88%90%E5%91%98%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E%E4%B8%BA%20private%2F</url>
    <content type="text"><![CDATA[这里就是要记住封装的好处 切记要将成员变量声明为 private 。这样可以减少改动成员之后的破坏性，可细微划分访问控制、允诺约束条件获得保证，并且提供 class 作者以充分实现弹性。 protected 并不比 public 更具有封装性]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[条款25：考虑写出一个不抛异常的 swap 函数]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%9D%A1%E6%AC%BE26%EF%BC%9A%E5%B0%BD%E9%87%8F%E5%BB%B6%E5%90%8E%E5%8F%98%E9%87%8F%E5%AE%9A%E4%B9%89%E5%BC%8F%E5%87%BA%E7%8E%B0%E7%9A%84%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[其实该条款总结下来就是再讲一个东西，而这个东西分成两点： 如果类的赋值成本低于一组构造和析构成本，那么将对象的定义定义到循环体外部去，尤其是在循环次数很多的情况下。否则就是将定义循环体内部中去。 尽可能延后变量定义式出现的时间，最好达到需要什么才去定义什么，这样做可以增加程序的清晰度并改善程序效率。另外最好在程序定义的时候就直接构造（初始化）。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>effective C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树相关题目]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%A0%91%E7%9B%B8%E5%85%B3%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[复原二叉树 题解此道题目就是要注意先序排序与中序排序，一个是根左右，一个是左根右，先序排序的第一个为根，利用递推关系输出每一个根（由于其的递推出口并没有等于号，意思就是说这里同样输出叶子节点） 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;string pre;string in;void post(int root,int start,int end)&#123; //递归打印这棵树的后序，递归出口为 start &gt; end //注意这里不带等于号的原因就是要把叶子节点一样给输出来 if(start&gt;end) return; int i=start;//i为 root所代表的值在中序中的下标 while(i&lt;end&amp;&amp;in[i]!=pre[root]) i++; int cnt=i-start;//左子树结点个数 //由于是先序排序，顺序永远都是根左右， post(root+1,start,i-1); //左节点 因为是后序排序，先把左节点先弄出顺序，在左节点内部在来后序排序，直到两边左边节点大于右边节点 post(root+1+cnt,i+1,end); cout&lt;&lt;pre[root];&#125;int main()&#123; while(cin&gt;&gt;pre&gt;&gt;in)&#123; int len=pre.length(); post(0,0,len-1); cout&lt;&lt;endl; &#125; return 0;&#125; 关于树的一个简单DFS运用 题解 简单的dfs运用 可以模拟树的组成，但是特别耗时间，只用用相应的搜索方法来做才容易一点，这道题有必要再做一遍。 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;vector&gt;#include&lt;string&gt;using namespace std;const int maxn = 1e5+5;//此处实际上是充分利用了vector的特性//如果此处是二维数组的话，那么一定会浪费许多没必要的空间开支//所以用一个vector的数组，每个vector存储其对应的祖先//而一共有题目给出数量的vectorvector&lt;int&gt;people[maxn];char sex[maxn*2];int ans;int top;int que[maxn];//这里e的值只是用来判断到底是该植入值还是该判断值//换算到这个题目中的意思就是前面一个人不需要看起祖先只需要输入其祖先就行了//后面一个人则需要做的是根据已有的对方祖先进行判断void dfs(int x,int s,int e)&#123; if (s&gt;=5) return ; if (e==0)&#123; for (int i=0;i!=top;i++)&#123; if (x==que[i])&#123; ans=1; return; &#125; &#125; &#125; else que[top++]=x; for (int i=0;i!=people[x].size();i++) dfs(people[x][i],s+1,e); return;&#125;//上面的递归搜索可以用来因为是从底层向上面进行搜索//由于孩子祖先有两个所以上面搜索方式每一个孩子的祖先作为单独的节点再次进行搜索，直到递推出口为止int main()&#123; int n; cin&gt;&gt;n; char ch; int x,fa,ma; for (int i=0;i!=n;i++)&#123; cin&gt;&gt;x; getchar(); cin&gt;&gt;sex[x]; cin&gt;&gt;fa&gt;&gt;ma; if (fa!=-1) people[x].push_back(fa); if (ma!=-1) people[x].push_back(ma); sex[fa]='M'; sex[ma]='F'; &#125; int k; cin&gt;&gt;k; for (int i=0;i!=k;i++)&#123; cin&gt;&gt;fa&gt;&gt;ma; ans=0; if (sex[fa]==sex[ma]) cout&lt;&lt;"Never Mind"&lt;&lt;endl; else&#123; top=0; dfs(fa,0,1); dfs(ma,0,0); if (ans) cout&lt;&lt;"No"&lt;&lt;endl; else cout&lt;&lt;"Yes"&lt;&lt;endl; &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM集训相关知识]]></title>
    <url>%2F2018%2F12%2F01%2FACM%E9%9B%86%E8%AE%AD%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[基本的数据结构 扩充顺序表 （我的理解就是连续的顺序容器）存储方法就是在内存中开辟一段连续的空间。 而数据元素的位置确认： 常见的线性表运算： 此处一般都是用数组来实现，其的插入运算和删除运算都是基于连续内存空间上面所实现的。 单链表定义：链表的存储方式： 双向链表 循环链表简单来说就是首尾相连接的单向链表。 以上有时间再来进行详细的全面总结。 栈 如果用C语言来表示栈的话，得以数组作为基础，秉持先进后出的思想就行了。可以用int值作为下标值作为当时存储的栈的位置。也可以用两个指针来指示当前下标值。可以借用栈的思想来做题目。 队列 队列的基本逻辑运算： 这里也是运用两个int型的值当做是变量，分别指向头指针以及尾指针，然后执行添加减少的操作。一般到最后全部用做到下标上面。 而循环队列也是建立两个指针，但是不同的是其是将首尾进行连接之后，也就是说，其直接将每次得到的新结果对队列的总长度进行一个求余数（求mod）。 下学期上课的时候可以用C语言代码实现以下。 循环队列其实可以干和循环链表一样的事情。比如一道例题： 代码如下：1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt; #include&lt;queue&gt;#include&lt;string&gt; #include&lt;stdio.h&gt; using namespace std; int main()&#123; int n; while(cin&gt;&gt;n)&#123; queue&lt;string&gt; a; for(int i=0;i&lt;n;i++)&#123; string name; cin&gt;&gt;name; a.push(name); &#125; int w,s; scanf(&quot;%d,%d&quot;,&amp;w,&amp;s); for(int i=0;i&lt;w-1;i++)&#123; string temp = a.front(); a.pop(); a.push(temp); &#125; while(a.size())&#123; for(int i=0;i&lt;s-1;i++)&#123; string temp = a.front(); a.pop() a.push(temp); &#125; cout&lt;&lt;a.front()&lt;&lt;endl; a.pop(); &#125; &#125; &#125; 串串的定义： 此处则可以理解成是字符串。 二叉树树的定义： 二叉树的性质： 排序简单的冒泡排序]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>acm</tag>
        <tag>c++</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年生日重庆之旅]]></title>
    <url>%2F2018%2F11%2F30%2F2018%E5%B9%B4%E7%94%9F%E6%97%A5%E9%87%8D%E5%BA%86%E4%B9%8B%E6%97%85%2F</url>
    <content type="text"><![CDATA[说句实话，自己也不知道应该写些什么东西，转眼之间似乎已经21岁了，知道自己内心不甘心的地方，但是唯一不太知道的是如何去改善这些不甘心的地方。问问自己的内心，其实自己一直想要的就是别人的关注。我觉得我个人的心路成长分成了几个阶段。 第一个阶段就是拼命的展现自我，追求其他人的认可与关爱。 如果在这个阶段里面获取了足够的认可，也许就会一直在这个阶段里面不断，要求满足，然后被满足的过程中进行沉沦。我个人的想法就是，如果没有进入到下一个阶段，那么永远得不到成长。 第二个阶段就是知道了这个世界上不会轻易的给自己满足的，知道了原来自己是会被拒绝的。 这个时期如果没有处理好的话，那么特别容易走向一个极端，走向一个“佛系”的一个极端，假意成为一个无欲无求的人，这个时期的我们就会厌恶一切“争宠”的行为，反而还会将那些争取优秀的人看作是特别低级的人类，从而厌恶一切优秀，但同时自己会在暗中做出很多自认为独一无二的事情，来彰显自己与别人不一样的地方。 第三个阶段往往是在经历了很长阶段的第二阶段，经历过打击，重新并且深刻的认知到这个世界并不是围绕着自己转动，一个人真的没办法获取周围每个人的关注。 也许甚至自己没办法获取周围一个朋友的全部的关注，其实换位思考一下，自己也没有全身心的投入自己去关注别人，其实到最后自己还是以一个自己都达不到的标准全部要求别人，有点自欺欺人的感觉。 其实自己就在上面所说的第二阶段中无力翻腾着。虽然自己没有去蔑视努力，知道自己一切改变都是努力的结果，这是好的，但是从进入大学的一年多来，自己觉得自己很累，每天过得也很充实，也有一个固定的目标，但是自己却好像从来不能得到满足。 其实最近发生的一切不安，一切困惑，问问自己，其实全部来源于自我认知的偏差。真的以为自己是无所不能的超人，认为所有事情，只要自己认真去做，那么就一定可以实现，但是却忘记了一个很重要的前提，人的精力是有限的，真的没有办法做到面面俱到。 从最先开始的选择程序员这条路，到后面编程语言的选择，然后又到了工具，开发环境，以及编程之路方向上面的选择，我最近做出了很多很多的选择。很高兴自己做出了很多的选择，但是同样又很悲伤自己做出的选择。 外因 每个人的人生只有一次，对于个人而言，发生的一切，其实都是一个全新的体验，所以不知道该怎么做，产生迷茫的情绪是一件很正常的事情，另外对于自己而言，周围也没有陪伴自己成长的长者，没有人可以体会到自己生命中每一个抉择背后所要承担的东西。再加上本着想把一切做好的目的，这个时候就会产生即使做出选择也会产生后悔的不确定感。 内因 我觉得归根到内心的话，还是有对自己不够自信这个心态存在的，还记得上次在经开一中一个科技展览会的时候，被一个学妹说不自信的时候，当时震惊的同时，其实更多的还是认可，我的确对自己不是特别的自信。不做选择的时候，怀疑自己是不是做不了选择了，当自己做出选择之后，又在怀疑自己是不是做出了一个错误的选择，我觉得这都是自己内心中需要克服的地方。 上面综合起来带来了 焦虑。 焦虑，一遍一遍的怀疑自己，一遍一遍的苛刻完美的标准，一遍一遍夸大其他人的成就而贬低自己的成就。以至于没有动力，没有耐心，没有毅力，以至于最后任欲望侵袭，堕落。 其实自己的初心是好的，但是为什么在初心之后的前行道路上会有如此大的阻碍呢，我觉得就是急功近利的心态，心急吃不了热豆腐，这句话适用于人生道路上面的每一寸。 不要因为走的太远，而忘记为什么出发 本来只是一个生日的小总结，不知不觉就说了这么多，本来只是想写写在重庆遇到了什么人，遇到了什么样的事情，但是还是抵御不住欲望的诱惑，主要还是焦虑，急功近利的心态毁了自己，自己在重庆得到的最大的收获便是在热闹的外界环境下，保持一份静谧，就像火锅配料上面的耗油，虽然起不到任何好吃的作用，但是却能在自己最辣的时候，给自己一点静谧。 这次的重庆之旅，有遗憾，有可惜，有没有完成的心愿，也有没有尽兴的地方，但是越长大越发现，我们总是希望人生中没有遗憾，可是到后来才发现，人生的遗憾才是人生中最有魅力的地方，因为有遗憾，才会有所向往。所有完美的东西最致命的弱点就是没有遗憾，从而也就没有了向往。 现在是凌晨的一点钟，自己还坐在火车上面颠簸，但是自己却有点享受这个时候的氛围，过道里时不时有人走过，有人上车，有人下车，旁边呼呼打鼾声音，还有时不时飘来的香烟味，提醒我 原来一直以来追求的生活就在周围。 希望自己回去以后可以好好的安排自己的人生，不要焦虑，不要急功近利，健身计划，英语六级，编程之路，成长之路，太过于追求结果就会导致失去自己想要的结果。 生活里最妙的永远不是按部就班，规划好的结果，而是转角里不经意的惊喜 祝自己21岁生日快乐。]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>个人经历</tag>
        <tag>旅行</tag>
        <tag>重庆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017~2018.5.1个人小结]]></title>
    <url>%2F2018%2F05%2F01%2F2017-2018-5-1%E4%B8%AA%E4%BA%BA%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[其实心知肚明自己的拖延症是非常强大的，总是在有意无意的拖延着，本来最先开始的预计是每一年都会写一个年终总结，然后2017年的年终总结直到现在才开始下笔，每次都有理由是最近的自己很忙很累，没有办法静下心来认真的写一写自己的总结，同时也秉持着“下一次一定有时间，其实后面的时间还多些呢？”然后就是这一些想法使自己拖延习惯变得越来越严重。也就有了今天”排除万难“在五一假期的第一天，在大家都出去郊游的情况下选择自己在宿舍里面好好整理。 从当初上大学一直到现在，说实话自己还是有点自命清高，也就是不太喜欢现在的环境，不过这种心态发展到现在，已经剔除了这种心态里面不太好的一面。这种想超脱环境的心态，我不知道该不该评价其的好与不好，但是我只知道的是，如果要超脱到现在原有的环境的话，得比周围的人付出200%的努力。 但是鉴于自己的表现，真的达到了200%的表现吗？我不知道，因为不知道自己努力的方向在哪，什么都想学，什么都想出人头地，但是却又什么都做不好，其实我现在越来越觉得人生最难的就是再控制好广度的同时钻研好深度。我觉得这才是难以控制的。落实到我现在的生活里面来看。上个学期的事情不去谈论过多，毕竟上个学期是来到学校的第一个学期，什么都很新鲜，由于好奇心的相互探索，自己找到了很多有趣的朋友，并且接触到了辩论，然后上个学期在保持学习进度的同时，在辩论上面进行了发展。上个学期就大学第一个学期而言，就算有太多的目标没有完成，但是这也都是可以值得原谅的。 现在我就要说的是大学的第二个学期，大道理每个人都懂，每个人都不是特别喜欢对自己说教的人，尤其是那个对你说教的人还是你的同级的时候，就更不容易接受，特别是自己做了一件事情，渴求肯定的时候，这个时候别人的”善意性质的批评“我觉得一定是听不下去的，但是对于自己而言，也许别人不会来说自己这一方面的事情，但是自己心里一定还是要有一些自知自明的，我知道对于自己这半个学期而来，很不满意，分几个块来说，由于自己每一方面都想要顾到，然后到最后自己每一方面都没有顾到。健身，辩论，编程，绩点学习奖学金，志愿者，旅游，自媒体写作，个人感觉这每一块都没有做好，因为每一件事情都想做好，但是每一件事都需要大量的时间基础很沉淀，于是我觉得目前最好的解决办法就是进行时间上面的优先级排序，把现阶段最重要的事情拿出来排到前面，自己想做，但是又不是必须做的事情放到后面。于是我就做了一下这张思维导图。 我目前的想法是想把计算机专业层面的学习放在第一位然后就是英语方面的学习，然后就是大学课程上面的学习。然后就是之后的兴趣发展。但是发展到现在，讲真的自己还是有点松懈了，没有以前的那股劲，但是就是羡慕那些有本事，有能力的人。之前的生活就是每天编点程序，学计算机方面的东西，然后也就是因为这些导致了翘课，导致了松懈，导致了现在会在宿舍里面发呆也不去教室上课，这些统统是导致的。我觉得这仍旧是自己开始松懈的标志，但是更是由于这些，我的生活也变得不太规律，之前一个星期每天估计一两点睡觉，而且早上不会再像以前一样去教室自习。我觉得我也不会像以前一样暗示自己这都不是个事，因为天然默认未来一切都是好的。然后就莫名其妙的给自己发一大段一大段的鸡汤 。这次的总结 我不想给自己讲大道理，因为全部都懂，我只想批评自己，只想反省。自己做的不对的地方就应该去改正。 未来还有一块是关于辩论队是去是留的问题，由于时间以及自己按照排序想做的事情冲突，不得不退了校队，并且极力减少自己再院队里面的比赛，但是自己还是比较喜欢这方面。但是没有办法，因为只要打乱了那个优先级排名的话，那么自己所有的事情都会乱。并且我喜欢自己做事情能够专一，最近发现自己在专一度上面没有很用功，后面可能会考虑尝试一下番茄时间。总之对于辩论队的诸多事宜，我最终决定还是仅仅是当作一个爱好，为自己的本命学科让路。 下一个问题是关于坚持，本来我觉得在这个层面是不存在的问题的，但是最近感觉的自己的自制力越来越差，其实毅力也就像肌肉，你只有多练练，才能使毅力这块肌肉越来越硬。所以以后跑步健身都要勤快点，去锻炼毅力这块肌肉。 最后是关于人际交往，有室友层面的，也有朋友层面的，交往一定要懂得度，这个度的把握，不仅要体现在自己身上，还要体现在别人身上。对于某些自以为是，只会偏激并且片面评价别人的人，我觉得还是把他们当作大神供起来吧。 贱人自有贱人收，我没办法弄他们，因为我不是贱人。 最后的最后希望从这个五一假期开始就带来改变，记住自己的优先级安排表，同时也记住坚持和努力，永远与自己的懒惰和松懈战斗下去。 总之对于现在而言​​，从5月1日到接下来放假的时间里，需要完成的目标有： 1、计算机编程语言C++的相关补充（尽量来看，还有暑假可以用来看）。 2、英语四级必须得过，接下来时间把英语听力弄好，每天尽力完成一套英语卷子。 3、体育锻炼 运动，马上夏天了，如果不想显示出自己的肥肉的话，得好好努力了。 ​4、保证接下来不挂科。允许不再以拿奖学金为主要目的。 5​、闲暇时间都看点自己感兴趣的书籍，不要再刷电视剧了。（这一点尽量控制）]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>成长</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年中秋节感慨]]></title>
    <url>%2F2017%2F10%2F05%2F2017%E5%B9%B4%E4%B8%AD%E7%A7%8B%E8%8A%82%E6%84%9F%E6%85%A8%2F</url>
    <content type="text"><![CDATA[我一直以来觉得生活的意义就是上进，就是毫无理由的提升自己，让自己变的更有价值，更有意义。这种思想产生于小时候受到的好好学习，努力考上大学的功利思想吧。但是也就是这种思想促使我一步一步走到现在，虽然没有太大的成就，但是也与周围的人拉开了距离。很久以前自己的这种思想也经常延申出另外一种表现方式。那就是比较。我觉得现阶段在我生活里的所有上进，所有快乐和所有成就感全部都来自于比较。我的大学比某些人好，我某些优点比某些人好，我比某些人更懂得生活，这些都会让我感到一种优越性质的快乐，就是我比别人行，我比别人厉害的快乐。但是反观这种快乐的来源，虽然从一定的角度上，他可能促进了我对上进意义的探索，但是也限制了我对未来意义上的追逐。比如说，我今天看到一个以我所谓的评判标准比我差劲的一个人，我会开心。但是当我看到一个比我厉害，或者说是我认为没有我厉害但是却做了一件我觉得很了不起的一件事情，这个时候我会难过，因为我不知道自己能不能做的跟他一样好，或者说是比他还要好。我之前觉得这是一种嫉妒心里，羡慕妒忌别人比我好的，却殊不知别人是付出了多大的代价达到这一步的。我知道有的时候妒忌心真的没有办法避免，至少我是没有办法去避免这种不好的心里，但是将这一点往深层次去考虑，这何尝不是一种自卑心里呢？曾经的我极度鄙视嫉妒心里，所以认为一切比较都是没有必要的，一切比较都是满足自己虚无的虚荣心，但是这样做的后果又是什么样的呢？这样做的后果是害怕比较，厌恶上进，难道这一切真的只是比较错了吗，还是说那种虚无的妒忌心真的毁灭一切的根源吗？我觉得可能还是内心深处弱点，我觉得这可能需要我接下来几十年的经历和历练去完善的问题，自卑。这里说的自卑可能不是那种口头上的什么我不行，我真的不行。我觉得这不叫做自卑，那叫做自暴自弃。自卑的心理我觉得纯粹是来自于价值观中的悲观体系，和性格中无法避免的软弱以及懦弱。可能这一系列的说法特别宽泛和抽象，那我举个例子。比如说我现在热衷于唱歌，如果我发现一个不是那种天赋流，仅仅是通过努力提升上去的人，唱歌突然变得很厉害了，按照正常人的想法，第一也许会妒忌，或者是倾佩。但是这两者之后我的反应就是难过与害怕。也许这里害怕这个词用的过于夸张，但是我想说的这个词用的很准确。我一向觉得有些事情如果发生在别人的身上那就是别人的事情，跟我与我自己所处于的世界是无关的。这是我基本的理念，但是我为什么会感到害怕呢？究竟是害怕什么呢？仅仅是害怕别人做的更好觉得自己会被嘲笑吗？我觉得可能是我性格上的问题，我可能还是有点需要被肯定，被积极对待的心理。简单来说是需要得到更多的爱与关怀。当遇到这样的事情之后，我的第一反应是他做的更好了，我为什么做不到，那肯定是我自己太没用了，自己太没用了，那么别人一定不会注意到这么失败的自己，因为自己太没用了。而且最致命的可能就是，觉得自己无论怎么努力都无法超过他。到最后虽然自己崇尚生活在自己的世界里，但是还是用别人的价值观和别人的成功与失败的来衡量自己。我觉得这是我这一个阶段需要解决的问题。归根到底，也是自己不够强大，内心世界还没有像钢铁一般。说实话，目前的我找不到解决这个很好的办法，但是可以一步一步的改变，而且这些改变也在我的身上潜移默化的进行着，比如说，更加坦然的面对自己，面对生活中的别人的优点与缺点，不再仇视比较，不再过多的去关注比较后的快乐与悲伤，虽然现在还是会有一些优越性质的高兴与难过，但是不会去主导自己心情。虽然仍然无法专注与自己的生活，但是一路走来我觉得自己成长的心路历程也是我最伟大的财富。祝自己中秋节快乐。]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>成长</tag>
        <tag>中秋节</tag>
        <tag>青春</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于军训体制的一些思考]]></title>
    <url>%2F2017%2F09%2F15%2F%E5%85%B3%E4%BA%8E%E5%86%9B%E8%AE%AD%E4%BD%93%E5%88%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[今天是军训的第七天，到了军训最后的阶段了，按照大家的说法和教官们的默许，最后几天就是纯放松型的交友盛会。回顾最先开始的几天，我觉得所有对这对生活里美好的期望全部被一些存在与生理上的痛苦所摧毁。在最初开始的几天里，我现在唯一记下去的就是我们的教官连长是如何吼我们，用他所谓的阶级思想来压榨我们的自由，我不知道自己这样的说法是不是属于正确的，因为在我们国家这种部队制度，本来就是军人务必服从命令的思想支撑。在此之前我的所有思想体系，全部都是基于一点，任何人都不能阻挡住我的自由。说实话，这种思想我认真想了想，就是考虑了下产生这种思想的原因，大概率可能是青春期里的叛逆？还是独立思想及独立人格作怪？我曾经在一本书里看到的一句话，人永远不可能完全自由，也就是不可能完全跟着天性的方向行走，因为社会这个产物，本来就是各种规则相互碰撞的结果。但是在现在这种部队制度越来越变味。我所理解服从命令应该是助于管理，以便于提升完成任务的效率。而现在这种服从命令越来越多的转化成了对权利的一种狂热，也就是所谓的官大你一级压死你。越来越多的人用命令进行压迫做一些无法理解甚至是利己的事情，也就是越来越多的在部队里面的人开始崇拜权利。于是越来越多的军痞产生了。我觉得军人在任何时候首先要做的事严格要求自己，比如说一些基本的军人常识，不要总是要求别人做到，然而自己却做不到。反而违背了军人服从命令的初衷。我知道并且也相信着我所遇见的军人中有很大一部分只能被称作为军痞，但是这个世界上正直的军人一定很多的。但是有这样的经历也不可能完全避免掉，在这些天里，我收获最多的是我会被磨平的急性子和自己的忍耐能力。虽然每天都在倒计时数数还剩下多少天，虽然每天都在心底里与这种在我看来毫无意义甚至是毁灭人性的虐待作斗争，但是我知道这种时候可以反抗，可以直接甩脸就走，但是自己已经成人了，成人必须具备这样的一个观点，成人的世界里必须遵守规则。不遵守规则的人直接出局。所以就会有忍耐的存在。现在真的是什么决定最后的承担者必须是自己了，对自己负责，遵守游戏规则。这次军训前面很累后面很轻松，新的生活即将开始，准备好自己的健身计划，英语和读书计划，这是你需要做的事情。最后来一句振奋人心的鸡汤。未来的你一定会感谢现在拼命努力的自己。]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>青春</tag>
        <tag>经历</tag>
        <tag>军训</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遗失的2016与无限可能的2017]]></title>
    <url>%2F2017%2F08%2F01%2F%E9%81%97%E5%A4%B1%E7%9A%842016%E4%B8%8E%E6%97%A0%E9%99%90%E5%8F%AF%E8%83%BD%E7%9A%842017%2F</url>
    <content type="text"><![CDATA[与上一次写下博客的时间实在是过去了太久太久，从去年高考的意外失败，到今年高考过后不知道是应该开心还是惋惜的局面。我知道自己并不是一个强调高考一定是一件关乎生死的大事。之所以选择复读这条路呢，是觉得不甘心，因为知道自己是一个容易受环境影响的人，不甘心就此平庸下去。于是这一年就像是消失，不再关心网上的一些动态。先开始是抱着苦读书的心态加入到了复读的队伍中，但是等到真正融入到那个环境中自己一个致命的毛病再一次犯了，开始轻视自己最后的目标。开始浪，开始没有高三那年这么不认真学习。虽然最后结果不差，从湖北省的66000多名跳到了24000名，但是我觉得如果当时自己不那么轻视高考的话，肯定会更好。但是人生就是人生，经历过才会刻苦铭心。这一年说长也不长，说短呢，倒也是盼了数不清的日日夜夜。在复读的班级里我见过各式各样的颓废，与各式各样的惨淡，还有各式各样的对梦想的摧残与亵渎，甚至在有一些人身上完全不用跟他们谈论梦想。我觉得这就是一种提前衰老的世俗气和死气，跟他们相互交流的过程中，难免不会被其沾染分毫。由于种种原因换到外面的合租寝室与另外一个复读班级。不过还是经常用一些稀奇古怪的理由去翘课。现在想来没有指责，也没有什么引以为豪的变态想法，只剩下一种好笑的想法。不过在复读的过程中，我有一次还经历请来了警察，事情的原因是我忍受不了一些狗血与荒谬的规定，我于是就与其对着干，然后对方以我闹事为名请来了警察。就跟警察好好聊聊呗。最后得出的结论，也就是从这件事情得出来的想法，社会上是存在狗眼看人低的现象，也存在某些荒谬的规定，但是如果你没有改变这些规则的能力与筹码的时候，你最好还是忍下来，免得最后受伤害和出笑话的都是你。最后6个月和7个月的时候换了寝室，跟两个自认为玩的不错的朋友合租了房子，之所以会产生矛盾就是觉得模糊了朋友与室友的关系。我觉得这一点我到大学去一定得注意。朋友是志同道合的，是可以交心的。而室友则是只是住在一起，有的时候不需要有共同的奋斗目标，只是住在一起，衣食住行上的相互照应。室友没有必要会成为好朋友。这就是以后需要注意的地方了。然后就是体重问题了，这个是硬伤，本来去年去复读前体重为84公斤，好不容易瘦下来的，现在才刚刚恢复到顶尖水平。不过加油吧。这个东西是急不来的慢慢加油一定会看到成效的，正所谓，玉树则不达嘛。不过以后还是要有一个好的健身计划和健康的作息时间表。要说这一年成长了么，我觉得主要是由以前理性的思维变得更加多元以及更加深入，谢谢奇葩说和狼人杀这两项事物让我看到了这个世界上还存在着诸多可能性。呵呵，年轻就有无限可能嘛还有一个月就要读大学。虽然有时候觉得这个大学也选的不怎么样，毕竟可以当作是滑档下来读的一所大学，但是听到一句话，你没有到这个学校的第一名，你是没有资格指责这个学校对你是没有益处的，因为在这个学校里面你总是会有上升的空间。以前真的有一种心态，就是特别想找一个对象，好好过，好好风花雪月，曾经也堕落过，也糜乱过，有的时候想想我们这个年纪很容易把欣赏当作是喜欢，把一种羡慕的想成为当作是爱情，到最后反而使爱情的真谛隐下去了，我觉得爱情就是平等，精神上的平等，互相成长，互相加深对人生的理解，也许有的时候性和欲望会常常来干涉，但是无论如何都占据不了爱情的真谛。我年纪还小，对婚姻的理解还尚在上一辈之间，他们让我感受到最多的是生活的迫不得已，也就是无可奈何的一起过日子。会不会结婚，能不能结婚，这都不是现在应该考虑的问题，我一生都会秉持着一个理念，Follow my heart 。我现在所做的一起努力使为了让未来的我在事情的抉择方面能更加靠近本心本愿一边。当然现在还不能把大学最终朝哪个方向定下来。但是勇敢，无畏，我觉得是人生中最重要的品质。在我的视角里荒废的2016年，就给2017年的我无限的可能。在今后的生活中我觉得一句话可以成为我的路标没有什么可以通向真诚，因为真诚是通向一切道路。真诚面对人，面对事，面对今后可能出现的无限挫折难过，以及开心完美与胜利。未来无论如何，总之我真诚，我坦荡，我会让这无限的可能尽可能的按照我心想象的方向前进。加油。因为你叫王舒啸。]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>成长</tag>
        <tag>青春</tag>
        <tag>经历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2015年年度总结]]></title>
    <url>%2F2015%2F12%2F02%2F2015%E5%B9%B4%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[今年是一个神奇的一年，做了许多以前没有想过的事情。但也碰触到了一些禁忌的事。泰戈尔也说过，人天生最强大的力量便是成长。对，就是成长。我们每一个人生来就不是完美的，我知道自己的缺点，自己的懦弱，自己在2015年所犯下的错误。但是还好，已经过去了，我也应该长大了。我也同样记得柴静说过的，只有同样经历过的人才有资格说我理解你。2015年上半年经历过一场车祸，终于从小孩子的认知，强行提升到了成人阶段，虽然有诸多不愿，但是，仍在慢慢适应。高二上学期，高二下学期，高三。时间过得很快。我理解了很多以前不理解的，看到了以前看不到的。人真的只有经历过痛苦才会知道自己真正想要的是什么。有的时候欲望，贪念，真的会毁掉一个人，但是也只有承受住来自与其磨难才可以真正成人。 但是由于自己的意志力不够，总是失败，但是我也不会妥协，抗争到底，这才是我。不过说到意志力，何谓意志力呢，个人觉得是一种抗逆的能力。抗拒痛苦和诱惑的能力。不巧，曾经拥有过的品质，由于生活过于安逸，再逐渐消失。比如说自己的拖延症，说大不大，但是说小也不小。我讨厌痛苦，这就是拖延症本质的原因。包括，给自己的任务完成不了，这也是其原因造成的。没有毅力。容易在家人面前控制不住自己的情绪。新的一年，我一定会改变这些。这一年里，也结识了许多人，逐渐知道社会7上的人情冷暖，以及人脉。我不想知道这些，但是现在能做的也就是默默的接受，总好比一味的抗拒。自己的性格也改了很多，一切朝好的方向进行转变。现在的我，也会学习每个人自己所遇到人的优点，从而改变自己。也许缓慢，但是方向是对的。关于你自己，我知道有的时候会有一种奇异的感觉包围着你，但是请相信一切的一切都会好的。打破常规，遵循本心。只当做看阴阳造化了。今后的日子，我希望自己能够坦荡做人，活出真实的自己，与自己的邪念抗争到底，完成自己的目标，过一种“没有任何借口”的生活。对自己，对别人，对一切负责。最后的最后，祝自己高考圆满，不求痴心妄想，只求问心无愧。]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>成长</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看见与经历]]></title>
    <url>%2F2015%2F08%2F29%2F%E7%9C%8B%E8%A7%81%E4%B8%8E%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[一直以来都是想写点什么，距离我上一次发博文也已经过去将近半年了，这半年里，也可以说这2015年里对我的改变也是挺大的。知道什么是苦，什么是乐，什么是欲望，什么是爱。今天是距离高三开学的最后一天，不知道我为什么总是这么喜欢做这样的事，直到最后一步才开始完成。我知道来自于自身里的缺陷。我懒，我没有过大的自制力，也没有太强的执行力。 我很懦弱，所以逃避。我一直坚信着一个人最可怕的并不是弱点，而是在有生之年并不去改变这些缺点。强点就是将自己的懦弱 前些日子也看过一些书籍，这本书对我的启发很大，并不能说这本书给了我很大的感受，因为那都是别人的生活，别人的人生历练。但是他打开了我通向这个世界的大门。我知道生，也知道死，也知道爱，只是有的亲身经历过，有的并没有经历过。我知道主观，也知道客观。这些带给我的都只是我人生路上的一个经历。曾经的我认为要对身边的人无下限的好，也曾经认为自己已经很成熟。认为自己的消极的态度就是成熟之人必备的。错错错。真正的成熟就是要在外界的压力和内界的蜕变下找到真正的自己，所谓破而后立，当你已经立到不能再破的时候，你也就形成了自己的思想理论和自己有别于他人的鲜明个性。而往往来说这个过程却是要花费一辈子的时间。 马上这个暑假也过去了，在这个暑假里，我由衷的觉得欲望和爱之间的关系，我可以做一个只有欲望的人，面对形形色色的人不动自己的生色。我目前觉得找一个与自己惺惺相惜的人那种默契才是我真正需要的。当人考虑这些东西要等到大半年之后，等我高三结束之时，也就是我人生觉醒之刻。这个夏天学会了一个人去旅行，学会了看题图，学会了处理自己与运动之间的关系。明天我将再次踏上战场，整装待发。 一直相信自己，从不会失望。 墨橹 写于 8月30日]]></content>
      <categories>
        <category>成长</category>
      </categories>
      <tags>
        <tag>成长</tag>
        <tag>经历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【书记】活着]]></title>
    <url>%2F2015%2F04%2F06%2F%E3%80%90%E4%B9%A6%E8%AE%B0%E3%80%91%E6%B4%BB%E7%9D%80%2F</url>
    <content type="text"><![CDATA[我今天要分享的小说是活着，这本小说讲述的是一个人与命运之间的关系，他们无法接受对方，但同时也没有办法背离对方。这本书我的很多朋友都看过，他们为故事里的悲剧角色叹息，甚至有几个感性的朋友每每谈起这本书总会泪滴点点。这本书如果整个看下来我看过9遍，只是一部分一部分的看的话，我看过不止十八遍。虽然这里没有像‘书读百遍，其义自现’的体会，但还是有了自己感受。首先我先声明我讲的东西并不深刻，也没有深度。你们知道什么叫作深刻么？其实一个人的存在并不深刻，但是这个人背后所浓缩的某些特点，与整个社会的客观存在某种现象的相联系，这才是深刻。我并不想去批判那个时代所呈现的劣根，因为这常常才是使人绝望的地方.我现在就向大家简要介绍一下《活着》这本书的故事剧情：故事里的主人公叫做福贵，是一个阔绰的少爷，他娶了一个妻子家珍，并且有一个4岁的女儿叫做凤霞。之后的悲剧也就是从这里开始的。福贵因为参与赌博被黑，卖掉了房子，输了全家三代积累下来的财富，自己怀孕的妻子家珍被老丈人无情带走。留下女儿和母亲相依为命，再过了一年多的苦生活后，家珍就带着一岁的儿子有庆回来，开始了一家人的平凡的农民生活。但是就在不久之后，福贵的母亲病了，福贵去城镇里请大夫，但是被国民党军抓取做壮丁，辗转两年被解放军所救，即后也就跟这解放军回家了。此时家里，母亲已经去世，女儿凤霞在一次高烧后变成了聋哑人，听妻子说母亲临终前一遍一遍的对妻子说，福贵是不会去赌博的。福贵也就在家里安顿下来，过了好几年，因为家里穷，只能卖女儿，让儿子去上学，最后女儿跑回来不忍送走，就留下来了。日子就这么一天天的过去，有一天因为县长的老婆生孩子要输血，结果儿子有庆被一个不负责任的大夫，给抽死了。后来竟然发现县长竟然是福贵当年相依为命的战友春生，不过春生之后也死于文化大革命。过了好几年，凤霞嫁了一个偏头女婿二喜，不久后死于产后大出血。两个孩子去世后，妻子家珍把外孙接到乡下来住，可没过多久就安安静静的死了。女婿二喜之后死于一场事故，死的时候外孙苦根仅仅4岁，还不知道死的概念。只留下祖孙俩人活着，但是好景不长，小苦根也意外失去了自己的生命。晚年的福贵买了一头老牛，取名为福贵。一起安享晚年。我这里并不想去讲这本书里所呈现出来的现实，也不想去评价这本书里的人物形象。这本书我看了很多遍，我甚至认为他们就像是我曾经与我精神交流的朋友。因为朴素，所以真实；因为真实，所以真挚；因为真挚，所以才会深深的触动我。在这里我只是想讲由这本书里我主管里延伸出来的3个问题吗，并且用我自己的生活感悟和经验，主观描述，客观阐述，解决的这三个问题 什么是活着。 为什么要活着。 怎么活着。首先第一个问题：什么才是活着。众所周知，生活的三大主题，生，死，爱。这三大永恒的主题将会影响我们的一生，生死相互对立而制衡，但是爱可以超越它们。（这里的爱并不只是男女之间的情愫，也并不是人与人之间产生的情感，具体来说它是一种主观感受，比如说喜怒哀乐恨，他们都是爱的一种表现）这里就为大家拓展下爱。大家谈到爱免不到就会想到《罗密欧与朱丽叶》，《梁山伯与祝英台》这两篇都是凄美且经典的爱情故事，他们所传达出来的思想则是”我爱你，所以我要为你殉情“大家知道随后即出的电影《泰坦尼克号》为什么那么有名，仅仅谈爱情一举超过了前面两部影片呢，甚至达到近几十年无人能敌的新的高峰呢，因为其提出了一个在当时特别前卫的思想理论‘我爱你，所以我就为你活下去，连同你的那一份一起活下去。”这就是爱，一定程度里爱可以超越生死。接下来便是我个人对生死的看法了，因为我有过这方面的经历所以我有这个资格拿出来来给大家分享，其实我今年17岁。在此之前对生死一点概念都是没有的，何谓生，何谓死呢，之前我的主观感觉就是教科书的生与死。直到我经历他。大家知道接触生死的第一感觉是什么吗？也许大家并不知道，仅仅只是以为是害怕，是恐惧。那么你就错了，并不是这样。接触生死的第一感觉不是恐慌，而恰恰是兴奋，我无法描述是一种怎样的兴奋，因为持续的时间特别短，大概可以类比为是一个从没有吃过糖的孩子，第一次吃糖的感觉，多少有点新鲜感在里面。之后就是一种安不下心的恐惧感，这种感觉没有经历过的人是不知道的，那是一种无法装出来的感觉。事后我也进行相关资料的查阅，好像是一个叫什么卡的理论科学家发表的一篇论文叫《生死论》里提到人在濒临死亡的那一刻，潜意识里已经把自己当作死亡，这时的恐惧将是对生活以及其他人或事物的无限眷念产生的。所以就像我的一个老师所讲的这个时候的人第一想法就是想自己最亲近的人，比如说妈妈。呵呵。我当时也是无法静下心，心里一直想如果妈妈在身边就好了，就好像这个人可以给你带来无尽的心安。之后过了一会儿后自己的心就静下来了，那种静下来的感觉叫做庆幸。感谢自己他妈的还活着。说句实话，那次的经历让我之后的一个月很不好过去，但是他对我最大的意义就是他完全打开了我对外界事物感知，就像一个美妙的气孔被揭开，然后进行气体交流的感觉。只有到了那个时候我才真正的知道到底什么是活着。就像我前面所说的爱是一切感受的源泉，所以活着就是我们在这个世界上主观上存在的感受。包括生，包括死，包括爱，包括我们生活的任何一种主观感觉，这就是活着。 我们为什么要活着 我很反感很多专家类的人物整天批判中国人没有信仰，中国人的信仰就是“好死不如赖活着，无论发生什么活着就行了。”活着这本书也就是讲为什么活着这个问题的，福贵在书里是这么形容自己的一生：&quot;我是有时候想想伤心，有时候想想又很踏实”一个早已进去垂暮之年的老人尚且如此，全家人的葬都是这样一位老人送走的，其中的滋味是我们所没办法想象的。那联系到实际，我们为什么活着呢，其实这个问题古往今来无数人士都参与过探讨，都没有得出一个科学性的结论。他们的探讨的过程大多数都是微观细胞的存在形式，和宏观宇宙的神秘意图。由我个人的观点，并没有 微及细胞，大至宇宙，也不像这本书里的观点。活着并不是为了活着以外的事物而活着，而是为了活着本身而活着。围绕这一个比较抽象的说法，也就展开了福贵的一生。中国有一个成语叫做千钧一发。让一根头发去承受三万斤的重压，但是头发并没有断。这就是中国人的韧性。真正强大的人并不是看他征服了什么，而是看他可以承受什么。所以我的答案也就由此而产生活着就是为了坚持，坚持去爱，坚持享受所有由活着带来的一切主观感受，坚持忍受由死去带来的一切恐惧体会，这就是活着。我的观点也就是这个，也许十年后我会推翻我的理论，（我已经推翻了我小时候很多的想法理论。）但至少现在不会。 第三，我们应该怎么活。这里其实就要客观的来讲一下这本书的局限性。这本书里讲的是上个世纪从解放后的土地改革、人民公社制度、大炼钢铁、三年自然灾害、文化大革命之间，讲的只是底层人民对于温饱问题矛盾，缺少的则是精神世界的建设。当然在那个年代谈精神年代就像说梦话一样。但是现在的社会水平已经高于当年很多倍了，但是现在的人民幸福度却远低当年。这又是为什么呢？唯一可以解释的原因就是，人们解决了温饱类的问题后，精神世界的匮乏甚至是溃烂，出现了极大的问题。那么怎么解决呢。物质和精神上的协调与平衡该如何做到呢？一切随心，随自己的主观感觉，随自己想要完成的事情。人为什么会不快乐，大家知道么？是由于我们个人的主观感觉被客观规律法则所牵制，导致我们并不快乐。而往往这些客观法则规律常常是没有最正确的理由的，比如说为什么评判现在一个人书读的好，就一切都好。为什么长大后赚钱的多少是评判一个人是否成功的重要依据。实现人生价值评判方式有很多，为什么单单只是这一点。那还有为什么男大当婚，女大当嫁…还有很多问题我们问不出来缘由，这些都是整个社会所给予的。那么为什么社会要这样规定呢？肯定是对整个社会的和谐稳定有益处。但同时也造成了巨大的压力给个人。按照幸福最大化原理，没有人，或者说是没有生物从本质上讲是喜欢痛苦和苦难的。然而面对这一切压力，但总是有人活的潇洒。比如庄子的物我合一，陶渊明的物我两忘，这些都是境界上的潇洒。而我们该如何做到这些呢？唯有修心。提高心理素质和承受能力，寻觅物质与精神守恒的一点。这就是我们活着该做的事情。人生的最高的境界便是淡。我没有达到这个境界，所以我没有办法为大家展开。但是按照自己的心活下去，我相信万法同一。殊途总会同归的。 写与2015年4月6日。]]></content>
      <categories>
        <category>书籍</category>
      </categories>
      <tags>
        <tag>书评</tag>
        <tag>创作</tag>
      </tags>
  </entry>
</search>
